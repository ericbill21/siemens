{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siemens_Approach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericbill21/siemens/blob/master/Siemens_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W70udFHYSHNI",
        "cellView": "form"
      },
      "source": [
        "#@title Imports and config\n",
        "\n",
        "# Tensorflow and Keras\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython.display import clear_output\n",
        "from psutil import virtual_memory\n",
        "\n",
        "# Arithmetic Operations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Progress calculation\n",
        "import sys\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# Time prediciton\n",
        "PREV_TIME = 0\n",
        "PB_START_TIME = 0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nzni4e78sTX",
        "cellView": "form",
        "outputId": "c1ae2349-ffb6-4b6f-8b55-3b01d52ae0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title GPU and RAM info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr  8 20:14:09 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E98cwmoUT7w1",
        "cellView": "form"
      },
      "source": [
        "#@title Global constants\n",
        "\n",
        "# Dictionaries\n",
        "COLORS = {0 : 'green', 1 : 'red', 'green' : 0, 'red' : 1}\n",
        "SOURCES = {'A' : 'https://drive.google.com/file/d/1hAzAKZNpmSclSI7HnV_cRjpMS4Kh5r1q/view?usp=sharing', 'B' : 'https://drive.google.com/file/d/12VlecL-5iYs-BFpnTOba1x65jWofBX1P/view?usp=sharing', 'C' : 'https://drive.google.com/file/d/1-Z0RuJIi1cZcqrrmV6TqT0O1PwI2OiBY/view?usp=sharing'}\n",
        "SOURCE_SIZE = {'A': 1000,'B' : 5000, 'C' : 50000}\n",
        "\n",
        "CURRENT_SET = 'B'\n",
        "\n",
        "# Balancing dataset to threshold\n",
        "THRESHOLD = 0.4\n",
        "\n",
        "# Random number seed\n",
        "random.seed(time.time())\n",
        "\n",
        "# Examlpe subsets of each dataset\n",
        "subsetA = [47, 847, 993, 55, 102, 572, 430, 115, 842, 72, 770, 107, 78, 834, 593, 43, 234, 709, 210, 378]\n",
        "#subsetB = [606, 2663, 1809, 2145, 4539, 3333, 3562, 2262, 512, 2046, 1541, 909, 286, 4815, 3663, 1742, 2822, 2756, 2937, 3080, 3845, 3949, 2506, 3984, 2803, 2067]\n",
        "subsetC = [32088, 33534, 39634, 40177, 25142, 752, 41771, 11793, 16415, 3811, 2096, 35902, 42221, 19594, 25109, 40476, 25162, 41150, 34610, 28329, 46339, 43149, 44441, 25720, 38747, 49497, 12708, 23920, 2280, 17946]\n",
        "\n",
        "subsetB = random.sample(range(5000), 800)\n",
        "\n",
        "VAL_INDICES = locals()['subset' + CURRENT_SET]\n",
        "\n",
        "# Penalty applied to false green classifications in custom loss function\n",
        "PENALTY = 0.3"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISkimS6oUTP9"
      },
      "source": [
        "#@title Functions\n",
        "\n",
        "\n",
        "def getDataSet():\n",
        "  \"\"\"Returns the dataset currently selected by CURRENT_SET.\"\"\"\n",
        "  path = 'https://drive.google.com/uc?export=download&id='+SOURCES[CURRENT_SET].split('/')[-2]\n",
        "  return pd.read_excel(path)\n",
        "  \n",
        "\n",
        "def makePlot(dataSet = np.array([]), correct_pred_points = np.array([]),\n",
        "             incorrect_pred_points = np.array([]), figsize=(14,10)):\n",
        "  \"\"\"\"Plots green and red points and markers as scatter graph.\n",
        "  \n",
        "  Args:\n",
        "    dataSet: Optional; Expects pandas.DataFrame object with columns 'x_i1',\n",
        "      'x_i2', 'l_i1'. Dataset to be plotted. Defaults to dataset selected by\n",
        "      CURRENT_SET.\n",
        "    showCorrectPoints: Optional; Expects boolean stating whether correctly \n",
        "      classified points should be marked as black 'x' or not.\n",
        "    correct_pred_points: Optional; Expects 2-dimensional list of shape (x,2)\n",
        "      containing correctly predicted points. Marked as black 'x' on scatter\n",
        "      graph.\n",
        "    incorrect_pred_points: Optional; Expects 2-dimensional list of shape (x,2)\n",
        "      containing incorrectly predicted points. Marked as black '*' on scatter\n",
        "      graph.\n",
        "  \n",
        "  Raises:\n",
        "    TypeError: If dataSet is not an instance of pd.DataFrame or the other\n",
        "      parameters do not have the required shape.\n",
        "  \"\"\"\n",
        "\n",
        "  # Preparing optional parameters\n",
        "  if dataSet.shape == (0,):\n",
        "    dataSet = getDataSet()\n",
        "  if isinstance(correct_pred_points, list):\n",
        "    correct_pred_points = np.array(correct_pred_points)\n",
        "  if isinstance(incorrect_pred_points, list):\n",
        "    incorrect_pred_points = np.array(incorrect_pred_points)\n",
        "\n",
        "  # Checking for the right type\n",
        "  if not isinstance(dataSet, pd.DataFrame):\n",
        "    raise TypeError(f'dataSet is of type: {type(dataSet)}, but should be {pd.DataFrame}')\n",
        "\n",
        "  # Checking for the right shape \n",
        "  if correct_pred_points.shape != (correct_pred_points.shape[0],2) and np.array(correct_pred_points).shape != (0,):\n",
        "    raise TypeError(f'The shape of the parameter correct_pred_points is: \\\n",
        "      {np.array(correct_pred_points).shape}, but it should be 2 dimensional')\n",
        "  \n",
        "  if incorrect_pred_points.shape != (incorrect_pred_points.shape[0],2) and np.array(incorrect_pred_points).shape != (0,):\n",
        "    raise TypeError(f'The shape of the parameter incorrect_pred_points is: \\\n",
        "      {np.array(incorrect_pred_points).shape}, but it should be 2 dimensional')\n",
        "  \n",
        "  # Creating a subplot\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "  # Scattering all points\n",
        "  x = dataSet['x_i1']\n",
        "  y = dataSet['x_i2']\n",
        "  c = [COLORS[i] for i in dataSet['l_i']] \n",
        "\n",
        "  ax.scatter(x, y, c=c)\n",
        "\n",
        "  # Adding markers to the specified points\n",
        "  if correct_pred_points.shape[0] > 0:\n",
        "    ax.scatter(correct_pred_points[:, 0], correct_pred_points[:, 1],\n",
        "              marker = \"x\", c = 'black', label='correct')\n",
        "  if incorrect_pred_points.shape[0] > 0:\n",
        "    ax.scatter(incorrect_pred_points[:, 0], incorrect_pred_points[:, 1],\n",
        "            marker = \"*\", c = 'black', label='incorrect')\n",
        "\n",
        "  if correct_pred_points.shape[0] > 0 or incorrect_pred_points.shape[0] > 0:\n",
        "    plt.legend()\n",
        "\n",
        "  # Setting parameters for ploting\n",
        "  plt.xlabel('x_i1')\n",
        "  plt.ylabel('x_i2')\n",
        "  plt.title(f'DataSet {CURRENT_SET}')\n",
        "  plt.axis('scaled')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def seperateValidationSet(dataSet, validationIndices):\n",
        "  \"\"\"Formats a subset of points from a dataset as validation points.\n",
        "\n",
        "  Validation points are extracted and deleted from dataSet to be used for\n",
        "  validation later on.\n",
        "\n",
        "  Args:\n",
        "    dataSet: Expects pandas.DataFrame object with columns 'x_i1', 'x_i2', 'l_i1'.\n",
        "      dataSet which the validation points are extracted from.\n",
        "    validationIndices: Expects 1-dimensional list of integers. The elements\n",
        "      corresponding to these indices are extracted from dataSet.\n",
        "  Returns: 2-tuple of the form (valSet_points, valSet_labels), where valSet_points\n",
        "    is a tensor of shape (x,2) and valSet_labels is a tensor of shape (x,1).\n",
        "  \"\"\"\n",
        "\n",
        "  # Cheching for the right type\n",
        "  if not isinstance(dataSet, pd.DataFrame):\n",
        "    raise TypeError(f'dataSet is of type: {type(dataSet)}, but should be \\\n",
        "      {pd.DataFrame}')\n",
        "\n",
        "  # Cheching for the right shape \n",
        "  if len(np.array(validationIndices).shape) != 1:\n",
        "    raise TypeError(f'The shape of the parameter validationIndices is: \\\n",
        "      {np.array(validationIndices).shape}, but it should be 1 dimensional')\n",
        "  \n",
        "  valSet_points = []\n",
        "  valSet_labels = []\n",
        "\n",
        "  for i in validationIndices:\n",
        "    valSet_points.append([dataSet['x_i1'].loc[i], dataSet['x_i2'].loc[i]])\n",
        "    valSet_labels.append([dataSet['l_i'].loc[i]])\n",
        "  \n",
        "  #Saving the testing points\n",
        "  valSet_points = tf.constant(valSet_points, tf.float32)\n",
        "  valSet_labels = tf.constant(valSet_labels, tf.float32)\n",
        "\n",
        "  #Removing the testing point\n",
        "  dataSet.drop(index=validationIndices, inplace=True)\n",
        "  dataSet.reset_index(inplace=True)\n",
        "\n",
        "  return (valSet_points, valSet_labels)\n",
        "\n",
        "\n",
        "def printProgressBar(iteration, total, prefix = '', suffix = '', decimals = 1,\n",
        "                     length = 100, fill = 'â–ˆ'):\n",
        "  \"\"\"Prints a progress bar.\n",
        "\n",
        "  Args:\n",
        "    iteration: Expects integer. Current progress step as. (iteration/total progress).\n",
        "    total: Expects integer. Total progress steps until completion.\n",
        "    prefix: Optional; Expects String. Printed infront of the progress bar.\n",
        "    suffix: Optional; Expects String. Printed behind ETA.\n",
        "    decimals: Optional; Expects integer. Number of decimal places of percentage\n",
        "      progress.\n",
        "    length: Optional; Expects integer. Length of the progress bar in characters.\n",
        "    fill: Optional; Expects char. Filler of the progress bar.\n",
        "  \"\"\"\n",
        "  # Preparing strings\n",
        "  percentage_progress = (100*(iteration/float(total)))\n",
        "  percent = (\"{0:.\" + str(decimals) + \"f}\").format(percentage_progress)\n",
        "  filledLength = int(length * iteration // total)\n",
        "  bar = fill * filledLength + '-' * (length - filledLength)\n",
        "\n",
        "  # Bob's alternative time calculation\n",
        "  if iteration == 0:\n",
        "    global PB_START_TIME\n",
        "    PB_START_TIME = time.time()\n",
        "    time_so_far = 0\n",
        "    time_remaining = 0\n",
        "  else:\n",
        "    time_so_far = time.time() - PB_START_TIME\n",
        "    time_remaining = time_so_far/percentage_progress * (100-percentage_progress)\n",
        "\n",
        "  sys.stdout.write(f'\\r{prefix} |{bar}| {percent}% | ETA: {round((time_remaining/60), 2)} minutes | {suffix}')\n",
        "  sys.stdout.flush()\n",
        "\n",
        "  # Erease progress bar on complete\n",
        "  if iteration == total:\n",
        "    global PREV_TIME\n",
        "    PREV_TIME = 0\n",
        "    sys.stdout.write('\\r')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def makeCertaintyMap(model, accuracy = 100, specific_color = None):\n",
        "  \"\"\"Visualizes the prediction certainty of the model for a grid of data points.\n",
        "\n",
        "  All data points have x and y values between 0 and 1. \n",
        "\n",
        "  Args:\n",
        "    model: Expects a keras model. The model who's certainty is to be\n",
        "      visualized.\n",
        "    accuracy: Optional; Expects integer. Data points are spaced 1/accuracy apart\n",
        "      along the x and y axis. The grid of data points plotted has the dimension\n",
        "      accuracy*accuracy.\n",
        "    specific_color: Optional; Expects 0 or 1. If 0, plots the model's certainty\n",
        "      that a data point is green for all points in the grid. If 1, analogously \n",
        "      for red. \n",
        "\n",
        "  Raises:\n",
        "    TypeError: If specific_color is not 'None', '0' or '1', or if accuracy is not\n",
        "      an int.\n",
        "  \"\"\"\n",
        "  # Exceptions\n",
        "  if specific_color != None:\n",
        "    if specific_color != 0 and specific_color != 1:\n",
        "      raise TypeError(f'Invalid value for specific_color. Value is {specific_color}, \\\n",
        "        but should be \"None\", \"0\" or \"1\".')\n",
        "\n",
        "  if not isinstance(accuracy, int):\n",
        "    raise TypeError(f'Invalid type for accuracy. Type is {type(accuracy)}, but \\\n",
        "      should be int.')\n",
        "\n",
        "  accuracy_map = np.zeros((accuracy, accuracy))\n",
        "\n",
        "  for i in range(accuracy):\n",
        "    tensor = tf.constant([[j/accuracy, i/accuracy] for j in range(accuracy)], tf.float32)\n",
        "    result = model.predict(tensor)\n",
        "\n",
        "    if specific_color != None:\n",
        "      # Saving the prediction for the specified color\n",
        "      accuracy_map[i] = result[:, specific_color]\n",
        "    \n",
        "    else:\n",
        "      result = result.max(axis=1) #Getting each max value\n",
        "\n",
        "      #Normalize the values which are between 0.5 <-> 1 to 0 <-> 1\n",
        "      normalized = (result-0.5)/0.5\n",
        "      accuracy_map[i] = normalized\n",
        "  \n",
        "    # Print current progress\n",
        "    printProgressBar(i, accuracy-1)\n",
        "\n",
        "  if specific_color != None:\n",
        "    plt.title(f'Certaintiy for {COLORS[specific_color]}')\n",
        "  else:\n",
        "    plt.title(f'General Certainty')\n",
        "\n",
        "  plt.imshow(accuracy_map, origin='lower', cmap='tab20b', vmin=0, vmax=1)\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "  return accuracy_map\n",
        "\n",
        "\n",
        "def timeCalc():\n",
        "  \"\"\"Calculates time between previous call and current call.\n",
        "\n",
        "  Returns:\n",
        "    Time difference in minutes as float.\n",
        "  \"\"\"\n",
        "  global PREV_TIME\n",
        "  if PREV_TIME == 0:\n",
        "    PREV_TIME = time.time()\n",
        "    return 0\n",
        "  \n",
        "  res = (time.time() - PREV_TIME) / 60\n",
        "  PREV_TIME = time.time()\n",
        "  return res\n",
        "\n",
        "\n",
        "def plotLoss(history):\n",
        "  \"\"\"Plots training loss and validation loss with respect to training epochs.\n",
        "\n",
        "  Args:\n",
        "    history: Expects keras History. history of keras model.\n",
        "  \"\"\"\n",
        "\n",
        "  if 'val_loss' in history.history:\n",
        "    plt.plot(history.history['val_loss'])\n",
        "\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def showPredicitons(model, history, valSet_points,\n",
        "                    valSet_labels, showCorrectPoints=False):\n",
        "  \"\"\"Visualizes the predictions for the validation points\n",
        "\n",
        "  Args:\n",
        "    model: Expects keras model. Model which performs the predictions.\n",
        "    history: Expects keras History. history of keras model.\n",
        "    valSet_points: Expects tensor of shape (x,2). Data points used for validation.\n",
        "    valSet_labels: Expects tensor of shape (x,1). Ground truth labels of the \n",
        "      validation points.\n",
        "    showCorrectPoints: Optional; Expects boolean stating whether correctly \n",
        "      classified points should be marked as black 'x' or not.\n",
        "\n",
        "  Returns:\n",
        "    2-dimensional numpy array of shape (x,2) with the predictions for the\n",
        "    validation points.\n",
        "  \"\"\"\n",
        "  # Predict the validation points\n",
        "  prediction = model.predict(valSet_points)\n",
        "\n",
        "  points = valSet_points.numpy()\n",
        "  labels = valSet_labels.numpy()[:, 0].astype(int)\n",
        "\n",
        "  # Identifying correctly and incorrectly classified points\n",
        "  correct_indices = np.where((labels == np.argmax(prediction, axis=1)) == True)\n",
        "  incorrect_indices = np.where((labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "  number_of_points = np.bincount(np.argmax(prediction, axis=1))\n",
        "\n",
        "  total_misclassifications = np.bincount(labels == np.argmax(prediction, axis=1))[0]\n",
        "  red_misclassifications = len(np.where(labels[incorrect_indices] == 1)[0])\n",
        "  green_misclassifications = len(np.where(labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "  #Average misclassification certainty\n",
        "  misclass_certainties = []\n",
        "  for i in incorrect_indices[0]:\n",
        "    misclass_certainties.append(np.max(prediction[i]))\n",
        "  avg_misclass_certainty = sum(misclass_certainties)/total_misclassifications\n",
        "  \n",
        "  print('Validation accuracy: {:.2f}%'.format((history.history['val_accuracy'])[-1]*100))\n",
        "  print(f'Predictions for green: {number_of_points[0]} / {len(labels)}')\n",
        "  print(f'Predictions for red: {number_of_points[1]} / {len(labels)}')\n",
        "  print(f'Points misclassified: {total_misclassifications}')\n",
        "  print(f'Red points misclassified: {red_misclassifications}')\n",
        "  print(f'Green points misclassified: {green_misclassifications}')\n",
        "  print('Average misclassification certainty: {:.2f}'.format(avg_misclass_certainty))\n",
        "\n",
        "\n",
        "  if showCorrectPoints:\n",
        "    makePlot(correct_pred_points=points[correct_indices],\n",
        "           incorrect_pred_points=points[incorrect_indices])\n",
        "  else:\n",
        "    makePlot(incorrect_pred_points=points[incorrect_indices])\n",
        "    \n",
        "  # Make bar graph showing red and green misclassifications\n",
        "  bars = ('Red', 'Green')\n",
        "  height = [red_misclassifications, green_misclassifications]\n",
        "  x_pos = np.arange(len(bars))\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.bar(x_pos, height, width=0.35, color=['red', 'green'])\n",
        "\n",
        "  ax.set_ylabel('Misclassifications')\n",
        "  ax.set_title('Misclassifications by color')\n",
        "  ax.set_xticks(x_pos)\n",
        "  ax.set_xticklabels(bars)\n",
        "\n",
        "  rects = ax.patches # Array of bars\n",
        "\n",
        "  labels = [red_misclassifications, green_misclassifications]\n",
        "\n",
        "  for rect, label in zip(rects, labels): # Add labels above bars\n",
        "      height = rect.get_height()\n",
        "      ax.text(rect.get_x() + rect.get_width() / 2, height, label,\n",
        "              ha='center', va='bottom')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  return prediction\n",
        "\n",
        "  \n",
        "def balanceDataset(dataSet, threshold, verbose=1):\n",
        "  \"\"\"Artificially balances dataSet by duplicating red or green points.\n",
        "\n",
        "  Args: \n",
        "    dataSet: Expects pandas.DataFrame object with columns 'x_i1', 'x_i2', 'l_i1'.\n",
        "      The dataset to be balanced.\n",
        "    threshold: Expects float between 0 and 0.5. The function duplicates red or \n",
        "      green points until the fraction of points of the less frequent color is\n",
        "      at least equal to the threshold.\n",
        "\n",
        "  Returns:\n",
        "    balanced dataset of shape (x,2)\n",
        "  \"\"\"\n",
        "\n",
        "  total_number_of_points = dataSet.shape[0]\n",
        "  number_of_green_points = dataSet.loc[dataSet[\"l_i\"] == 0].shape[0]\n",
        "  number_of_red_points = dataSet.loc[dataSet[\"l_i\"] == 1].shape[0]\n",
        "\n",
        "  amount = 0\n",
        "\n",
        "  if number_of_red_points / total_number_of_points < threshold:\n",
        "    amount = int( (threshold * total_number_of_points - number_of_red_points) // (1 - threshold) )\n",
        "    red_points = dataSet.loc[dataSet['l_i'] == 1] #Getting all red points\n",
        "    chosen_points = red_points.sample(amount, replace=True) #Selecting a random subset of red points\n",
        "    dataSet = dataSet.append(chosen_points, ignore_index=True) #appending the subset\n",
        "\n",
        "  if number_of_green_points / total_number_of_points < threshold:\n",
        "    amount = int( (threshold * total_number_of_points - number_of_green_points) // (1 - threshold) )\n",
        "    green_points = dataSet.loc[dataSet['l_i'] == 0] #Getting all green points\n",
        "    chosen_points = green_points.sample(amount, replace=True) #Selecting a random subset of green points\n",
        "    dataSet = dataSet.append(chosen_points, ignore_index=True) #appending green subset\n",
        "\n",
        "  if 'index' in dataSet.columns:\n",
        "    dataSet.pop('index') #removing old indices\n",
        "\n",
        "  total_number_of_points = dataSet.shape[0]\n",
        "  number_of_green_points = dataSet.loc[dataSet[\"l_i\"] == 0].shape[0]\n",
        "  number_of_red_points = dataSet.loc[dataSet[\"l_i\"] == 1].shape[0]\n",
        "\n",
        "  if verbose > 0:\n",
        "    print(f'Artificially exended by {amount} points')\n",
        "    print(f'Relation is now: {round(number_of_green_points / total_number_of_points, 2)}',\n",
        "            f'green : {round(number_of_red_points / total_number_of_points, 2)} red ')\n",
        "  \n",
        "  return dataSet\n",
        "\n",
        "\n",
        "def plotPenaltyEffect(x, y, validation_data, interval=(0,1), accuracy=10, \n",
        "                      batch_size=32, epochs=200, verbose=0):\n",
        "  \"\"\"Plots red, green, and total misclassifications in relation to penalty.\n",
        "\n",
        "  Args:\n",
        "    x: Expects tensor of shape (x,2) and type tf.float32. Training points.\n",
        "    y: Expects tensor of shape (x,1) and type float32. Training labels.\n",
        "    validation_data: Expects 2-tuple (valSet_points, valSet_labels) where\n",
        "      valSet_points is a tensor of shape (x,2) and type tf.float32 and \n",
        "      valSet_labels tensor of shape (x,1) and type tf.float32. Validation points\n",
        "      and labels.\n",
        "    interval: Optional; Expects 2-tuple (x,y) which defines the interval of penalties\n",
        "      plotted. x is the lowest penalty, y the highest.\n",
        "    accuracy: Optional; Expects int. Interval is evenly split into 'accuracy' many\n",
        "      points.\n",
        "    All others: Optional; See tf.keras.Model.\n",
        "\n",
        "  Returns:\n",
        "    3-tuple of int lists (total_misclass_percentage, red_misclass_percentage, \n",
        "      green_misclass_percentage).\n",
        "  \"\"\"\n",
        "  total_misclass_percentages = []\n",
        "  red_misclass_percentages = []\n",
        "  green_misclass_percentages = []\n",
        "  penalties = np.zeros(accuracy + 1)\n",
        "  increments = (interval[1]-interval[0])/accuracy\n",
        "\n",
        "  points = validation_data[0].numpy()\n",
        "  labels = validation_data[1].numpy()[:, 0].astype(int)\n",
        "\n",
        "  number_of_points = len(labels)\n",
        "  red_points = len(np.where(labels==1)[0])\n",
        "  green_points = len(np.where(labels==0)[0])\n",
        "\n",
        "  if verbose > 0:\n",
        "    printProgressBar(0, accuracy+1)\n",
        "\n",
        "\n",
        "  # MAIN LOOP\n",
        "  for i in range(accuracy+1):\n",
        "    penalty = interval[0] + (interval[1]-interval[0])*(i/accuracy)\n",
        "    model.set_weights(initialWeights)\n",
        "\n",
        "    model.compile(optimizer='adam', loss=construct_custom_penalty_loss(penalty),\n",
        "                  metrics=['accuracy']) # Compile model with penalty\n",
        "\n",
        "    history = model.fit(x, y, batch_size, epochs, verbose=0, validation_data=validation_data)\n",
        "\n",
        "    prediction = model.predict(validation_data[0])\n",
        "\n",
        "    correct_indices = np.where((labels == np.argmax(prediction, axis=1)) == True)\n",
        "    incorrect_indices = np.where((labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "    total_misclassifications = np.bincount(labels == np.argmax(prediction, axis=1))[0]\n",
        "    red_misclassifications = len(np.where(labels[incorrect_indices] == 1)[0])\n",
        "    green_misclassifications = len(np.where(labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "    total_misclass_percentages.append((total_misclassifications/number_of_points)*100)\n",
        "    red_misclass_percentages.append((red_misclassifications/red_points)*100)\n",
        "    green_misclass_percentages.append((green_misclassifications/green_points)*100)\n",
        "\n",
        "    penalties[i] = penalty\n",
        "    \n",
        "    if verbose > 0:\n",
        "      printProgressBar(i+1, iterations+1)\n",
        "\n",
        "\n",
        "  # PLOTTING RESULTS\n",
        "  if verbose > 0:\n",
        "    plt.figure(figsize=(20,15))\n",
        "    plt.plot(penalties, total_misclass_percentages, 'b', penalties, \n",
        "              red_misclass_percentages, 'r', penalties, green_misclass_percentages,\n",
        "              'g')\n",
        "    plt.title(f'Dataset {CURRENT_SET}: Misclassification by penalty')\n",
        "    plt.ylabel('% misclassified')\n",
        "    plt.xlabel('Penalty')\n",
        "    plt.xticks(np.arange(interval[0], interval[1]+increments, increments))\n",
        "    plt.legend(['total', 'red', 'green'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "  return (total_misclass_percentages, red_misclass_percentages,\n",
        "         green_misclass_percentages)\n",
        "\n",
        "def KNN(dataSet, point, k, significance=0.1, increment=0.05, show_plot=True):\n",
        "  '''\n",
        "  Statistical classifier. It selects the closest k neighbours and uses them to \n",
        "  assume the color of the given point, by selecting the maximum amount of neighbours \n",
        "  of one color weigthed by their squared distance.\n",
        "\n",
        "  Args:\n",
        "    dataSet: Optional, pandas.DataFrame object with columns 'x_i1', 'x_i2', 'l_i1'.\n",
        "      Dataset to be used for calculation. Defaults to dataset selected\n",
        "      by CURRENT_SET.\n",
        "    point: Array in the form of [x_i1, x_i2]\n",
        "    k: Positive integer\n",
        "      Number of neighbours taken into account for classification\n",
        "    significance: Optional, float between 0 and 1\n",
        "      Start search radius\n",
        "    increment: Option, float between 0 and 1\n",
        "      Amount of increment of the search radius while gathering k neighbours\n",
        "    show_plot: Optional, boolean\n",
        "      If 'True' the function plots the dataset and the selected neighbours\n",
        "\n",
        "  Returns:\n",
        "    A 2-tuple with the predictions for each class. \n",
        "    (prediction_green, prediction_red)\n",
        "\n",
        "  '''\n",
        "  # Gathering points until at least k neighbours are found \n",
        "  neighb = np.array([])\n",
        "  while significance <= 1 or neighb.shape[0] < k:\n",
        "      neighb = dataSet.loc[(dataSet['x_i1'] - point[0])**2 + (dataSet['x_i2'] - point[1])**2 <= significance**2]\n",
        "      significance += increment\n",
        "  \n",
        "  # Reindexing\n",
        "  neighb = neighb.reset_index()\n",
        "\n",
        "  # Calculating the distances of each neighbour to the target point\n",
        "  dist = np.zeros(neighb.shape[0])\n",
        "  for i in range(neighb.shape[0]):\n",
        "    dist[i] = (neighb['x_i1'].loc[i] - point[0])**2 + (neighb['x_i2'].loc[i] - point[1])**2\n",
        "\n",
        "  # Removing all overhang neighbours until there are only k\n",
        "  while neighb.shape[0] > k:\n",
        "    neighb = neighb.drop(np.argmax(dist))\n",
        "    dist[np.argmax(dist)] = -1\n",
        "\n",
        "  # Reindexing\n",
        "  dist = np.zeros(neighb.shape[0])\n",
        "  neighb = neighb.reset_index()\n",
        "\n",
        "  # Calculating the distances of each neighbour to the target point\n",
        "  for i in range(neighb.shape[0]):\n",
        "    dist[i] = (neighb['x_i1'].loc[i] - point[0])**2 + (neighb['x_i2'].loc[i] - point[1])**2\n",
        "\n",
        "\n",
        "  pred_g = 0\n",
        "  pred_r = 0\n",
        "\n",
        "  # Sum the neighbours of each color with the weight 1-dist^2 \n",
        "  for i in range(neighb.shape[0]):\n",
        "    if neighb['l_i'].loc[i] == 0:\n",
        "      pred_g += (1 - dist[i])\n",
        "    elif neighb['l_i'].loc[i] == 1:\n",
        "      pred_r += (1 - dist[i])\n",
        "\n",
        "  # Normalize\n",
        "  sum = pred_g + pred_r\n",
        "  pred_g = pred_g // sum\n",
        "  pred_r = pred_r // sum\n",
        "\n",
        "  # Plot neighbours \n",
        "  if show_plot:\n",
        "    selected_neighb = [[neighb['x_i1'].loc[i], neighb['x_i2'].loc[i]] for i in range(neighb.shape[0])]\n",
        "    makePlot(dataSet, [point], selected_neighb)\n",
        "    print(f'Prediction for green: \\t{pred_g}')\n",
        "    print(f'Prediction for red: \\t{pred_r}')\n",
        "\n",
        "  return (pred_g, pred_r)\n",
        "\n",
        "def makeCertaintyMapKNN(k, accuracy = 100, specific_color = None):\n",
        "  \"\"\"Visualizes the prediction certainty of K-nearest-neighbour algorithm for a grid of data points.\n",
        "\n",
        "  All data points have x and y values between 0 and 1. \n",
        "\n",
        "  Args:\n",
        "    k: postive integer.\n",
        "      The number of neighbours specified for the KNN algorithm who's certainty\n",
        "      is to bevisualized.\n",
        "    accuracy: Optional; positive integer\n",
        "      Data points are spaced 1/accuracy apart along the x and y axis. The grid \n",
        "      of data points plotted has the dimension accuracy*accuracy.\n",
        "    specific_color: Optional; Expects 0 or 1\n",
        "      If 0, plots the model's certainty that a data point is green for all\n",
        "      points in the grid. If 1, analogously for red. \n",
        "\n",
        "  Raises:\n",
        "    TypeError: If specific_color is not 'None', '0' or '1', or if accuracy and k\n",
        "    is not an int.\n",
        "  \"\"\"\n",
        "  #Exceptions\n",
        "  if specific_color != None:\n",
        "    if specific_color != 0 and specific_color != 1:\n",
        "      raise TypeError(f'Invalid value for specific_color. Value is {specific_color}, \\\n",
        "        but should be \"None\", \"0\" or \"1\".')\n",
        "\n",
        "  if not isinstance(accuracy, int):\n",
        "    raise TypeError(f'Invalid type for accuracy. Type is {type(accuracy)}, but \\\n",
        "      should be int.')\n",
        "    \n",
        "  if not isinstance(k, int):\n",
        "    raise TypeError(f'Invalid type for k. Type is {type(k)}, but \\\n",
        "      should be int.')\n",
        "\n",
        "  # Init Data\n",
        "  dataSet = getDataSet()\n",
        "  accuracy_map = np.zeros((accuracy, accuracy))\n",
        "\n",
        "  # Main Loop\n",
        "  for i in range(accuracy):\n",
        "    for j in range(accuracy):\n",
        "      result = KNN(dataSet, [j/accuracy, i/accuracy], k, show_plot=False)\n",
        "\n",
        "      if specific_color != None:\n",
        "        # Saving the prediction for the specified color\n",
        "        accuracy_map[i,j] = result[specific_color]\n",
        "      else:\n",
        "        result = np.max(result)\n",
        "\n",
        "        #Normalize the values which are between 0.5 <-> 1 to 0 <-> 1\n",
        "        normalized = (result-0.5)/0.5\n",
        "        accuracy_map[i,j] = normalized\n",
        "    \n",
        "      # Print current progress\n",
        "      printProgressBar((j+1) + i*accuracy, accuracy**2)\n",
        "\n",
        "  # Choosing headline\n",
        "  if specific_color != None:\n",
        "    plt.title(f'Certaintiy for {COLORS[specific_color]}')\n",
        "  else:\n",
        "    plt.title(f'General Certainty')\n",
        "\n",
        "  # Plot\n",
        "  plt.imshow(accuracy_map, origin='lower', cmap='tab20b', vmin=0, vmax=1)\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "  \n",
        "  return accuracy_map\n",
        "\n",
        "\n",
        "def makeDensityMap(dataSet=None, significance=0.1, cmap=plt.cm.get_cmap('Spectral'), specific_color = None):\n",
        "  '''\n",
        "  \tCreates a headmap of the density of the current selected dataSet\n",
        "\n",
        "    Args:\n",
        "      dataSet: Optional, pandas.DataFrame object with columns 'x_i1', 'x_i2', 'l_i1'.\n",
        "        Dataset to be used for calculation. Defaults to dataset selected\n",
        "        by CURRENT_SET.\n",
        "      signifcance: Optional, float between 0 and 1\n",
        "        Determines the radius by which neighbours are being counted for the \n",
        "        density of a particular point\n",
        "      cmap: Optional, matplotlib colormap\n",
        "        Is used for color coding the density of the dataset at the end\n",
        "      specific_color: Optional, Expects 0 or 1\n",
        "        If 0, a heatmap of only green points is computed. If 1, analogously for red\n",
        "  '''\n",
        "  if specific_color != None:\n",
        "    dataSet = dataSet.loc[dataSet['l_i'] == specific_color]\n",
        "    dataSet.reset_index(inplace=True)\n",
        "\n",
        "  total_number_of_points = dataSet.shape[0]\n",
        "  array = np.zeros((total_number_of_points, 3))\n",
        "\n",
        "  # Counting all neighbours within a radius of significance\n",
        "  for i in range(total_number_of_points):\n",
        "    count = dataSet.loc[(dataSet['x_i1'] - dataSet['x_i1'].loc[i])**2 + (dataSet['x_i2'] - dataSet['x_i2'].loc[i])**2 <= significance**2]\n",
        "\n",
        "    array[i, 0] = dataSet['x_i1'].loc[i]\n",
        "    array[i, 1] = dataSet['x_i2'].loc[i]\n",
        "    array[i, 2] = len(count)\n",
        "\n",
        "    printProgressBar(i+1, total_number_of_points)\n",
        "\n",
        "  print(f'Max: {np.max(array[:,2])}')\n",
        "  print(f'Min: {np.min(array[:,2])}')\n",
        "\n",
        "  # Used for the normalization\n",
        "  norm = plt.Normalize(vmin=np.min(array[:,2]),vmax=np.max(array[:,2]))\n",
        "\n",
        "  # Setting parameters for ploting\n",
        "  plt.scatter(array[:, 0], array[:, 1], c=array[:, 2], cmap=cmap, norm=norm)\n",
        "  plt.colorbar()\n",
        "  plt.xlabel('x_i1')\n",
        "  plt.ylabel('x_i2')\n",
        "  plt.title(f'Density of DataSet {CURRENT_SET}')\n",
        "  plt.axis('scaled')\n",
        "  plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGMBPET_gqbP",
        "cellView": "form"
      },
      "source": [
        "#@title Average Penalty Effect\n",
        "def averagePenaltyEffect(n, length_val, interval=(0,1), accuracy=10, \n",
        "                      batch_size=32, epochs=200, verbose=1):\n",
        "  \"\"\"Plots average penalty effect over n iterations.\n",
        "\n",
        "  Args:\n",
        "    n: Expects int. Number of iterations the penalty effect is measured and\n",
        "      averaged over.\n",
        "    length_val: Expects int. Size of the validation set. \n",
        "    All others: See plotPenaltyEffect.\n",
        "\n",
        "  Returns:\n",
        "    3-tuple of int lists (total_misclass_percentages_avg, red_misclass_percentages_avg,\n",
        "         green_misclass_percentages_avg).\n",
        "  \"\"\"\n",
        "  \n",
        "  penalties = np.arange(interval[0], interval[1]+(interval[1]-interval[0])/accuracy,\n",
        "                        (interval[1]-interval[0])/accuracy)\n",
        "\n",
        "  # INITIALIZATION OF DATA COLLECTION OBJECTS\n",
        "  \n",
        "  # For averaging\n",
        "  total_misclass_percentages_collected = []\n",
        "  red_misclass_percentages_collected = []\n",
        "  green_misclass_percentages_collected = []\n",
        "  # For saving in excel\n",
        "  validation_points_collected = np.zeros((length_val, 3*n))\n",
        "  misclassification_matrix = np.zeros((len(penalties), 3*n))\n",
        "  # Column names\n",
        "  val_columns = []\n",
        "  coll_columns = []\n",
        "\n",
        "  # Initialize progress bar\n",
        "  if verbose > 0:\n",
        "    printProgressBar(0, n)\n",
        "\n",
        "  # MAIN LOOP\n",
        "  for i in range(n):\n",
        "    # PREPARING DATA\n",
        "    dataSet = getDataSet()\n",
        "    dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "    # Choose random validation set\n",
        "    random.seed(time.time())\n",
        "    val_indices = random.sample(range(5000), length_val)\n",
        "\n",
        "    valSet_points, valSet_labels = seperateValidationSet(dataSet=dataSet, validationIndices=val_indices)\n",
        "    dataSet = balanceDataset(dataSet, threshold=THRESHOLD, verbose=0)\n",
        "\n",
        "    training_labels = tf.constant(dataSet.pop('l_i'), tf.float32)\n",
        "    training_points = tf.constant(dataSet, tf.float32)\n",
        "\n",
        "    # Collecting misclassification percentages\n",
        "    allPercentages = plotPenaltyEffect(training_points, training_labels, (valSet_points, valSet_labels),\n",
        "                                       interval=interval, accuracy=accuracy,\n",
        "                                       batch_size=batch_size, epochs=epochs, \n",
        "                                       verbose=0)\n",
        "\n",
        "    total_misclass_percentages_collected.append(allPercentages[0])\n",
        "    red_misclass_percentages_collected.append(allPercentages[1])\n",
        "    green_misclass_percentages_collected.append(allPercentages[2])\n",
        "\n",
        "    # Creating seperate columns for validation set\n",
        "    val_columns.append(f'x_i1:{i}')\n",
        "    val_columns.append(f'x_i2:{i}')\n",
        "    val_columns.append(f'l_i:{i}')\n",
        "\n",
        "    valSet_points = valSet_points.numpy()\n",
        "    valSet_labels = valSet_labels.numpy()\n",
        "\n",
        "    for j in range(length_val):\n",
        "      validation_points_collected[j,3*i + 0] = valSet_points[j, 0]\n",
        "      validation_points_collected[j,3*i + 1] = valSet_points[j, 1] \n",
        "      validation_points_collected[j,3*i + 2] = valSet_labels[j, 0] \n",
        "\n",
        "    # Creating seperarte columns for current misclassification\n",
        "    coll_columns.append(f'total:{i}')\n",
        "    coll_columns.append(f'red:{i}')\n",
        "    coll_columns.append(f'green:{i}')\n",
        "\n",
        "    misclassification_matrix[:, 3*i + 0] = allPercentages[0]\n",
        "    misclassification_matrix[:, 3*i + 1] = allPercentages[1]\n",
        "    misclassification_matrix[:, 3*i + 2] = allPercentages[2]\n",
        "\n",
        "    if verbose > 0:\n",
        "      printProgressBar(i+1, n)\n",
        "\n",
        "  \n",
        "  # Averaging\n",
        "  total_misclass_percentages_avg = np.average(total_misclass_percentages_collected, axis=0)\n",
        "  red_misclass_percentages_avg = np.average(red_misclass_percentages_collected, axis=0)\n",
        "  green_misclass_percentages_avg = np.average(green_misclass_percentages_collected, axis=0)\n",
        "\n",
        "  # PLOTTING RESULTS\n",
        "  plt.figure(figsize=(20,15))\n",
        "  plt.plot(penalties, total_misclass_percentages_avg, 'b', penalties, \n",
        "           red_misclass_percentages_avg, 'r', penalties,\n",
        "           green_misclass_percentages_avg, 'g')\n",
        "  plt.title(f'Dataset {CURRENT_SET}: Average misclassification by penalty')\n",
        "  plt.ylabel('% misclassified')\n",
        "  plt.xlabel('Penalty')\n",
        "  plt.xticks(penalties)\n",
        "  plt.legend(['total', 'red', 'green'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # SAVING DATA\n",
        "  # Save average misclassification percentages to excel\n",
        "  pd.DataFrame([total_misclass_percentages_avg, red_misclass_percentages_avg, \n",
        "                green_misclass_percentages_avg], ['total','red','green'], \n",
        "               columns=penalties).to_excel(f'averagePenaltyEffect_{CURRENT_SET}.xlsx')\n",
        "  # Save misclassification percentages collected to excel\n",
        "  pd.DataFrame(misclassification_matrix, penalties, columns=coll_columns).to_excel(f'averagePenaltyEffect_collected_{CURRENT_SET}.xlsx')\n",
        "  # Save all validation set to one '.xlsx' file\n",
        "  pd.DataFrame(validation_points_collected, columns=val_columns).to_excel(f'validationSets_{CURRENT_SET}.xlsx')\n",
        "\n",
        "  return (total_misclass_percentages_avg, red_misclass_percentages_avg,\n",
        "         green_misclass_percentages_avg)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCsy_7qMzuBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "e9a96764-a2c1-4985-9e4f-44e8324b6485"
      },
      "source": [
        "#@title Preparing data\n",
        "dataSet = getDataSet()\n",
        "dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "valSet_points, valSet_labels = seperateValidationSet(dataSet=dataSet, validationIndices=VAL_INDICES)\n",
        "\n",
        "dataSet = balanceDataset(dataSet, threshold=THRESHOLD)\n",
        "\n",
        "#Creating tensors\n",
        "training_labels = tf.constant(dataSet.pop('l_i'), tf.float32)\n",
        "training_points = tf.constant(dataSet, tf.float32)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Artificially exended by 0 points\n",
            "Relation is now: 0.47 green : 0.53 red \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N24D-gWpnFmD",
        "cellView": "form"
      },
      "source": [
        "#@title Custom Loss Function\n",
        "\n",
        "def construct_custom_penalty_loss(penalty,\n",
        "                                  lossFunction=keras.losses.sparse_categorical_crossentropy):\n",
        "  \"\"\"Constructs a loss function which penalizes 'red as green' misclassifications. \n",
        "\n",
        "  Args:\n",
        "    penalty: Expects float between 0 and 1. Value added to the loss if a red\n",
        "      point is misclassified as green. \n",
        "    lossFunction: Optional; Expects a loss function. The loss function used after\n",
        "      adapting the loss values.\n",
        "\n",
        "  Returns:\n",
        "    custom_penalty_loss function with specified penalty and loss function. Can be\n",
        "    used like a regular loss function. \n",
        "  \"\"\"\n",
        "\n",
        "  def custom_penalty_loss(y_true, y_pred):\n",
        "    length = tf.shape(y_true)[0]\n",
        "\n",
        "    #Creating a vector with all values set to the penalty: [0.3, 0.3, ... 0.3]\n",
        "    error = tf.multiply(tf.constant(penalty, tf.float32), tf.ones(length)) \n",
        "\n",
        "    #Setting every entry to 0 if the corresponding entry in y_true is 1\n",
        "    error = tf.where(tf.equal(y_true[:, 0], tf.zeros(length)), error, tf.zeros(length))\n",
        "\n",
        "    #Setting every entry to 0 if the algorithm predicted 0\n",
        "    error = tf.where(tf.greater(y_pred[:, 0], y_pred[:, 1]), tf.zeros(length), error)\n",
        "\n",
        "    #Transforms the vector from [0, 0, 0.3, ... 0,3] to [[0, -0], [0, -0], [0.3, -0.3], ... [0.3, -0.3]]\n",
        "    error = tf.stack([error, tf.multiply(tf.constant(-1, tf.float32), error)], 1)\n",
        "\n",
        "    #Adding the artificial loss\n",
        "    y_pred = y_pred + error\n",
        "\n",
        "    #Eliminating values > 1 or < 0\n",
        "    y_pred0 = tf.where(tf.greater(y_pred[:, 0], tf.ones(length)), tf.ones(length), y_pred[:, 0])\n",
        "    y_pred1 = tf.where(tf.greater(y_pred[:, 1], tf.zeros(length)), y_pred[:, 1], tf.zeros(length))\n",
        "    y_pred = tf.stack([y_pred0, y_pred1], axis=1)\n",
        "\n",
        "\n",
        "    loss = lossFunction(y_pred=y_pred, y_true=y_true)\n",
        "    return loss\n",
        "  \n",
        "  return custom_penalty_loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrxlkLjeccKz"
      },
      "source": [
        "# Configure and compile model\n",
        "initalizer = keras.initializers.GlorotNormal()\n",
        "\n",
        "model = keras.Sequential([\n",
        "          keras.layers.Flatten(input_shape=(2,)),      #input layer: 2 neurons\n",
        "          keras.layers.Dense(100,activation='relu', kernel_initializer=initalizer), \n",
        "          keras.layers.Dense(70,activation='relu', kernel_initializer=initalizer), \n",
        "          keras.layers.Dense(50,activation='relu', kernel_initializer=initalizer),       \n",
        "          keras.layers.Dense(10,activation='relu', kernel_initializer=initalizer),\n",
        "          keras.layers.Dense(2,activation='softmax', kernel_initializer=initalizer)   #output layer: 2 neurons              \n",
        "          ])\n",
        "\n",
        "model.compile(optimizer='adam', loss=construct_custom_penalty_loss(PENALTY), metrics=['accuracy'])\n",
        "\n",
        "#Save initial weights\n",
        "initialWeights = model.get_weights()\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(training_points, training_labels, batch_size=128, epochs=500,\n",
        "                    shuffle=True, validation_data=(valSet_points, valSet_labels))\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwMWzXb3CC-S",
        "outputId": "b5a3e7f5-7799-4a5a-b3ed-991a1df15213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Machine Learning Classifier')\n",
        "makeCertaintyMap(model,specific_color=1)\n",
        "print('Statistical Classifier')\n",
        "makeCertaintyMapKNN(50,accuracy=25, specific_color=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Machine Learning Classifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Statistical Classifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}