{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siemens_Approach.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericbill21/siemens/blob/master/Siemens_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njeg6hj5kBjI"
      },
      "source": [
        "#@title Imports and config\n",
        "\n",
        "# Tensorflow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython.display import clear_output\n",
        "from psutil import virtual_memory\n",
        "\n",
        "# Arithmetic Operations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "# Data visualization\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('default')\n",
        "\n",
        "# Progress calculation\n",
        "import sys\n",
        "import time\n",
        "from datetime import date\n",
        "\n",
        "# Time prediciton\n",
        "PREV_TIME = 0\n",
        "PB_START_TIME = 0\n",
        "\n",
        "# Mounting Google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd5eTUqAkBjK",
        "outputId": "8c91e64c-58ba-4bce-f553-a3e958d05142",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title GPU and RAM info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# ram_gb = virtual_memory().total / 1e9\n",
        "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "# if ram_gb < 20:\n",
        "#   print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "#   print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "#   print('re-execute this cell.')\n",
        "# else:\n",
        "#   print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRjXSfIYkBjM"
      },
      "source": [
        "#@title Global constants\n",
        "\n",
        "# Dictionaries\n",
        "COLORS = {0 : 'green', 1 : 'red', 'green' : 0, 'red' : 1}\n",
        "SOURCES = {'A' : 'https://drive.google.com/file/d/1hAzAKZNpmSclSI7HnV_cRjpMS4Kh5r1q/view?usp=sharing', 'B' : 'https://drive.google.com/file/d/12VlecL-5iYs-BFpnTOba1x65jWofBX1P/view?usp=sharing', 'C' : 'https://drive.google.com/file/d/1-Z0RuJIi1cZcqrrmV6TqT0O1PwI2OiBY/view?usp=sharing'}\n",
        "SOURCE_SIZE = {'A': 1000,'B' : 5000, 'C' : 50000}\n",
        "\n",
        "CURRENT_SET = 'A'\n",
        "\n",
        "# Balancing dataset to threshold\n",
        "THRESHOLD_DATA = 0.4\n",
        "\n",
        "# Threshold for balanced validation set\n",
        "THRESHOLD_VAL = 0.4\n",
        "\n",
        "# Random number seed\n",
        "random.seed(time.time())\n",
        "\n",
        "# Examlpe subsets of each dataset\n",
        "#subsetA = [47, 847, 993, 55, 102, 572, 430, 115, 842, 72, 770, 107, 78, 834, 593, 43, 234, 709, 210, 378]\n",
        "#subsetB = [606, 2663, 1809, 2145, 4539, 3333, 3562, 2262, 512, 2046, 1541, 909, 286, 4815, 3663, 1742, 2822, 2756, 2937, 3080, 3845, 3949, 2506, 3984, 2803, 2067]\n",
        "#subsetC = [32088, 33534, 39634, 40177, 25142, 752, 41771, 11793, 16415, 3811, 2096, 35902, 42221, 19594, 25109, 40476, 25162, 41150, 34610, 28329, 46339, 43149, 44441, 25720, 38747, 49497, 12708, 23920, 2280, 17946]\n",
        "\n",
        "subsetA = random.sample(range(1000), 150)\n",
        "subsetB = random.sample(range(5000), 800)\n",
        "subsetC = random.sample(range(50000), 8000)\n",
        "\n",
        "VAL_INDICES = locals()['subset' + CURRENT_SET]\n",
        "\n",
        "# Penalty applied to false green classifications in custom loss function\n",
        "PENALTY = 0.2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpYD2sOxkBjP"
      },
      "source": [
        "#@title Functions\n",
        "def getDataSet():\n",
        "  \"\"\"Returns the dataset currently selected by CURRENT_SET.\"\"\"\n",
        "  path = 'https://drive.google.com/uc?export=download&id='+SOURCES[CURRENT_SET].split('/')[-2]\n",
        "  return pd.read_excel(path)\n",
        "  \n",
        "\n",
        "def makePlot(dataSet = np.array([]), correct_pred_points = np.array([]),\n",
        "             incorrect_pred_points = np.array([]), figsize=(14,10)):\n",
        "  \"\"\"\"Plots green and red points and markers as scatter graph.\n",
        "  \n",
        "  Args:\n",
        "    dataSet: pandas.DataFrame, optional\n",
        "      Dataframe with columns 'x_i1', 'x_i2', 'l_i1'. Dataset to be plotted.\n",
        "      Defaults to dataset selected by CURRENT_SET.\n",
        "    correct_pred_points: 2-D list, optional \n",
        "      List of shape (x,2) containing correctly predicted points. Marked as black\n",
        "      'x' on scatter graph.\n",
        "    incorrect_pred_points: 2-D list, optional \n",
        "      List of shape (x,2) containing incorrectly predicted points. Marked as\n",
        "      black '*' on scatter graph.\n",
        "    figsize: 2-tuple of floats\n",
        "      (x,y) where x is width and y is height of figure in inches.\n",
        "  \n",
        "  Raises:\n",
        "    TypeError: If dataSet is not an instance of pd.DataFrame or the other\n",
        "      parameters do not have the required shape.\n",
        "  \"\"\"\n",
        "  # Preparing optional parameters\n",
        "  if dataSet.shape == (0,):\n",
        "    dataSet = getDataSet()\n",
        "  if isinstance(correct_pred_points, list):\n",
        "    correct_pred_points = np.array(correct_pred_points)\n",
        "  if isinstance(incorrect_pred_points, list):\n",
        "    incorrect_pred_points = np.array(incorrect_pred_points)\n",
        "\n",
        "  # Checking for the right type\n",
        "  if not isinstance(dataSet, pd.DataFrame):\n",
        "    raise TypeError(f'dataSet is of type: {type(dataSet)}, but should be ' +\n",
        "                    f'{pd.DataFrame}')\n",
        "\n",
        "  # Checking for the right shape \n",
        "  if (correct_pred_points.shape != (correct_pred_points.shape[0],2)\n",
        "      and np.array(correct_pred_points).shape != (0,)):\n",
        "    raise TypeError(f'The shape of the parameter correct_pred_points is: \\\n",
        "      {np.array(correct_pred_points).shape}, but it should be 2 dimensional')\n",
        "  \n",
        "  if (incorrect_pred_points.shape != (incorrect_pred_points.shape[0],2)\n",
        "      and np.array(incorrect_pred_points).shape != (0,)):\n",
        "    raise TypeError(f'The shape of the parameter incorrect_pred_points is: \\\n",
        "      {np.array(incorrect_pred_points).shape}, but it should be 2 dimensional')\n",
        "  \n",
        "  # Creating a subplot\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "  # Scattering all points\n",
        "  x = dataSet['x_i1']\n",
        "  y = dataSet['x_i2']\n",
        "  c = [COLORS[i] for i in dataSet['l_i']] \n",
        "\n",
        "  ax.scatter(x, y, c=c)\n",
        "\n",
        "  # Adding markers to the specified points\n",
        "  if correct_pred_points.shape[0] > 0:\n",
        "    ax.scatter(correct_pred_points[:, 0], correct_pred_points[:, 1],\n",
        "              marker = \"x\", c = 'black', label='correct')\n",
        "  if incorrect_pred_points.shape[0] > 0:\n",
        "    ax.scatter(incorrect_pred_points[:, 0], incorrect_pred_points[:, 1],\n",
        "            marker = \"*\", c = 'black', label='incorrect')\n",
        "\n",
        "  if correct_pred_points.shape[0] > 0 or incorrect_pred_points.shape[0] > 0:\n",
        "    plt.legend()\n",
        "\n",
        "  # Setting parameters for ploting\n",
        "  plt.xlabel('x_i1')\n",
        "  plt.ylabel('x_i2')\n",
        "  plt.title(f'DataSet {CURRENT_SET}')\n",
        "  plt.axis('scaled')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def seperateValidationSet(dataSet, validationIndices):\n",
        "  \"\"\"Formats a subset of points from a dataset as validation points.\n",
        "\n",
        "  Validation points are extracted and deleted from dataSet to be used for\n",
        "  validation later on.\n",
        "\n",
        "  Args:\n",
        "    dataSet: pandas.DataFrame, optional\n",
        "      Dataframe with columns 'x_i1', 'x_i2', 'l_i1'. Dataset which the\n",
        "      validation points are extracted from.\n",
        "    validationIndices: 1-D list of ints\n",
        "      The elements corresponding to these indices are extracted from dataSet.\n",
        "\n",
        "  Returns: 2-tuple of the form (valSet_points, valSet_labels), where valSet_points\n",
        "    is a tensor of shape (x,2) and valSet_labels is a tensor of shape (x,1).\n",
        "  \"\"\"\n",
        "  # Checking for the right type\n",
        "  if not isinstance(dataSet, pd.DataFrame):\n",
        "    raise TypeError(f'dataSet is of type: {type(dataSet)}, but should be \\\n",
        "      {pd.DataFrame}')\n",
        "\n",
        "  # Checking for the right shape \n",
        "  if len(np.array(validationIndices).shape) != 1:\n",
        "    raise TypeError(f'The shape of the parameter validationIndices is: \\\n",
        "      {np.array(validationIndices).shape}, but it should be 1 dimensional')\n",
        "  \n",
        "  valSet_points = dataSet[['x_i1','x_i2']].loc[validationIndices]\n",
        "  valSet_labels = dataSet['l_i'].loc[validationIndices]\n",
        "  \n",
        "  # Saving the validation points\n",
        "  valSet_points = np.array(valSet_points)\n",
        "  valSet_labels = np.array(valSet_labels).astype('float')\n",
        "\n",
        "  # Removing the validation point\n",
        "  dataSet.drop(index=validationIndices, inplace=True)\n",
        "  dataSet.reset_index(inplace=True)\n",
        "\n",
        "  return (valSet_points, valSet_labels)\n",
        "\n",
        "\n",
        "\n",
        "def printProgressBar(iteration, total, prefix = '', suffix = '', decimals = 1,\n",
        "                     length = 100, fill = '█'):\n",
        "  \"\"\"Prints a progress bar.\n",
        "\n",
        "  Args:\n",
        "    iteration: int\n",
        "      Current progress step as. (iteration/total progress).\n",
        "    total: int\n",
        "      Total progress steps until completion.\n",
        "    prefix: str, optional\n",
        "      Printed infront of the progress bar.\n",
        "    suffix: str, optional\n",
        "      Printed behind ETA.\n",
        "    decimals: int, optional\n",
        "      Number of decimal places of percentage progress.\n",
        "    length: int, optional\n",
        "      Length of the progress bar in characters.\n",
        "    fill: char, optional\n",
        "      Filler of the progress bar.\n",
        "  \"\"\"\n",
        "  # Preparing strings\n",
        "  percentage_progress = (100*(iteration/float(total)))\n",
        "  percent = (\"{0:.\" + str(decimals) + \"f}\").format(percentage_progress)\n",
        "  filledLength = int(length * iteration // total)\n",
        "  bar = fill * filledLength + '-' * (length - filledLength)\n",
        "\n",
        "  # Bob's alternative time calculation\n",
        "  if iteration == 0:\n",
        "    global PB_START_TIME\n",
        "    PB_START_TIME = time.time()\n",
        "    time_so_far = 0\n",
        "    time_remaining = 0\n",
        "  else:\n",
        "    time_so_far = time.time() - PB_START_TIME\n",
        "    time_remaining = time_so_far/percentage_progress * (100-percentage_progress)\n",
        "\n",
        "  sys.stdout.write(f'\\r{prefix} |{bar}| {percent}% | ETA: {round((time_remaining/60), 2)} minutes | {suffix}')\n",
        "  sys.stdout.flush()\n",
        "\n",
        "  # Erease progress bar on complete\n",
        "  if iteration == total:\n",
        "    global PREV_TIME\n",
        "    PREV_TIME = 0\n",
        "    sys.stdout.write('\\r')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "\n",
        "def makeCertaintyMap(model, accuracy = 100, specific_color = None):\n",
        "  \"\"\"Visualizes the prediction certainty of the model for a grid of data points.\n",
        "\n",
        "  All data points have x and y values between 0 and 1. \n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      The model who's certainty is to be visualized.\n",
        "    accuracy: int, optional\n",
        "      Data points are spaced 1/accuracy apart along the x and y axis. The grid\n",
        "      of data points plotted has the dimension accuracy*accuracy.\n",
        "    specific_color:0 or 1, optional\n",
        "      If 0, plots the model's certainty that a data point is green for all\n",
        "      points in the grid. If 1, analogously for red. \n",
        "\n",
        "  Raises:\n",
        "    TypeError: If specific_color is not 'None', '0' or '1', or if accuracy is not\n",
        "      an int.\n",
        "  \"\"\"\n",
        "  # Exceptions\n",
        "  if specific_color != None:\n",
        "    if specific_color != 0 and specific_color != 1:\n",
        "      raise TypeError(f'Invalid value for specific_color. Value is {specific_color}, \\\n",
        "        but should be \"None\", \"0\" or \"1\".')\n",
        "\n",
        "  if not isinstance(accuracy, int):\n",
        "    raise TypeError(f'Invalid type for accuracy. Type is {type(accuracy)}, but \\\n",
        "      should be int.')\n",
        "\n",
        "  accuracy_map = np.zeros((accuracy, accuracy))\n",
        "\n",
        "  for i in range(accuracy):\n",
        "    array = np.array([[j/accuracy, i/accuracy] for j in range(accuracy)])\n",
        "    result = model.predict(array)\n",
        "\n",
        "    if specific_color != None:\n",
        "      # Saving the prediction for the specified color\n",
        "      accuracy_map[i] = result[:, specific_color]\n",
        "    \n",
        "    else:\n",
        "      result = result.max(axis=1) #Getting each max value\n",
        "\n",
        "      #Normalize the values which are between 0.5 <-> 1 to 0 <-> 1\n",
        "      normalized = (result-0.5)/0.5\n",
        "      accuracy_map[i] = normalized\n",
        "  \n",
        "    # Print current progress\n",
        "    printProgressBar(i, accuracy-1)\n",
        "\n",
        "  if specific_color != None:\n",
        "    plt.title(f'Certaintiy for {COLORS[specific_color]}')\n",
        "  else:\n",
        "    plt.title(f'General Certainty')\n",
        "\n",
        "  plt.imshow(accuracy_map, origin='lower', cmap='tab20b', vmin=0, vmax=1)\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "  return accuracy_map\n",
        "\n",
        "\n",
        "\n",
        "def timeCalc():\n",
        "  \"\"\"Calculates time between previous call and current call.\n",
        "\n",
        "  Returns:\n",
        "    Time difference in minutes as float.\n",
        "  \"\"\"\n",
        "  global PREV_TIME\n",
        "  if PREV_TIME == 0:\n",
        "    PREV_TIME = time.time()\n",
        "    return 0\n",
        "  \n",
        "  res = (time.time() - PREV_TIME) / 60\n",
        "  PREV_TIME = time.time()\n",
        "  return res\n",
        "\n",
        "\n",
        "\n",
        "def plotLoss(history):\n",
        "  \"\"\"Plots training loss and validation loss with respect to training epochs.\n",
        "\n",
        "  Args:\n",
        "    history: keras History\n",
        "      history of keras model.\n",
        "  \"\"\"\n",
        "  if 'val_loss' in history.history:\n",
        "    plt.plot(history.history['val_loss'])\n",
        "\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def showPredicitons(model, history, valSet_points,\n",
        "                    valSet_labels, showCorrectPoints=False):\n",
        "  \"\"\"Visualizes the predictions for the validation points.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model which performs the predictions.\n",
        "    history: keras History\n",
        "      history of keras model.\n",
        "    valSet_points: 2-D array of shape (x,2)\n",
        "      Data points used for validation.\n",
        "    valSet_labels: 1-D array of shape (x,)\n",
        "      Ground truth labels of the validation points.\n",
        "    showCorrectPoints: boolean, optional\n",
        "      Whether correctly classified points should be marked as black 'x' or not.\n",
        "\n",
        "  Returns:\n",
        "    2-dimensional numpy array of shape (x,2) with the predictions for the\n",
        "    validation points.\n",
        "  \"\"\"\n",
        "  # Predict the validation points\n",
        "  prediction = model.predict(valSet_points)\n",
        "\n",
        "  # Identifying correctly and incorrectly classified points\n",
        "  correct_indices = np.where((valSet_labels == np.argmax(prediction, axis=1)) == True)\n",
        "  incorrect_indices = np.where((valSet_labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "  number_of_points = np.bincount(np.argmax(prediction, axis=1))\n",
        "\n",
        "  total_misclassifications = np.bincount(valSet_labels == np.argmax(prediction, axis=1))[0]\n",
        "  red_misclassifications = len(np.where(valSet_labels[incorrect_indices] == 1)[0])\n",
        "  green_misclassifications = len(np.where(valSet_labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "  #Average misclassification certainty\n",
        "  misclass_certainties = []\n",
        "  for i in incorrect_indices[0]:\n",
        "    misclass_certainties.append(np.max(prediction[i]))\n",
        "  avg_misclass_certainty = sum(misclass_certainties)/total_misclassifications\n",
        "  \n",
        "  print('Validation accuracy: {:.2f}%'.format((history.history['val_accuracy'])[-1]*100))\n",
        "  print(f'Predictions for green: {number_of_points[0]} / {len(valSet_labels)}')\n",
        "  print(f'Predictions for red: {number_of_points[1]} / {len(valSet_labels)}')\n",
        "  print(f'Points misclassified: {total_misclassifications}')\n",
        "  print(f'Red points misclassified: {red_misclassifications}')\n",
        "  print(f'Green points misclassified: {green_misclassifications}')\n",
        "  print('Average misclassification certainty: {:.2f}'.format(avg_misclass_certainty))\n",
        "\n",
        "  if showCorrectPoints:\n",
        "    makePlot(correct_pred_points=valSet_points[correct_indices],\n",
        "           incorrect_pred_points=valSet_points[incorrect_indices])\n",
        "  else:\n",
        "    makePlot(incorrect_pred_points=valSet_points[incorrect_indices])\n",
        "    \n",
        "  # Make bar graph showing red and green misclassifications\n",
        "  bars = ('Red', 'Green')\n",
        "  height = [red_misclassifications, green_misclassifications]\n",
        "  x_pos = np.arange(len(bars))\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.bar(x_pos, height, width=0.35, color=['red', 'green'])\n",
        "\n",
        "  ax.set_ylabel('Misclassifications')\n",
        "  ax.set_title('Misclassifications by color')\n",
        "  ax.set_xticks(x_pos)\n",
        "  ax.set_xticklabels(bars)\n",
        "\n",
        "  rects = ax.patches # Array of bars\n",
        "\n",
        "  labels = [red_misclassifications, green_misclassifications]\n",
        "\n",
        "  for rect, label in zip(rects, labels): # Add labels above bars\n",
        "      height = rect.get_height()\n",
        "      ax.text(rect.get_x() + rect.get_width() / 2, height, label,\n",
        "              ha='center', va='bottom')\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "  return prediction\n",
        "\n",
        "  \n",
        "\n",
        "def balanceDataset(dataSet, threshold, verbose=1):\n",
        "  \"\"\"Artificially balances dataSet by duplicating red or green points.\n",
        "\n",
        "  Args: \n",
        "    dataSet: pandas.DataFrame, optional\n",
        "      Dataframe with columns 'x_i1', 'x_i2', 'l_i1'. The datset to be balanced.\n",
        "    threshold: float between 0 and 0.5\n",
        "      The function duplicates red or green points until the fraction of points\n",
        "      of the less frequent color is at least equal to the threshold.\n",
        "\n",
        "  Returns:\n",
        "    pandas.DataFrame with columns 'x_i1', 'x_i2', 'l_i1'.\n",
        "  \"\"\"\n",
        "  total_number_of_points = dataSet.shape[0]\n",
        "  number_of_green_points = dataSet.loc[dataSet[\"l_i\"] == 0].shape[0]\n",
        "  number_of_red_points = dataSet.loc[dataSet[\"l_i\"] == 1].shape[0]\n",
        "\n",
        "  amount = 0\n",
        "\n",
        "  if number_of_red_points / total_number_of_points < threshold:\n",
        "    amount = int( (threshold * total_number_of_points - number_of_red_points) // (1 - threshold) )\n",
        "    red_points = dataSet.loc[dataSet['l_i'] == 1] #Getting all red points\n",
        "    chosen_points = red_points.sample(amount, replace=True) #Selecting a random subset of red points\n",
        "    dataSet = dataSet.append(chosen_points, ignore_index=True) #appending the subset\n",
        "\n",
        "  if number_of_green_points / total_number_of_points < threshold:\n",
        "    amount = int( (threshold * total_number_of_points - number_of_green_points) // (1 - threshold) )\n",
        "    green_points = dataSet.loc[dataSet['l_i'] == 0] #Getting all green points\n",
        "    chosen_points = green_points.sample(amount, replace=True) #Selecting a random subset of green points\n",
        "    dataSet = dataSet.append(chosen_points, ignore_index=True) #appending green subset\n",
        "\n",
        "  dataSet = dataSet[['x_i1','x_i2','l_i']]\n",
        "\n",
        "  total_number_of_points = dataSet.shape[0]\n",
        "  number_of_green_points = dataSet.loc[dataSet[\"l_i\"] == 0].shape[0]\n",
        "  number_of_red_points = dataSet.loc[dataSet[\"l_i\"] == 1].shape[0]\n",
        "\n",
        "  if verbose > 0:\n",
        "    print(f'Artificially exended by {amount} points')\n",
        "    print(f'Relation is now: {round(number_of_green_points / total_number_of_points, 2)}',\n",
        "            f'green : {round(number_of_red_points / total_number_of_points, 2)} red ')\n",
        "  \n",
        "  return dataSet\n",
        "\n",
        "\n",
        "\n",
        "def calculatePenaltyEffect(model, x, y, validation_data, interval=(0,1), accuracy=10, \n",
        "                      batch_size=32, epochs=200, verbose=0):\n",
        "  \"\"\"Calculates red, green, and total misclassifications in relation to penalty.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model for which the penalty effect is measured.\n",
        "    x: tensor of shape (x,2) and type tf.float32\n",
        "      Training points.\n",
        "    y: tensor of shape (x,1) and type float32\n",
        "      Training labels.\n",
        "    validation_data: 2-tuple\n",
        "      (valSet_points, valSet_labels) where valSet_points is a tensor of shape\n",
        "      (x,2) and type tf.float32 and valSet_labels tensor of shape (x,1) and type\n",
        "      tf.float32. Validation points and labels.\n",
        "    interval: 2-tuple, optional\n",
        "      (x,y) which defines the penalty interval plotted. x is the lowest penalty,\n",
        "      y the highest.\n",
        "    accuracy: int, optional\n",
        "      Penalty interval is evenly split into 'accuracy' many points.\n",
        "    verbose: boolean, optional\n",
        "      Whether to print progress bar and plot results or not. \n",
        "    All others: optional\n",
        "      See tf.keras.Model.\n",
        "\n",
        "  Returns:\n",
        "    3-tuple of int lists (total_misclass_percentage, red_misclass_percentage, \n",
        "    green_misclass_percentage).\n",
        "  \"\"\"\n",
        "  total_misclass_percentages = []\n",
        "  red_misclass_percentages = []\n",
        "  green_misclass_percentages = []\n",
        "  penalties = np.zeros(accuracy + 1)\n",
        "  increments = (interval[1]-interval[0])/accuracy\n",
        "\n",
        "  points = validation_data[0]\n",
        "  labels = validation_data[1].astype(int)\n",
        "\n",
        "  number_of_points = len(labels)\n",
        "  red_points = len(np.where(labels==1)[0])\n",
        "  green_points = len(np.where(labels==0)[0])\n",
        "\n",
        "  if verbose > 0:\n",
        "    printProgressBar(0, accuracy+1)\n",
        "\n",
        "  # MAIN LOOP\n",
        "  for i in range(accuracy+1):\n",
        "    penalty = interval[0] + (interval[1]-interval[0])*(i/accuracy)\n",
        "    model.set_weights(initialWeights)\n",
        "\n",
        "    model.compile(optimizer='adam', loss=construct_custom_penalty_loss(penalty),\n",
        "                  metrics=['accuracy']) # Compile model with penalty\n",
        "\n",
        "    history = model.fit(x, y, batch_size, epochs, verbose=0,\n",
        "                        validation_data=validation_data)\n",
        "\n",
        "    prediction = model.predict(validation_data[0])\n",
        "\n",
        "    correct_indices = np.where((labels == np.argmax(prediction, axis=1)) == True)\n",
        "    incorrect_indices = np.where((labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "    total_misclassifications = np.bincount(labels == np.argmax(prediction, axis=1))[0]\n",
        "    red_misclassifications = len(np.where(labels[incorrect_indices] == 1)[0])\n",
        "    green_misclassifications = len(np.where(labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "    total_misclass_percentages.append((total_misclassifications/number_of_points)*100)\n",
        "    red_misclass_percentages.append((red_misclassifications/red_points)*100)\n",
        "    green_misclass_percentages.append((green_misclassifications/green_points)*100)\n",
        "\n",
        "    penalties[i] = penalty\n",
        "    \n",
        "    if verbose > 0:\n",
        "      printProgressBar(i+1, iterations+1)\n",
        "\n",
        "  # PLOTTING RESULTS\n",
        "  if verbose > 0:\n",
        "    plt.figure(figsize=(20,15))\n",
        "    plt.plot(penalties, total_misclass_percentages, 'b', penalties, \n",
        "              red_misclass_percentages, 'r', penalties, green_misclass_percentages,\n",
        "              'g')\n",
        "    plt.title(f'Dataset {CURRENT_SET}: Misclassification by penalty')\n",
        "    plt.ylabel('% misclassified')\n",
        "    plt.xlabel('Penalty')\n",
        "    plt.xticks(np.arange(interval[0], interval[1]+increments, increments))\n",
        "    plt.legend(['total', 'red', 'green'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "  return (total_misclass_percentages, red_misclass_percentages,\n",
        "         green_misclass_percentages)\n",
        "\n",
        "\n",
        "\n",
        "def KNN(dataSet, point, k, significance=0.1, increment=0.05, show_plot=True):\n",
        "  \"\"\" K-nearest neighbor classifier.\n",
        "\n",
        "  Statistical classifier. Uses the k nearest neighbors to predict the color of a\n",
        "  given point by comparing the number of neighbours of each color and weigthing\n",
        "  them with their squared distance to the point.\n",
        "\n",
        "  Args:\n",
        "    dataSet: pandas.DataFrame, optional\n",
        "      Dataframe with columns 'x_i1', 'x_i2', 'l_i1'. Dataset to be used for\n",
        "      calculation. Defaults to dataset selected by CURRENT_SET.\n",
        "    point: Array in the form of [x_i1, x_i2]\n",
        "    k: Positive int\n",
        "      Number of neighbours taken into account for classification\n",
        "    significance: float between 0 and 1, optional\n",
        "      Start search radius.\n",
        "    increment: float between 0 and 1, optional\n",
        "      Amount of increment of the search radius while gathering k neighbours.\n",
        "    show_plot: boolean, optional\n",
        "      If 'True' the function plots the dataset and the selected neighbours.\n",
        "\n",
        "  Returns:\n",
        "    A 2-tuple with the predictions for each class. \n",
        "    (prediction_green, prediction_red)\n",
        "  \"\"\"\n",
        "  # Gathering points until at least k neighbours are found \n",
        "  neighb = np.array([])\n",
        "  while significance <= 1 and neighb.shape[0] < k:\n",
        "      neighb = dataSet.loc[(dataSet['x_i1'] - point[0])**2 +\n",
        "                           (dataSet['x_i2'] -point[1])**2 <= significance**2]\n",
        "      significance += increment\n",
        "  \n",
        "  # Reindexing\n",
        "  neighb = neighb.reset_index()\n",
        "\n",
        "  # Calculating the distances of each neighbour to the target point\n",
        "  dist = np.zeros(neighb.shape[0])\n",
        "  for i in range(neighb.shape[0]):\n",
        "    dist[i] = (neighb['x_i1'].loc[i] - point[0])**2 + (neighb['x_i2'].loc[i] -\n",
        "                                                       point[1])**2\n",
        "\n",
        "  # Removing all overhang neighbours until there are only k\n",
        "  while neighb.shape[0] > k:\n",
        "    neighb = neighb.drop(np.argmax(dist))\n",
        "    dist[np.argmax(dist)] = -1\n",
        "\n",
        "  # Reindexing\n",
        "  dist = np.zeros(neighb.shape[0])\n",
        "  neighb = neighb.reset_index()\n",
        "\n",
        "  # Calculating the distances of each neighbour to the target point\n",
        "  for i in range(neighb.shape[0]):\n",
        "    dist[i] = (neighb['x_i1'].loc[i] - point[0])**2 + (neighb['x_i2'].loc[i] -\n",
        "                                                       point[1])**2\n",
        "\n",
        "\n",
        "  pred_g = 0\n",
        "  pred_r = 0\n",
        "\n",
        "  # Sum the neighbours of each color with the weight 1-dist^2 \n",
        "  for i in range(neighb.shape[0]):\n",
        "    if neighb['l_i'].loc[i] == 0:\n",
        "      pred_g += (1 - dist[i])\n",
        "    elif neighb['l_i'].loc[i] == 1:\n",
        "      pred_r += (1 - dist[i])\n",
        "\n",
        "  # Normalize\n",
        "  sum = pred_g + pred_r\n",
        "  pred_g = pred_g // sum\n",
        "  pred_r = pred_r // sum\n",
        "\n",
        "  # Plot neighbours \n",
        "  if show_plot:\n",
        "    selected_neighb = [[neighb['x_i1'].loc[i], neighb['x_i2'].loc[i]]\n",
        "                       for i in range(neighb.shape[0])]\n",
        "    makePlot(dataSet, [point], selected_neighb)\n",
        "    print(f'Prediction for green: \\t{pred_g}')\n",
        "    print(f'Prediction for red: \\t{pred_r}')\n",
        "\n",
        "  return (pred_g, pred_r)\n",
        "\n",
        "\n",
        "\n",
        "def makeCertaintyMapKNN(k, accuracy = 100, specific_color = None):\n",
        "  \"\"\"Visualizes the prediction certainty of K-nearest-neighbour algorithm for a grid of data points.\n",
        "\n",
        "  All data points have x and y values between 0 and 1. \n",
        "\n",
        "  Args:\n",
        "    k: postive int\n",
        "      The number of neighbours specified for the KNN algorithm who's certainty\n",
        "      is to bevisualized.\n",
        "    accuracy: positive int, optional\n",
        "      Data points are spaced 1/accuracy apart along the x and y axis. The grid \n",
        "      of data points plotted has the dimension accuracy*accuracy.\n",
        "    specific_color: 0 or 1, optional\n",
        "      If 0, plots the model's certainty that a data point is green for all\n",
        "      points in the grid. If 1, analogously for red. \n",
        "\n",
        "  Raises:\n",
        "    TypeError: If specific_color is not 'None', '0' or '1', or if accuracy and k\n",
        "    is not an int.\n",
        "  \"\"\"\n",
        "  #Exceptions\n",
        "  if specific_color != None:\n",
        "    if specific_color != 0 and specific_color != 1:\n",
        "      raise TypeError(f'Invalid value for specific_color. Value is {specific_color}, \\\n",
        "        but should be \"None\", \"0\" or \"1\".')\n",
        "\n",
        "  if not isinstance(accuracy, int):\n",
        "    raise TypeError(f'Invalid type for accuracy. Type is {type(accuracy)}, but \\\n",
        "      should be int.')\n",
        "    \n",
        "  if not isinstance(k, int):\n",
        "    raise TypeError(f'Invalid type for k. Type is {type(k)}, but \\\n",
        "      should be int.')\n",
        "\n",
        "  # Init Data\n",
        "  dataSet = getDataSet()\n",
        "  accuracy_map = np.zeros((accuracy, accuracy))\n",
        "\n",
        "  # Main Loop\n",
        "  for i in range(accuracy):\n",
        "    for j in range(accuracy):\n",
        "      result = KNN(dataSet, [j/accuracy, i/accuracy], k, show_plot=False)\n",
        "\n",
        "      if specific_color != None:\n",
        "        # Saving the prediction for the specified color\n",
        "        accuracy_map[i,j] = result[specific_color]\n",
        "      else:\n",
        "        result = np.max(result)\n",
        "\n",
        "        #Normalize the values which are between 0.5 <-> 1 to 0 <-> 1\n",
        "        normalized = (result-0.5)/0.5\n",
        "        accuracy_map[i,j] = normalized\n",
        "    \n",
        "      # Print current progress\n",
        "      printProgressBar((j+1) + i*accuracy, accuracy**2)\n",
        "\n",
        "  # Choosing headline\n",
        "  if specific_color != None:\n",
        "    plt.title(f'Certaintiy for {COLORS[specific_color]}')\n",
        "  else:\n",
        "    plt.title(f'General Certainty')\n",
        "\n",
        "  # Plot\n",
        "  plt.imshow(accuracy_map, origin='lower', cmap='tab20b', vmin=0, vmax=1)\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "  \n",
        "  return accuracy_map\n",
        "\n",
        "\n",
        "\n",
        "def makeDensityMap(dataSet=None, significance=0.1,\n",
        "                   cmap=plt.cm.get_cmap('Spectral'), specific_color = None):\n",
        "  \"\"\"Creates a headmap of the density of the current selected dataSet.\n",
        "\n",
        "    Args:\n",
        "      dataSet: pandas.DataFrame, optional\n",
        "        Dataframe with columns 'x_i1', 'x_i2', 'l_i1'. Dataset to be used for\n",
        "        calculation. Defaults to dataset selected by CURRENT_SET.\n",
        "      signifcance: float between 0 and 1, optional\n",
        "        Determines the radius by which neighbours are being counted for the \n",
        "        density of a particular point.\n",
        "      cmap: matplotlib colormap, optional\n",
        "        Is used for color coding the density of the dataset at the end.\n",
        "      specific_color: 0 or 1, optional\n",
        "        If 0, a heatmap of only green points is computed. If 1, analogously for\n",
        "        red.\n",
        "  \"\"\"\n",
        "  if specific_color != None:\n",
        "    dataSet = dataSet.loc[dataSet['l_i'] == specific_color]\n",
        "    dataSet.reset_index(inplace=True)\n",
        "\n",
        "  total_number_of_points = dataSet.shape[0]\n",
        "  array = np.zeros((total_number_of_points, 3))\n",
        "\n",
        "  # Counting all neighbours within a radius of significance\n",
        "  for i in range(total_number_of_points):\n",
        "    count = dataSet.loc[(dataSet['x_i1'] - dataSet['x_i1'].loc[i])**2 +\n",
        "     (dataSet['x_i2'] - dataSet['x_i2'].loc[i])**2 <= significance**2]\n",
        "\n",
        "    array[i, 0] = dataSet['x_i1'].loc[i]\n",
        "    array[i, 1] = dataSet['x_i2'].loc[i]\n",
        "    array[i, 2] = len(count)\n",
        "\n",
        "    printProgressBar(i+1, total_number_of_points)\n",
        "\n",
        "  print(f'Max: {np.max(array[:,2])}')\n",
        "  print(f'Min: {np.min(array[:,2])}')\n",
        "\n",
        "  # Used for the normalization\n",
        "  norm = plt.Normalize(vmin=np.min(array[:,2]),vmax=np.max(array[:,2]))\n",
        "\n",
        "  # Setting parameters for ploting\n",
        "  plt.scatter(array[:, 0], array[:, 1], c=array[:, 2], cmap=cmap, norm=norm)\n",
        "  plt.colorbar()\n",
        "  plt.xlabel('x_i1')\n",
        "  plt.ylabel('x_i2')\n",
        "  plt.title(f'Density of DataSet {CURRENT_SET}')\n",
        "  plt.axis('scaled')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def getBalancedValSetIndices(dataSet, size, threshold):\n",
        "  \"\"\"Get indices of validation points such that neither color represents\n",
        "    less than (threshold*100)% of the validation set.\n",
        "\n",
        "  Args:\n",
        "    dataSet: pandas.DataFrame\n",
        "      Dataframe with columns 'x_i1', 'x_i2', 'l_i1'. Dataset from\n",
        "      which the validation points are to be chosen.\n",
        "    size: int\n",
        "      Size of the validation set.\n",
        "    threshold: float between 0 and 1\n",
        "      Fraction of validation points which each color must at least\n",
        "      represent.\n",
        "\n",
        "  Returns:\n",
        "    1-D array of ints (indices).\n",
        "  \"\"\"\n",
        "  random.seed(time.time())\n",
        "\n",
        "  # Amount of points for each color\n",
        "  amount_g = int(random.randint(size*threshold, size*(1-threshold)))\n",
        "  amount_r = size - amount_g\n",
        "\n",
        "  # Indices of each points with the specific color\n",
        "  indices_g = np.where(dataSet['l_i'] == 0)[0]\n",
        "  indices_r = np.where(dataSet['l_i'] == 1)[0]\n",
        "\n",
        "  # Check if possible \n",
        "  if indices_g.shape[0] + indices_r.shape[0] < size:\n",
        "    raise ValueError('The requested size of the validation set is not feasible')\n",
        "\n",
        "  if indices_r.shape[0] < amount_r:\n",
        "    indices_g += amount_r - indces_r.shape[0]\n",
        "\n",
        "  if indices_g.shape[0] < amount_g:\n",
        "    indices_r += amount_g - indces_g.shape[0]\n",
        "  \n",
        "  # Randomly selceting a subset for each color\n",
        "  indices_g = np.random.choice(indices_g, amount_g)\n",
        "  indices_r = np.random.choice(indices_r, amount_r)\n",
        "\n",
        "  # Concatenate and shuffle the chosen subsets\n",
        "  indices = np.concatenate([indices_g, indices_r])\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "  return indices"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOv1fe0BkBjr"
      },
      "source": [
        "#@title Average Penalty Effect\n",
        "def averagePenaltyEffect(model, n, valSet_size, path='', interval=(0,1),\n",
        "                         accuracy=10, batch_size=32, epochs=200, verbose=1):\n",
        "  \"\"\"Plots average penalty effect over n iterations.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model for which the penalty effect is measured.\n",
        "    n: int\n",
        "      Number of iterations the penalty effect is measured and averaged over.\n",
        "    valSet_size: int\n",
        "      Size of the validation set.\n",
        "    path: str, optional\n",
        "      Path to which the excel sheet will be saved. e.g. '/content/drive/MyDrive/'\n",
        "    verbose: boolean, optional\n",
        "      Whether to print progress bar or not.\n",
        "    All others:\n",
        "      See calculatePenaltyEffect.\n",
        "\n",
        "  Returns:\n",
        "    3-tuple of np arrays (total_misclass_percentages_avg,\n",
        "    red_misclass_percentages_avg, green_misclass_percentages_avg).\n",
        "  \"\"\"\n",
        "  #Start time\n",
        "  start_time = time.time()\n",
        "\n",
        "  penalties = np.arange(interval[0], interval[1]+(interval[1]-interval[0])/accuracy,\n",
        "                        (interval[1]-interval[0])/accuracy)\n",
        "\n",
        "  # INITIALIZATION OF DATA COLLECTION OBJECTS\n",
        "  # For averaging\n",
        "  total_misclass_percentages_collected = []\n",
        "  red_misclass_percentages_collected = []\n",
        "  green_misclass_percentages_collected = []\n",
        "  # For saving in excel\n",
        "  validation_points_collected = np.zeros((valSet_size, 3*n))\n",
        "  misclassification_matrix = np.zeros((len(penalties), 3*n))\n",
        "  # Column names\n",
        "  val_columns = []\n",
        "  coll_columns = []\n",
        "\n",
        "  # Initialize progress bar\n",
        "  if verbose > 0:\n",
        "    printProgressBar(0, n)\n",
        "\n",
        "  # MAIN LOOP\n",
        "  for i in range(n):\n",
        "    # PREPARING DATA\n",
        "    dataSet = getDataSet()\n",
        "    dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "    # Choose random validation set\n",
        "    val_indices = getBalancedValSetIndices(dataSet, valSet_size, THRESHOLD_VAL)\n",
        "\n",
        "    valSet_points, valSet_labels = seperateValidationSet(dataSet=dataSet,\n",
        "                                            validationIndices=val_indices)\n",
        "    dataSet = balanceDataset(dataSet, threshold=THRESHOLD_DATA, verbose=0)\n",
        "\n",
        "    training_labels = np.array(dataSet['l_i']).astype('float')\n",
        "    training_points = np.array(dataSet[['x_i1','x_i2']])\n",
        "\n",
        "    # Collecting misclassification percentages\n",
        "    allPercentages = calculatePenaltyEffect(model, training_points, training_labels,\n",
        "                                            (valSet_points, valSet_labels),\n",
        "                                            interval=interval, accuracy=accuracy,\n",
        "                                            batch_size=batch_size, epochs=epochs, \n",
        "                                            verbose=0)\n",
        "\n",
        "    total_misclass_percentages_collected.append(allPercentages[0])\n",
        "    red_misclass_percentages_collected.append(allPercentages[1])\n",
        "    green_misclass_percentages_collected.append(allPercentages[2])\n",
        "\n",
        "    # Creating seperate columns for validation set\n",
        "    val_columns.append(f'x_i1:{i}')\n",
        "    val_columns.append(f'x_i2:{i}')\n",
        "    val_columns.append(f'l_i:{i}')\n",
        "\n",
        "    for j in range(valSet_size):\n",
        "      validation_points_collected[j,3*i + 0] = valSet_points[j, 0]\n",
        "      validation_points_collected[j,3*i + 1] = valSet_points[j, 1] \n",
        "      validation_points_collected[j,3*i + 2] = valSet_labels[j] \n",
        "\n",
        "    # Creating seperarte columns for current misclassification\n",
        "    coll_columns.append(f'total:{i}')\n",
        "    coll_columns.append(f'red:{i}')\n",
        "    coll_columns.append(f'green:{i}')\n",
        "\n",
        "    misclassification_matrix[:, 3*i + 0] = allPercentages[0]\n",
        "    misclassification_matrix[:, 3*i + 1] = allPercentages[1]\n",
        "    misclassification_matrix[:, 3*i + 2] = allPercentages[2]\n",
        "\n",
        "    if verbose > 0:\n",
        "      printProgressBar(i+1, n)\n",
        "\n",
        "  # Averaging\n",
        "  total_misclass_percentages_avg = np.average(total_misclass_percentages_collected, axis=0)\n",
        "  red_misclass_percentages_avg = np.average(red_misclass_percentages_collected, axis=0)\n",
        "  green_misclass_percentages_avg = np.average(green_misclass_percentages_collected, axis=0)\n",
        "\n",
        "  result = (total_misclass_percentages_avg, red_misclass_percentages_avg,\n",
        "         green_misclass_percentages_avg)\n",
        "\n",
        "  # PLOTTING RESULTS\n",
        "  plotPenaltyEffect(model, data=result, interval=interval, accuracy=accuracy, n=n, \n",
        "                    valSet_size=valSet_size, batch_size=batch_size, epochs=epochs,\n",
        "                    path=path)\n",
        "\n",
        "  # Print time taken for calculation\n",
        "  end_time = time.time()\n",
        "  total_time = (end_time-start_time)/60\n",
        "  print(f'Time taken: {round(total_time, 2)} minutes.')\n",
        "\n",
        "  # Save results to excel\n",
        "  today = date.today()\n",
        "\n",
        "  writer = pd.ExcelWriter(f'{path}Penalty_Data_{CURRENT_SET}_{model.name}_' +\n",
        "                          f'{today.strftime(\"%d-%m-%Y\")}.xlsx')\n",
        "  \n",
        "  # Average misclass percentages\n",
        "  pd.DataFrame([total_misclass_percentages_avg, red_misclass_percentages_avg, \n",
        "                green_misclass_percentages_avg], ['total','red','green'], \n",
        "               columns=penalties).to_excel(writer, sheet_name=f'Average')\n",
        "\n",
        "  # Misclass percentages collected\n",
        "  pd.DataFrame(misclassification_matrix, penalties,\n",
        "               columns=coll_columns).to_excel(writer, sheet_name=f'Collected')\n",
        "\n",
        "  # Parameters\n",
        "  data = {'Values':[f'{model.name}', f'{CURRENT_SET}', f'{n}', f'{valSet_size}',\n",
        "                    f'{interval}', f'{accuracy}', f'{batch_size}', f'{epochs}']}\n",
        "\n",
        "  index = ['model','dataset','n','valSet_size','interval','accuracy',\n",
        "           'batch_size','epochs']\n",
        "\n",
        "  pd.DataFrame(data, index=index).to_excel(writer, sheet_name='Parameters')\n",
        "\n",
        "  # Validation sets\n",
        "  pd.DataFrame(validation_points_collected,\n",
        "               columns=val_columns).to_excel(writer, sheet_name=f'Validation Sets')\n",
        "\n",
        "  writer.save()\n",
        "\n",
        "  return result"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xguHGALIkBjx"
      },
      "source": [
        "#@title Plot Average Penalty Effect\n",
        "def plotPenaltyEffect(model, data, interval, accuracy, n, valSet_size, batch_size, epochs,\n",
        "                      dataset=CURRENT_SET, ylim=[0,10], maj_yt_incr=1,\n",
        "                      min_yt_incr=0.1, figsize=(14,10), showParameters=True,\n",
        "                      resolution=300, path=''):\n",
        "  \"\"\"Plots average penalty effect given by 'data' and saves png of plot to the\n",
        "    directory.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model for which the penalty effect is measured.\n",
        "    data: 3-tuple of np arrays, or str\n",
        "      (total_misclass_percentages_avg, red_misclass_percentages_avg,\n",
        "      green_misclass_percentages_avg) or the name of an Excel sheet present in\n",
        "      the directory as a String (e.g. 'data.xlsx').\n",
        "    interval: 2-tuple\n",
        "      (x,y) which defines the penalty interval plotted. x is the lowest penalty,\n",
        "      y the highest.\n",
        "    accuracy: int\n",
        "      Penalty interval is evenly split into 'accuracy' many points.\n",
        "    n, valSet_size, batch_size, epochs:\n",
        "      Parameters used for training and calculaing the average penalty effect.\n",
        "      Shown in configurations text in plot.\n",
        "    dataset: char, optional\n",
        "      Dataset which the penalty effect was measured on. 'A', 'B' or 'C'.\n",
        "    ylim: 1D list of floats or ints, optional\n",
        "      [x,y] which defines the range of % misclassification shown on the y-axis.\n",
        "    maj_yt_incr: float, optional\n",
        "      The increments in which major y-ticks are plotted on the y-axis.\n",
        "    min_yt_incr: float, optional\n",
        "      The increments in which minor y-ticks are plotted on the y-axis.\n",
        "    figsize: 2-tuple of floats, optional\n",
        "      (x,y) where x is the width of the plot and y is the height of the plot.\n",
        "    showParameters: boolean, optional\n",
        "      Whether to include a configuratiuon text in the plot or not. \n",
        "    resolution: int, optional\n",
        "      Resolution of the plot png in dpi.\n",
        "    path: str, optional\n",
        "      Path to which the plots will be saved. e.g. '/content/drive/MyDrive/'\n",
        "\n",
        "  Raises:\n",
        "    TypeError: if data is not of type String or 3-tuple of np arrays.\n",
        "  \"\"\"\n",
        "  # Penalties to be plotted on the x-axis\n",
        "  penalties = np.arange(interval[0], interval[1]+(interval[1]-interval[0])/accuracy,\n",
        "                          (interval[1]-interval[0])/accuracy)\n",
        "\n",
        "  # DATA PREPARATION\n",
        "  if (isinstance(data, tuple) and isinstance(data[0], np.ndarray) and \n",
        "      isinstance(data[1], np.ndarray) and isinstance(data[2], np.ndarray) and\n",
        "      len(data)==3):\n",
        "    total_misclass_percentages_avg = data[0]\n",
        "    red_misclass_percentages_avg = data[1]\n",
        "    green_misclass_percentages_avg = data [2]\n",
        "\n",
        "  elif isinstance(data, str):\n",
        "    data = pd.ExcelFile(data)\n",
        "    avg_data = pd.read_excel(data, 'Average')\n",
        "\n",
        "    total = pd.DataFrame(avg_data.loc[0])\n",
        "    total = total.drop('Unnamed: 0')\n",
        "    total_misclass_percentages_avg = total[0]\n",
        "\n",
        "    red = pd.DataFrame(avg_data.loc[1])\n",
        "    red = red.drop('Unnamed: 0')\n",
        "    red_misclass_percentages_avg = red[1]\n",
        "\n",
        "    green = pd.DataFrame(avg_data.loc[2])\n",
        "    green = green.drop('Unnamed: 0')\n",
        "    green_misclass_percentages_avg = green[2]\n",
        "\n",
        "  else:\n",
        "    raise TypeError(f'Invalid type of data. data should be of type String or '\n",
        "                    + f'a 3-tuple of np arrays, but data is of type {type(data)}.')\n",
        "\n",
        "  # Define yticks\n",
        "  major_yticks = np.arange(0, ylim[1]+maj_yt_incr, maj_yt_incr)\n",
        "  minor_yticks = np.arange(0, ylim[1]+min_yt_incr, min_yt_incr)\n",
        "\n",
        "  # Create subplot\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "  ax.plot(penalties, total_misclass_percentages_avg, 'b', penalties, \n",
        "            red_misclass_percentages_avg, 'r', penalties,\n",
        "            green_misclass_percentages_avg, 'g')\n",
        "\n",
        "  ax.set_title(f'Dataset {dataset}: Average misclassification by penalty',\n",
        "               fontsize='x-large')\n",
        "  ax.set_ylabel('% misclassified', fontsize='large')\n",
        "  ax.set_xlabel('Penalty', fontsize='large')\n",
        "\n",
        "  # Ranges of x and y-axis\n",
        "  ax.set_xlim(list(interval))\n",
        "  ax.set_ylim(ylim)\n",
        "\n",
        "  # Set ticks\n",
        "  ax.set_xticks(penalties)\n",
        "  ax.set_yticks(major_yticks)\n",
        "  ax.set_yticks(minor_yticks, minor=True)\n",
        "\n",
        "  # Color and grid\n",
        "  ax.set_facecolor('white')\n",
        "  ax.grid(which='minor', alpha=0.2, color='black')\n",
        "  ax.grid(which='major', alpha=0.5, color='black')\n",
        "\n",
        "  # Show configuration information on plot\n",
        "  if showParameters==True:\n",
        "    config_info = (f'{model.name}\\nn: {n}\\nVal. set size: {valSet_size}\\n' + \n",
        "                   f'Batch size: {batch_size}\\nEpochs: {epochs}')\n",
        "    ax.text(interval[1]+(interval[1]/(8*figsize[0])), ylim[1]-(ylim[1]/figsize[1]),\n",
        "            config_info)\n",
        "\n",
        "  plt.legend(['total', 'red', 'green'], loc='upper left', fontsize='medium')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  # Get current date\n",
        "  today = date.today()\n",
        "\n",
        "  fig.savefig(f'{path}Penalty_Plt_{dataset}_{model.name}_' +\n",
        "              f'{today.strftime(\"%d-%m-%Y\")}.png', dpi=resolution)\n",
        "  fig.savefig(f'{path}Penalty_Plt_{dataset}_{model.name}_' +\n",
        "              f'{today.strftime(\"%d-%m-%Y\")}.pdf')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tepNATmlkBjy"
      },
      "source": [
        "def epochsBatchSize(model, initialWeights, valSet_size, batchRange,\n",
        "                    batchIncrements, epochRange, epochIncrements, epsilon=0,\n",
        "                    saveAndPlot=True, path='', verbose=1):\n",
        "  \"\"\"Calculates total, red, and green % misclassification in relation to batch\n",
        "    size and epoch number for a random validation set on CURRENT_SET.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model which classifies the validation set.\n",
        "    initialWeights: array-like\n",
        "      Initial weights of model.\n",
        "    valSet_size: int\n",
        "      Size of the randomly chosen validation set.\n",
        "    batchRange: 2-tuple of ints\n",
        "      The range of batch sizes used. (x,y) where x is the smallest and y is the\n",
        "      largest batch size used. \n",
        "    batchIncrements: int\n",
        "      Increment in which the batch size is increased.\n",
        "    epochRange: 2-tuple of ints\n",
        "      The range of epochs used. (x,y) where x is the smallest and y is the\n",
        "      largest epoch number used.\n",
        "    epochIncrements: int\n",
        "      Increment in which the epoch number is increased.\n",
        "    epsilon: float, optional\n",
        "      The allowed absolute percentage difference between the misclass percentage\n",
        "      of an optimum point and the minimum misclass percentage.\n",
        "    saveAndPlot: boolean, optional\n",
        "      Whever to save results to Excel and plot graphs or not. Set to false when\n",
        "      using averageEpochsBatchSize.\n",
        "    path: str, optional\n",
        "      Path to which the plots will be saved. e.g. '/content/drive/MyDrive/'\n",
        "    verbose: boolean, optional\n",
        "      Whether to print a progress bar or not.\n",
        "\n",
        "  Returns:\n",
        "    6-tuple (epochs, batch_sizes, total_misclass_percentage,\n",
        "    red_misclass_percentage, green_misclass_percentage, valSet).\n",
        "    First 5 elements are lists, valSet is pd.DataFrame.\n",
        "  \"\"\"\n",
        "  # Start time\n",
        "  if verbose > 0:\n",
        "    start_time = time.time()\n",
        "\n",
        "  # Preparing data collection lists\n",
        "  epochs = []\n",
        "  batch_sizes = []\n",
        "  total_misclass_percentage = []\n",
        "  red_misclass_percentage = []\n",
        "  green_misclass_percentage = []\n",
        "\n",
        "  # Defining iteration lists\n",
        "  batch_size_iter = np.arange(batchRange[0], batchRange[1]+1, batchIncrements)\n",
        "  epoch_iter = np.arange(epochRange[0], epochRange[1]+1, epochIncrements)\n",
        "\n",
        "  if batch_size_iter[0] == 0:\n",
        "    batch_size_iter[0] = 1\n",
        "\n",
        "  # Preparing data\n",
        "  dataSet = getDataSet()\n",
        "  dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "  # Choose random validation set\n",
        "  random.seed(time.time())\n",
        "  val_indices = getBalancedValSetIndices(dataSet, valSet_size, THRESHOLD_VAL)\n",
        "\n",
        "  valSet_points, valSet_labels = seperateValidationSet(dataSet,val_indices)\n",
        "  \n",
        "  dataSet = balanceDataset(dataSet, threshold=THRESHOLD_DATA, verbose=0)\n",
        "\n",
        "  training_labels = np.array(dataSet['l_i']).astype('float')\n",
        "  training_points = np.array(dataSet[['x_i1','x_i2']])\n",
        "\n",
        "  number_of_points = len(valSet_labels)\n",
        "  red_points = len(np.where(valSet_labels==1)[0])\n",
        "  green_points = len(np.where(valSet_labels==0)[0])\n",
        "\n",
        "  # Initialize progress bar\n",
        "  if verbose > 0:\n",
        "    num_training_points = training_labels.shape[0]\n",
        "    progress = 0\n",
        "    full = 0\n",
        "    # Calculate full progress\n",
        "    for ep in epoch_iter:\n",
        "      for ba in batch_size_iter:\n",
        "        full += ep*math.ceil(num_training_points/ba)\n",
        "    # Print bar\n",
        "    printProgressBar(progress, full, suffix=f'{progress}/{full} steps')\n",
        "\n",
        "  # Epoch loop\n",
        "  for ep in epoch_iter:\n",
        "    # Batch size loop\n",
        "    for ba in batch_size_iter:\n",
        "      epochs.append(ep)\n",
        "      batch_sizes.append(ba)\n",
        "\n",
        "      # Prepare model for classification\n",
        "      model.set_weights(initialWeights)\n",
        "\n",
        "      history = model.fit(x=training_points, y=training_labels, batch_size=ba, \n",
        "                          epochs=ep, verbose=0)\n",
        "\n",
        "      # Classification and saving results\n",
        "      prediction = model.predict(valSet_points)\n",
        "\n",
        "      correct_indices = np.where((valSet_labels == np.argmax(prediction, axis=1))\n",
        "                                 == True)\n",
        "      incorrect_indices = np.where((valSet_labels == np.argmax(prediction, axis=1))\n",
        "                                   == False)\n",
        "\n",
        "      total_misclassifications = np.bincount(valSet_labels == np.argmax(prediction, axis=1))[0]\n",
        "      red_misclassifications = len(np.where(valSet_labels[incorrect_indices] == 1)[0])\n",
        "      green_misclassifications = len(np.where(valSet_labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "      total_misclass_percentage.append((total_misclassifications/number_of_points)*100)\n",
        "      red_misclass_percentage.append((red_misclassifications/red_points)*100)\n",
        "      green_misclass_percentage.append((green_misclassifications/green_points)*100)\n",
        "\n",
        "      # Update progress bar\n",
        "      if verbose > 0:\n",
        "        progress += ep*math.ceil(num_training_points/ba)\n",
        "        printProgressBar(progress, full, suffix=f'{progress}/{full} steps')\n",
        "\n",
        "  # Print time taken for calculation\n",
        "  if verbose > 0:  \n",
        "    end_time = time.time()\n",
        "    total_time = (end_time-start_time)/60\n",
        "    print(f'Time taken: {round(total_time, 2)} minutes.')\n",
        "  \n",
        "  # Validation set\n",
        "  valSet = pd.DataFrame.from_dict({'x_i1':valSet_points[:,0],'x_i2':valSet_points[:,1],\n",
        "                                  'l_i':valSet_labels})\n",
        "  \n",
        "  # Parameters\n",
        "  data = {'Values':[f'{model.name}', f'{CURRENT_SET}', f'{valSet_size}',\n",
        "                    f'{PENALTY}', f'{batchRange}', f'{batchIncrements}',\n",
        "                    f'{epochRange}', f'{epochIncrements}', f'{epsilon}']}\n",
        "\n",
        "  index = ['model','dataset','valSet_size','penalty','batchRange',\n",
        "           'batchIncrements','epochRange','epochIncrements','epsilon']\n",
        "\n",
        "  parameters = pd.DataFrame(data, index=index)\n",
        "\n",
        "  # SAVE RESULTS TO EXCEL\n",
        "  if saveAndPlot==True:\n",
        "    today = date.today()\n",
        "\n",
        "    # Initialize writer\n",
        "    writer = pd.ExcelWriter(f'{path}EBS_Data_{CURRENT_SET}_' + \n",
        "                          f'{model.name}_{today.strftime(\"%d-%m-%Y\")}.xlsx')\n",
        "    \n",
        "    # Create multiindex for epochs and batch_sizes\n",
        "    arrays = [epochs,batch_sizes]\n",
        "\n",
        "    tuples = list(zip(*arrays))\n",
        "\n",
        "    multiindex = pd.MultiIndex.from_tuples(tuples,\n",
        "                                      names=[\"epochs\", \"batch_sizes\"])\n",
        "    \n",
        "    # All data\n",
        "    allData = pd.DataFrame({'total':total_misclass_percentage,\n",
        "                            'red':red_misclass_percentage,\n",
        "                            'green':green_misclass_percentage}, index=multiindex)\n",
        "    \n",
        "    allData.to_excel(writer, sheet_name='All Data')\n",
        "\n",
        "    # Optimum points\n",
        "    result = (epochs, batch_sizes, total_misclass_percentage,\n",
        "            red_misclass_percentage, green_misclass_percentage)\n",
        "    optimumPoints = calculateOptimumPoints(result, epsilon)\n",
        "    optimumPoints.to_excel(writer, sheet_name='Optimum Points')\n",
        "\n",
        "    # Parameters\n",
        "    parameters.to_excel(writer, sheet_name='Parameters')\n",
        "\n",
        "    # Validation set\n",
        "    valSet.to_excel(writer, sheet_name='Validation Set')\n",
        "\n",
        "    writer.save()\n",
        "\n",
        "  # Plot and return results\n",
        "  result = (epochs, batch_sizes, total_misclass_percentage,\n",
        "            red_misclass_percentage, green_misclass_percentage, valSet)\n",
        "  \n",
        "  if saveAndPlot==True:\n",
        "    plotEpochsBatchSize(model, result, path=path)\n",
        "\n",
        "  return result\n",
        "  \n",
        "\n",
        "\n",
        "def calculateOptimumPoints(data, epsilon):\n",
        "  \"\"\"Calculates optimum points of epoch and batch size for total, red, and green\n",
        "    misclassification. \n",
        "\n",
        "  Args:\n",
        "    data: 5-tuple or str\n",
        "      (epochs, batch_sizes, total_misclass_percentage, red_misclass_percentage,\n",
        "      green_misclass_percentage) or the name of an Excel sheet present in the\n",
        "      directory as a String (e.g. 'data.xlsx').\n",
        "    epsilon: float\n",
        "      The allowed absolute percentage difference between the misclass percentage\n",
        "      of an optimum point and the minimum misclass percentage.\n",
        "\n",
        "  Returns: pd.DataFrame\n",
        "    columns: [min_misclass, epsilon, opt_misclass, opt_epoch, opt_batch,\n",
        "             t_misclass_here, r_misclass here, g_misclass_here]\n",
        "    rows: [total, red, green]\n",
        "\n",
        "  Raises:\n",
        "    TypeError: if data is not in correct form.\n",
        "  \"\"\"\n",
        "  # DATA PREPARATION\n",
        "  if isinstance(data, tuple):\n",
        "    # Converting data to list of np arrays\n",
        "    data = list(data)\n",
        "    for i in range(5):\n",
        "      if isinstance(data[i], list):\n",
        "        data[i] = np.array(data[i])\n",
        "\n",
        "    # Checking list shapes\n",
        "    for i in range(4):\n",
        "      if data[i].shape != data[i+1].shape:\n",
        "        raise TypeError(f'The elements of the 5-tuple data must all have the' +\n",
        "                  f' same shape. The {i+1}. element has shape {data[i].shape}' +\n",
        "                  f' and the {i+2}. element has shape {data[i+1].shape}.')\n",
        "        \n",
        "    if len(data[0].shape) != 1:\n",
        "      raise TypeError(f'The elements of the 5-tuple data must all be' + \n",
        "                      f' 1-dimensional.')\n",
        "      \n",
        "    epochs = data[0]\n",
        "    batch_sizes = data[1]\n",
        "    total_misclass_percentage = data[2]\n",
        "    red_misclass_percentage = data[3]\n",
        "    green_misclass_percentage = data[4]\n",
        "\n",
        "  elif isinstance(data, str):\n",
        "    data = pd.ExcelFile(data)\n",
        "    data = pd.read_excel(data, 'All Data')\n",
        "\n",
        "    # Check columns for equal length\n",
        "    for col in list(data.columns):\n",
        "      if data[col].isnull().values.any():\n",
        "        raise TypeError(f'The columns of the excel sheet data are not of ' +\n",
        "                        f'equal length. Column {col} contains NAN.')\n",
        "\n",
        "    epochs = data['epoch']\n",
        "    batch_sizes = data['batch_size']\n",
        "    total_misclass_percentage = data['total']\n",
        "    red_misclass_percentage = data['red']\n",
        "    green_misclass_percentage = data['green']\n",
        "\n",
        "  else:\n",
        "    raise TypeError(f'data should be of type tuple or str, but is of type' + \n",
        "                    f' {type(data)}.')\n",
        "\n",
        "  # CALCULATE OPTIMUM POINTS\n",
        "  # For total: Finds the configuration with total misclass within epsilon of\n",
        "  #   minimum total misclass which has the lowest red misclass.\n",
        "  # For green: Finds the configuration with green misclass within epsilon of\n",
        "  #   minimum green misclass which has the lowest red misclass.\n",
        "  # For red: Finds the configuration with red misclass within epsilon of\n",
        "  #   minimum red misclass which has the lowest total misclass.\n",
        "  columns = ['min_misclass', 'epsilon', 'opt_misclass', 'opt_epoch', 'opt_batch',\n",
        "             't_misclass_here', 'r_misclass here', 'g_misclass_here']\n",
        "  rows = ['total', 'red', 'green']\n",
        "  t_considerable_indices = []\n",
        "  r_considerable_indices = []\n",
        "  g_considerable_indices = []\n",
        "\n",
        "  #Total\n",
        "  t_min = np.min(total_misclass_percentage)\n",
        "  t_opt = np.argmin(total_misclass_percentage)  # Index of optimum point for t\n",
        "  for index in range(len(total_misclass_percentage)):\n",
        "    if total_misclass_percentage[index] <= (t_min+epsilon):\n",
        "      t_considerable_indices.append(index)\n",
        "  for index in t_considerable_indices:  # Find point with lowest red misclass\n",
        "    if red_misclass_percentage[index] < red_misclass_percentage[t_opt]:\n",
        "      t_opt = index\n",
        "\n",
        "  #Green\n",
        "  g_min = np.min(green_misclass_percentage)\n",
        "  g_opt = np.argmin(green_misclass_percentage)  # Index of optimum point for g\n",
        "  for index in range(len(green_misclass_percentage)):\n",
        "    if green_misclass_percentage[index] <= (g_min+epsilon):\n",
        "      g_considerable_indices.append(index)\n",
        "  for index in g_considerable_indices:  # Find point with lowest red misclass\n",
        "    if red_misclass_percentage[index] < red_misclass_percentage[g_opt]:\n",
        "      g_opt = index\n",
        "\n",
        "  #Red\n",
        "  r_min = np.min(red_misclass_percentage)\n",
        "  r_opt = np.argmin(red_misclass_percentage)  # Index of optimum point for r\n",
        "  for index in range(len(red_misclass_percentage)):\n",
        "    if red_misclass_percentage[index] <= (r_min+epsilon):\n",
        "      r_considerable_indices.append(index)\n",
        "  # Find point with lowest total misclass\n",
        "  # Only change r_opt if the improvement in total misclass is greater than the\n",
        "  #   loss in red misclass\n",
        "  for index in r_considerable_indices:  \n",
        "    if (total_misclass_percentage[index] < total_misclass_percentage[r_opt] and \n",
        "        (total_misclass_percentage[index]-total_misclass_percentage[r_opt] <\n",
        "         red_misclass_percentage[r_opt]-red_misclass_percentage[index])):\n",
        "      r_opt = index\n",
        "  \n",
        "  total_row = [t_min, epsilon, total_misclass_percentage[t_opt], epochs[t_opt],\n",
        "               batch_sizes[t_opt], total_misclass_percentage[t_opt],\n",
        "               red_misclass_percentage[t_opt], green_misclass_percentage[t_opt]]\n",
        "  red_row = [r_min, epsilon, red_misclass_percentage[r_opt], epochs[r_opt],\n",
        "               batch_sizes[r_opt], total_misclass_percentage[r_opt],\n",
        "               red_misclass_percentage[r_opt], green_misclass_percentage[r_opt]]\n",
        "  green_row = [g_min, epsilon, green_misclass_percentage[g_opt], epochs[g_opt],\n",
        "               batch_sizes[g_opt], total_misclass_percentage[g_opt],\n",
        "               red_misclass_percentage[g_opt], green_misclass_percentage[g_opt]]\n",
        "\n",
        "  return pd.DataFrame([total_row, red_row, green_row], index=rows, \n",
        "                      columns=columns)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB2vLv5NkBj1"
      },
      "source": [
        "def averageEpochsBatchSize(model, n, initialWeights, valSet_size, batchRange,\n",
        "                    batchIncrements, epochRange, epochIncrements, epsilon=0,\n",
        "                    path='', verbose=1):\n",
        "  \"\"\"Calculates total, red, and green % misclassification in relation to batch\n",
        "    size and epoch number averaged over n validation sets on CURRENT_SET.\n",
        "\n",
        "  Args:\n",
        "    n: int\n",
        "      Number of iterations.\n",
        "    All others:\n",
        "      See epochsBatchSize.\n",
        "\n",
        "  Returns:\n",
        "    5 tuple of lists (epochs, batch_sizes, total_misclass_avg, red_misclass_avg,\n",
        "    green_misclass_avg).\n",
        "  \"\"\"\n",
        "  # Start time\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Preparing data collection lists\n",
        "  epochs_collected = []\n",
        "  batch_sizes_collected = []\n",
        "  total_misclass_collected = []\n",
        "  red_misclass_collected = []\n",
        "  green_misclass_collected = []\n",
        "\n",
        "  # For saving in excel\n",
        "  validationSets = {}\n",
        "  misclassCollected = {}\n",
        "\n",
        "  # Initialize progress bar\n",
        "  if verbose > 0:\n",
        "    printProgressBar(0, n)\n",
        "\n",
        "  # MAIN LOOP\n",
        "  for i in range(n):\n",
        "    # Collecting misclassification percentages\n",
        "    data = epochsBatchSize(model, initialWeights, valSet_size, batchRange,\n",
        "                           batchIncrements, epochRange, epochIncrements,\n",
        "                           epsilon=0, saveAndPlot=False, verbose=0)\n",
        "\n",
        "    epochs_collected.append(data[0])\n",
        "    batch_sizes_collected.append(data[1])\n",
        "    total_misclass_collected.append(data[2])\n",
        "    red_misclass_collected.append(data[3])\n",
        "    green_misclass_collected.append(data[4])\n",
        "\n",
        "    # Adding validation set to dictionary for dataframe\n",
        "    validationSets[f'x_i1:{i}'] = data[5]['x_i1']\n",
        "    validationSets[f'x_i2:{i}'] = data[5]['x_i2']\n",
        "    validationSets[f'l_i:{i}'] = data[5]['l_i']\n",
        "\n",
        "    # Adding misclassification data to dictionary for dataframe\n",
        "    misclassCollected[f'total:{i}'] = data[2]\n",
        "    misclassCollected[f'red:{i}'] = data[3]\n",
        "    misclassCollected[f'green{i}'] = data[4]\n",
        "\n",
        "    # Update progress bar\n",
        "    if verbose > 0:\n",
        "      printProgressBar(i+1, n)\n",
        "\n",
        "\n",
        "  # Averaging\n",
        "  epochs = np.average(epochs_collected, axis=0)\n",
        "  batch_sizes = np.average(batch_sizes_collected, axis=0)\n",
        "  total_misclass_avg = np.average(total_misclass_collected, axis=0)\n",
        "  red_misclass_avg = np.average(red_misclass_collected, axis=0)\n",
        "  green_misclass_avg = np.average(green_misclass_collected, axis=0)\n",
        "\n",
        "\n",
        "  # SAVE RESULTS TO EXCEL\n",
        "  today = date.today()\n",
        "\n",
        "  # Create multiindex for epochs and batch_sizes\n",
        "  arrays = [epochs,batch_sizes]\n",
        "\n",
        "  tuples = list(zip(*arrays))\n",
        "\n",
        "  multiindex = pd.MultiIndex.from_tuples(tuples, names=[\"epochs\", \"batch_sizes\"])\n",
        "\n",
        "  # Initialize writer\n",
        "  writer = pd.ExcelWriter(f'{path}Avg_EBS_Data_{CURRENT_SET}_' + \n",
        "                        f'{model.name}_{today.strftime(\"%d-%m-%Y\")}.xlsx')\n",
        "\n",
        "  # Average \n",
        "  average = pd.DataFrame({'total':total_misclass_avg,\n",
        "                          'red':red_misclass_avg,\n",
        "                          'green':green_misclass_avg}, index=multiindex)\n",
        "\n",
        "  average.to_excel(writer, sheet_name='Average')\n",
        "\n",
        "  # Collected\n",
        "  misclassCollected = pd.DataFrame(misclassCollected, index=multiindex)\n",
        "  misclassCollected.to_excel(writer, sheet_name='Collected')\n",
        "\n",
        "  # Optimum points\n",
        "  result = (epochs, batch_sizes, total_misclass_avg, red_misclass_avg,\n",
        "            green_misclass_avg)\n",
        "  optimumPoints = calculateOptimumPoints(result, epsilon)\n",
        "  optimumPoints.to_excel(writer, sheet_name='Optimum Points')\n",
        "\n",
        "  # Parameters\n",
        "  data = {'Values':[f'{model.name}', f'{CURRENT_SET}', f'{n}', f'{valSet_size}',\n",
        "                    f'{PENALTY}', f'{batchRange}', f'{batchIncrements}',\n",
        "                    f'{epochRange}', f'{epochIncrements}', f'{epsilon}']}\n",
        "\n",
        "  index = ['model','dataset','n','valSet_size','penalty','batchRange',\n",
        "           'batchIncrements','epochRange','epochIncrements','epsilon']\n",
        "\n",
        "  parameters = pd.DataFrame(data, index=index)\n",
        "  parameters.to_excel(writer, sheet_name='Parameters')\n",
        "\n",
        "  # Validation set\n",
        "  validationSets = pd.DataFrame.from_dict(validationSets)\n",
        "  validationSets.to_excel(writer, sheet_name='Validation Sets')\n",
        "\n",
        "  writer.save()\n",
        "\n",
        "\n",
        "  # Plot and return results\n",
        "  result = (epochs, batch_sizes, total_misclass_avg, red_misclass_avg,\n",
        "            green_misclass_avg)\n",
        "  \n",
        "  plotEpochsBatchSize(model, result, path=path, prefix='Avg_')\n",
        "  \n",
        "  # Print time taken for calculation\n",
        "  if verbose > 0:  \n",
        "    end_time = time.time()\n",
        "    total_time = (end_time-start_time)/60\n",
        "    print(f'Time taken: {round(total_time, 2)} minutes.')\n",
        "\n",
        "  return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMXcj1OBkBj4"
      },
      "source": [
        "#@title Plot epochs / batch size\n",
        "def plotEpochsBatchSize(model, data, dataset=CURRENT_SET,\n",
        "                        misclass_range=(0,15), figsize=(14,10), resolution=300,\n",
        "                        cmap='viridis', path='', prefix=''):\n",
        "  \"\"\"Plots a 3D graph showing the relation between epoch number, batch size,\n",
        "    and percentage misclassification.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      The model which was used for training and classification.\n",
        "    data: 6-tuple or str\n",
        "      (epochs, batch_sizes, total_misclass_percentage, red_misclass_percentage,\n",
        "      green_misclass_percentage, valSet) or the name of an Excel\n",
        "      sheet present in the directory as a String (e.g. 'data.xlsx').\n",
        "    dataset: char, optional\n",
        "      The dataset used. 'A', 'B' or 'C'.\n",
        "    misclass_range: 2-tuple, optional\n",
        "      The range of misclassification percentages plotted (limits of the z-axis).\n",
        "    figsize: 2-tuple, optional\n",
        "      (x,y) where x is the width of the plot and y is the height of the plot.\n",
        "    resolution: int, optional\n",
        "      Resolution of the plot png in dpi.\n",
        "    cmap: Colormap, optional\n",
        "      A colormap for the surface patches.\n",
        "    path: str, optional\n",
        "      Path to which the plots will be saved. e.g. '/content/drive/MyDrive/'\n",
        "    prefix: str, optional\n",
        "      appended to the front of the pnd and pdf file names\n",
        "\n",
        "  Raises:\n",
        "    TypeError: if data is of invalid type or shape.\n",
        "  \"\"\"\n",
        "  # DATA PREPARATION\n",
        "  if isinstance(data, tuple):\n",
        "    # Converting data to list of np arrays\n",
        "    data = list(data)\n",
        "    for i in range(5):\n",
        "      if isinstance(data[i], list):\n",
        "        data[i] = np.array(data[i])\n",
        "\n",
        "    # Checking list shapes\n",
        "    for i in range(4):\n",
        "      if data[i].shape != data[i+1].shape:\n",
        "        raise TypeError(f'The first 5 elements of the tuple data must all ' +\n",
        "                  f'have the same shape. The {i+1}. element has shape ' +\n",
        "                  f'{data[i].shape} and the {i+2}. element has shape ' +\n",
        "                  f'{data[i+1].shape}.')\n",
        "        \n",
        "    if len(data[0].shape) != 1:\n",
        "      raise TypeError(f'The first 5 elements of the tuple data must all be ' +\n",
        "                      f'1-dimensional.')\n",
        "      \n",
        "    epochs = data[0]\n",
        "    batch_sizes = data[1]\n",
        "    total_misclass = data[2]\n",
        "    red_misclass = data[3]\n",
        "    green_misclass = data[4]\n",
        "\n",
        "  elif isinstance(data, str):\n",
        "    data = pd.ExcelFile(data)\n",
        "    data = pd.read_excel(data, 'All Data')\n",
        "\n",
        "    # Check columns for equal length\n",
        "    for col in list(data.columns):\n",
        "      if data[col].isnull().values.any():\n",
        "        raise TypeError(f'The columns of the excel sheet data are not of ' +\n",
        "                        f'equal length. Column {col} contains NAN.')\n",
        "\n",
        "    epochs = data['epoch']\n",
        "    batch_sizes = data['batch_size']\n",
        "    total_misclass = data['total']\n",
        "    red_misclass = data['red']\n",
        "    green_misclass = data['green']\n",
        "\n",
        "  else:\n",
        "    raise TypeError(f'data should be of type tuple or str, but is of type' + \n",
        "                    f' {type(data)}.')\n",
        "\n",
        "  # Plotting\n",
        "  fig = plt.figure(figsize=(figsize[0], figsize[1]*3))\n",
        "  # Total misclassification\n",
        "  ax_t = fig.add_subplot(3, 1, 1, projection='3d')\n",
        "  ax_t.plot_trisurf(epochs, batch_sizes, total_misclass, cmap=cmap)\n",
        "  ax_t.set_title(f'Dataset {dataset}: Total misclassification by epoch and batch size')\n",
        "  ax_t.set_xlabel('Epochs')\n",
        "  ax_t.set_ylabel('Batch size')\n",
        "  ax_t.set_zlabel('% misclassification')\n",
        "  ax_t.set_zlim3d(misclass_range[0], misclass_range[1])\n",
        "  # Red misclassification\n",
        "  ax_r = fig.add_subplot(3, 1, 2, projection='3d')\n",
        "  ax_r.plot_trisurf(epochs, batch_sizes, red_misclass, cmap=cmap)\n",
        "  ax_r.set_title(f'Dataset {dataset}: Red misclassification by epoch and batch size')\n",
        "  ax_r.set_xlabel('Epochs')\n",
        "  ax_r.set_ylabel('Batch size')\n",
        "  ax_r.set_zlabel('% misclassification')\n",
        "  ax_r.set_zlim3d(misclass_range[0], misclass_range[1])\n",
        "  # Green misclassification\n",
        "  ax_g = fig.add_subplot(3, 1, 3, projection='3d')\n",
        "  ax_g.plot_trisurf(epochs, batch_sizes, green_misclass, cmap=cmap)\n",
        "  ax_g.set_title(f'Dataset {dataset}: Green misclassification by epoch and batch size')\n",
        "  ax_g.set_xlabel('Epochs')\n",
        "  ax_g.set_ylabel('Batch size')\n",
        "  ax_g.set_zlabel('% misclassification')\n",
        "  ax_g.set_zlim3d(misclass_range[0], misclass_range[1])\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  # Saving\n",
        "  today = date.today()\n",
        "\n",
        "  fig.savefig(f'{path}{prefix}EBS_Plt_{dataset}_{model.name}_' +\n",
        "              f'{today.strftime(\"%d-%m-%Y\")}.png', dpi=resolution)\n",
        "  fig.savefig(f'{path}{prefix}EBS_Plt_{dataset}_{model.name}_' +\n",
        "              f'{today.strftime(\"%d-%m-%Y\")}.pdf')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbdlLeaiYaqo"
      },
      "source": [
        "#@tile Different Training Approaches\n",
        "def diffPenaltyAproach(n, val_size, model, penalty, epochs, batch_size, increment, epoch_end_of_inc, verbose=0, figsize=(14,10), path=''):\n",
        "\n",
        "  dataSet_original = getDataSet()\n",
        "  valSets = [getBalancedValSetIndices(dataSet_original, val_size, THRESHOLD_VAL) for i in range(n)]\n",
        "\n",
        "  history_1 = np.zeros((n,3))\n",
        "  history_2 = np.zeros((n,3))\n",
        "  history_3 = np.zeros((n,3))\n",
        "\n",
        "  printProgressBar(0, 3*n)\n",
        "\n",
        "  model.set_weights(initialWeights)\n",
        "  for i in range(n):\n",
        "    dataSet = dataSet_original.copy()\n",
        "    model.set_weights(initialWeights)\n",
        "    \n",
        "    val_data = seperateValidationSet(dataSet, valSets[i])\n",
        "    dataSet = balanceDataset(dataSet, threshold=THRESHOLD_DATA, verbose=0)\n",
        "\n",
        "    training_labels = np.array(dataSet['l_i']).astype(float)\n",
        "    training_points = np.array(dataSet[['x_i1','x_i2']])\n",
        "  \n",
        "    penaltyIncreasingTraining(model, penalty, epochs, batch_size, increment, epoch_end_of_inc, training_points, training_labels)\n",
        "    \n",
        "    history_1[i] = getProportionOfMisclassification(model, val_data)\n",
        "    printProgressBar(i+1, 3*n)\n",
        "\n",
        "  for i in range(n):\n",
        "    dataSet = dataSet_original.copy()\n",
        "    model.set_weights(initialWeights)\n",
        "\n",
        "    val_data = seperateValidationSet(dataSet, valSets[i])\n",
        "    dataSet = balanceDataset(dataSet, threshold=THRESHOLD_DATA, verbose=0)\n",
        "\n",
        "    training_labels = np.array(dataSet['l_i']).astype(float)\n",
        "    training_points = np.array(dataSet[['x_i1','x_i2']])\n",
        "  \n",
        "    model.fit(training_points, training_labels, epochs=epochs,\n",
        "                                batch_size=batch_size, shuffle=True, verbose=0)\n",
        "\n",
        "    history_2[i] = getProportionOfMisclassification(model, val_data)\n",
        "    printProgressBar(i + n+1, 3*n)\n",
        "  \n",
        "  for i in range(n):\n",
        "    dataSet = dataSet_original.copy()\n",
        "    model.set_weights(initialWeights)\n",
        "    \n",
        "    val_data = seperateValidationSet(dataSet, valSets[i])\n",
        "    dataSet = balanceDataset(dataSet, threshold=THRESHOLD_DATA, verbose=0)\n",
        "\n",
        "    training_labels = np.array(dataSet['l_i']).astype(float)\n",
        "    training_points = np.array(dataSet[['x_i1','x_i2']])\n",
        "  \n",
        "    penaltyIncreasingTraining(model, penalty, epochs, batch_size, increment, epoch_end_of_inc, training_points, training_labels, increasing=False)\n",
        "    \n",
        "    history_3[i] = getProportionOfMisclassification(model, val_data)\n",
        "    printProgressBar(i + 2*n+1, 3*n)\n",
        "  \n",
        "  clear_output()\n",
        "\n",
        "  labels = ['total', 'red', 'green']\n",
        "  y_1 = [i/n for i in np.sum(history_1, axis=0)]\n",
        "  y_2 = [i/n for i in np.sum(history_2, axis=0)]\n",
        "  y_3 = [i/n for i in np.sum(history_3, axis=0)]\n",
        "\n",
        "  x = np.arange(len(labels))  # the label locations\n",
        "  width = 0.2  # the width of the bars\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  rects1 = ax.bar(x - width, y_1, width, label='With Increment')\n",
        "  rects2 = ax.bar(x, y_2, width, label='Normal')\n",
        "  rects3 = ax.bar(x + width, y_3, width, label='With Decrement')\n",
        "\n",
        "  # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "  ax.set_ylabel('Misclassification in %')\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels)\n",
        "  ax.legend()\n",
        "\n",
        "  fig.text(0,0, f'Dataset: {CURRENT_SET}, Epochs: {epochs}, Batch Size: {batch_size}, Epoch Increment: {increment}, Epoch end of Increment: {epoch_end_of_inc}')\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  # Saving\n",
        "  today = date.today()\n",
        "\n",
        "  fig.savefig(f'{path}Comparison{CURRENT_SET}_{model.name}_' +\n",
        "              f'{today.strftime(\"%d-%m-%Y\")}.pdf')\n",
        "  \n",
        "\n",
        "def getProportionOfMisclassification(model, val_data):\n",
        "\n",
        "  # Creating Numpy arrays from tensors\n",
        "  points = val_data[0]\n",
        "  labels = val_data[1].astype('float')\n",
        "\n",
        "  # Counting number of points for each class\n",
        "  number_of_points = len(labels)\n",
        "  red_points = len(np.where(labels==1)[0])\n",
        "  green_points = len(np.where(labels==0)[0])\n",
        "\n",
        "  prediction = model.predict(val_data[0])\n",
        "\n",
        "  # Determining the incorrect predictions\n",
        "  incorrect_indices = np.where((labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "  # Counting the number of misclassifications\n",
        "  total_misclassifications = np.bincount(labels == np.argmax(prediction, axis=1))[0]\n",
        "  red_misclassifications = len(np.where(labels[incorrect_indices] == 1)[0])\n",
        "  green_misclassifications = len(np.where(labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "  return ((total_misclassifications/number_of_points)*100,\n",
        "          (red_misclassifications/red_points)*100,\n",
        "          (green_misclassifications/green_points)*100)\n",
        "\n",
        "\n",
        "def penaltyIncreasingTraining(model, penalty, epochs, batch_size, increment, epoch_end_of_inc, training_points, training_labels, increasing=True, verbose=0):\n",
        "\n",
        "  if increasing:\n",
        "    array_penalties = np.linspace(0, penalty, (epochs - epoch_end_of_inc) // increment)\n",
        "  else:\n",
        "    array_penalties = np.linspace(penalty, 0, (epochs - epoch_end_of_inc) // increment)\n",
        "\n",
        "  for i in range((epochs - epoch_end_of_inc) // increment):\n",
        "    model.compile(optimizer='adam', loss=construct_custom_penalty_loss(array_penalties[i]), metrics=['accuracy'])\n",
        "    \n",
        "    model.fit(training_points, training_labels, batch_size=batch_size, epochs=increment,\n",
        "                  shuffle=True, verbose=verbose)\n",
        "\n",
        "  model.fit(training_points, training_labels, batch_size=batch_size, epochs=epochs - epoch_end_of_inc,\n",
        "                  shuffle=True, verbose=verbose)\n",
        "  \n",
        "\n",
        "def getBalancedValSetIndices(dataSet, size, threshold):\n",
        "  \n",
        "  # Amount of points for each color\n",
        "  amount_g = int(random.randint(size*threshold, size*(1-threshold)))\n",
        "  amount_r = size - amount_g\n",
        "\n",
        "  # Indices of each points with the specific color\n",
        "  indices_g = np.where(dataSet['l_i'] == 0)[0]\n",
        "  indices_r = np.where(dataSet['l_i'] == 1)[0]\n",
        "\n",
        "  # Check if possible \n",
        "  if indices_g.shape[0] + indices_r.shape[0] < size:\n",
        "    raise ValueError('The requested size of the validation set is not feasible')\n",
        "\n",
        "  if indices_r.shape[0] < amount_r:\n",
        "    indices_g += amount_r - indces_r.shape[0]\n",
        "\n",
        "  if indices_g.shape[0] < amount_g:\n",
        "    indices_r += amount_g - indces_g.shape[0]\n",
        "  \n",
        "  # Randomly selceting a subset for each color\n",
        "  indices_g = np.random.choice(indices_g, amount_g)\n",
        "  indices_r = np.random.choice(indices_r, amount_r)\n",
        "\n",
        "  # Concatenate and shuffle the chosen subsets\n",
        "  indices = np.concatenate([indices_g, indices_r])\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "  return indices"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR2BPwsfkBj6",
        "outputId": "09c216ef-400f-467a-a830-98cac3f64f21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Preparing data\n",
        "dataSet = getDataSet()\n",
        "dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "valSet_points, valSet_labels = seperateValidationSet(dataSet=dataSet, validationIndices=VAL_INDICES)\n",
        "\n",
        "dataSet = balanceDataset(dataSet, threshold=THRESHOLD_DATA)\n",
        "\n",
        "#Creating tensors\n",
        "training_labels = np.array(dataSet['l_i']).astype('float')\n",
        "training_points = np.array(dataSet[['x_i1','x_i2']])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Artificially exended by 101 points\n",
            "Relation is now: 0.6 green : 0.4 red \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bljczC5kBj7"
      },
      "source": [
        "#@title Custom Loss Function\n",
        "\n",
        "def construct_custom_penalty_loss(penalty,\n",
        "                                  lossFunction=keras.losses.sparse_categorical_crossentropy):\n",
        "  \"\"\"Constructs a loss function which penalizes 'red as green' misclassifications. \n",
        "\n",
        "  Args:\n",
        "    penalty: float between 0 and 1\n",
        "      Value added to the loss if a red point is misclassified as green. \n",
        "    lossFunction: loss function, optional\n",
        "      The loss function used after adapting the loss values.\n",
        "\n",
        "  Returns:\n",
        "    custom_penalty_loss function with specified penalty and loss function. Can be\n",
        "    used like a regular loss function. \n",
        "  \"\"\"\n",
        "\n",
        "  def custom_penalty_loss(y_true, y_pred):\n",
        "    length = tf.shape(y_true)[0]\n",
        "\n",
        "    #Creating a vector with all values set to the penalty: [0.3, 0.3, ... 0.3]\n",
        "    error = tf.multiply(tf.constant(penalty, tf.float32), tf.ones(length)) \n",
        "\n",
        "    #Setting every entry to 0 if the corresponding entry in y_true is 1\n",
        "    error = tf.where(tf.equal(y_true[:, 0], tf.zeros(length)), error, tf.zeros(length))\n",
        "\n",
        "    #Setting every entry to 0 if the algorithm predicted 0\n",
        "    error = tf.where(tf.greater(y_pred[:, 0], y_pred[:, 1]), tf.zeros(length), error)\n",
        "\n",
        "    #Transforms the vector from [0, 0, 0.3, ... 0,3] to [[0, -0], [0, -0], [0.3, -0.3], ... [0.3, -0.3]]\n",
        "    error = tf.stack([error, tf.multiply(tf.constant(-1, tf.float32), error)], 1)\n",
        "\n",
        "    #Adding the artificial loss\n",
        "    y_pred = y_pred + error\n",
        "\n",
        "    #Eliminating values > 1 or < 0\n",
        "    y_pred0 = tf.where(tf.greater(y_pred[:, 0], tf.ones(length)), tf.ones(length), y_pred[:, 0])\n",
        "    y_pred1 = tf.where(tf.greater(y_pred[:, 1], tf.zeros(length)), y_pred[:, 1], tf.zeros(length))\n",
        "    y_pred = tf.stack([y_pred0, y_pred1], axis=1)\n",
        "\n",
        "\n",
        "    loss = lossFunction(y_pred=y_pred, y_true=y_true)\n",
        "    return loss\n",
        "  \n",
        "  return custom_penalty_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuey_TJrkBj8"
      },
      "source": [
        "# Configure and compile model\n",
        "initalizer = keras.initializers.GlorotNormal()\n",
        "\n",
        "model_0 = keras.Sequential([\n",
        "          keras.layers.Flatten(input_shape=(2,)),      #input layer: 2 neurons\n",
        "          keras.layers.Dense(100,activation='relu', kernel_initializer=initalizer), \n",
        "          keras.layers.Dense(70,activation='relu', kernel_initializer=initalizer), \n",
        "          keras.layers.Dense(50,activation='relu', kernel_initializer=initalizer),       \n",
        "          keras.layers.Dense(10,activation='relu', kernel_initializer=initalizer),\n",
        "          keras.layers.Dense(2,activation='softmax', kernel_initializer=initalizer)   #output layer: 2 neurons              \n",
        "          ], name=\"model_0\")\n",
        "\n",
        "model_0.compile(optimizer='adam', loss=construct_custom_penalty_loss(PENALTY),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "#Save initial weights\n",
        "initialWeights = model_0.get_weights()\n",
        "\n",
        "# Fit model\n",
        "history = model_0.fit(training_points, training_labels, batch_size=1024, epochs=50,\n",
        "                    shuffle=True, validation_data=(valSet_points, valSet_labels))\n",
        "clear_output()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElaI4R35kBj9",
        "outputId": "c53f577b-3603-43b0-82cb-e173c7bab5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        }
      },
      "source": [
        "diffPenaltyAproach(2, 100, model_0, PENALTY, 200, 64, 50, 150)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABX0AAAPwCAYAAABtEd38AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfZSXdZ3/8deIDDfCDKLAQEKDKKSrWN5sAidgyMJsO2qYVm6o3WiKupqaua03ya7g3epax7vdVszN3NXyXihlZyjvhUAtDct0sUTYNhkEZESY3x8t83NWJQVmxvnM43HOnDPf63tdn+s93zN/Pc91Pt+K5ubm5gAAAAAAUIRtOnoAAAAAAAC2HtEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoyLYdPcB72YYNG/Liiy+mb9++qaio6OhxAAAAAIAuqrm5Oa+88kqGDBmSbbbZ9LO8ou8mvPjiixk6dGhHjwEAAAAAkCR54YUXstNOO23yHNF3E/r27ZvkTx9kVVVVB08DAAAAAHRVK1euzNChQ1ua5aaIvpuwcUuHqqoq0RcAAAAA6HDvZBtaX+QGAAAAAFAQ0RcAAAAAoCCiLwAAAABAQezpCwAAAAD/a/369Vm3bl1Hj0EX1L1793Tr1m2rrCX6AgAAANDlNTc356WXXsqKFSs6ehS6sH79+qWmpuYdfVnbpoi+AAAAAHR5G4PvwIED07t37y2ObvBuNDc3Z82aNVm+fHmSZPDgwVu0nugLAAAAQJe2fv36luC7ww47dPQ4dFG9evVKkixfvjwDBw7coq0efJEbAAAAAF3axj18e/fu3cGT0NVt/B/c0n2lRV8AAAAASGzpQIfbWv+Doi8AAAAAQEFEXwAAAADoIhoaGlJRUZEVK1Zs8rza2tpcfvnl7TQVW5svcgMAAACAt1D7jbvb9X7Pz/zkOz736quvzhlnnJGXX3452277p8S3atWqbL/99hk3blwaGhpazm1oaEhdXV1+85vfZOzYsVm6dGmqq6uTJLNmzcopp5zyZyPwO3H00UdnxYoVue2227Z4rc7qvfIZeNIXAAAAADqZurq6rFq1KvPnz2859rOf/Sw1NTV55JFHsnbt2pbj9fX1GTZsWEaMGJHKysrU1NR0yv2L169fnw0bNnT0GJ2C6AsAAAAAncyoUaMyePDgNz3Re/DBB2f48OF5+OGHWx2vq6tr+X3j9g4NDQ055phj0tjYmIqKilRUVOS8885ruW7NmjX54he/mL59+2bYsGG59tpr39WMEydOzMknn5yvf/3r6d+/f2pqalqtnyQrVqzIcccdl0GDBqVnz57ZY489ctdddyX501PI/fr1yx133JHdd989PXr0yJIlS9LU1JTTTz8973vf+7Lddtvlwx/+cKvPYeN1d911V0aNGpXevXvnsMMOy5o1a3L99dentrY222+/fU4++eSsX7++5bp3uu6Pf/zj7LbbbunTp08OPPDALF26NEly3nnn5frrr8/tt9/e8nm+8fr2JPoCAAAAQCdUV1eX+vr6ltf19fWZOHFiJkyY0HL81VdfzSOPPNISfd9o7Nixufzyy1NVVZWlS5dm6dKlOf3001vev/TSS7Pvvvtm4cKFOeGEE3L88cdn8eLF72rG66+/Ptttt10eeeSRXHTRRTn//PNz7733Jkk2bNiQT3ziE3nggQfyb//2b3nqqacyc+bMdOvWreX6NWvW5MILL8y//Mu/5Je//GUGDhyYE088MQ899FBuuummPPHEE/nMZz6TAw88ML/+9a9bXXfFFVfkpptuypw5c9LQ0JBDDz0099xzT+65557ccMMNueaaa3LLLbe0XPNO173kkktyww035Kc//WmWLFnS8pmdfvrpOfzww1tC8NKlSzN27Nh39XltLfb0BQAAAIBOqK6uLqecckpef/31vPrqq1m4cGEmTJiQdevW5eqrr06SPPTQQ2lqanrL6FtZWZnq6upUVFSkpqbmTe8fdNBBOeGEE5IkZ555Zi677LLU19dn1KhR73jG0aNH59xzz02S7LrrrvnOd76TuXPn5mMf+1juu+++PProo3n66aczcuTIJMnOO+/c6vp169blyiuvzF577ZUkWbJkSa677rosWbIkQ4YMSfKn2Dpnzpxcd911ueCCC1quu+qqqzJixIgkyWGHHZYbbrghy5YtS58+fbL77ru3RPMjjjjiXa179dVXt6x74okn5vzzz0+S9OnTJ7169UpTU9Nbfp7tSfQFAAAAgE5o4sSJWb16dR577LG8/PLLGTlyZAYMGJAJEybkmGOOydq1a9PQ0JCdd945w4YNe9frjx49uuX3jWF4+fLlm71GkgwePLhljUWLFmWnnXZqCb5vpbKystUaTz75ZNavX/+ma5qamrLDDju0vO7du3dLmE2SQYMGpba2Nn369Gl1bOMsm7vuG/+e9xLRFwAAAAA6oV122SU77bRT6uvr8/LLL2fChAlJkiFDhmTo0KF58MEHU19fn0mTJm3W+t27d2/1uqKi4l1/kdqm1ujVq9efvb5Xr16tvnRu1apV6datWxYsWNBqG4gkrYLuW913U7NsybrNzc1/9u9ob6IvAAAAAHRSdXV1aWhoyMsvv5wzzjij5fj48eMze/bsPProozn++OPf9vrKyspWX2bWnkaPHp3f/e53eeaZZzb5tO8bfehDH8r69euzfPnyfOQjH9lqs2ytdTvy83wjX+QGAAAAAJ1UXV1d7r///ixatKjlSd8kmTBhQq655pq89tprb7mf70a1tbVZtWpV5s6dmz/84Q9Zs2ZNe4zdMuP48eMzZcqU3HvvvXnuuecye/bszJkz522vGTlyZI488shMnTo1P/rRj/Lcc8/l0UcfzYwZM3L33Xdv9ixba93a2to88cQTWbx4cf7whz9k3bp1mz3TlhB9AQAAAKCTqqury6uvvppddtklgwYNajk+YcKEvPLKKxk1alQGDx78ttePHTs2X/3qV3PEEUdkwIABueiii9pj7BY//OEPs99+++Vzn/tcdt9993z961//s0/KXnfddZk6dWpOO+20jBo1Koccckgee+yxzdq3eGuv+5WvfCWjRo3KvvvumwEDBuSBBx7Yopk2V0Xze3HTifeIlStXprq6Oo2NjamqqurocQAAAABoA2vXrs1zzz2X4cOHp2fPnh09Dl3Ypv4X302r9KQvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAA0G4aGhpSUVGRFStWdPQoxRJ9AQAAAKCTOvroo1NRUZGZM2e2On7bbbeloqKig6aio23b0QMAAAAAwHvSedXtfL/GzbqsZ8+eufDCC3Pcccdl++233yqjvPbaa6msrNwqa9H+POkLAAAAAJ3YAQcckJqamsyYMeNtz/nhD3+Yv/iLv0iPHj1SW1ubSy+9tNX7tbW1mT59eqZOnZqqqqoce+yxmTVrVvr165e77roro0aNSu/evXPYYYdlzZo1uf7661NbW5vtt98+J598ctavX9+y1g033JB99903ffv2TU1NTT7/+c9n+fLlbfb382aiLwAAAAB0Yt26dcsFF1yQb3/72/nd7373pvcXLFiQww8/PJ/97Gfz5JNP5rzzzsvZZ5+dWbNmtTrvkksuyV577ZWFCxfm7LPPTpKsWbMmV1xxRW666abMmTMnDQ0NOfTQQ3PPPffknnvuyQ033JBrrrkmt9xyS8s669aty/Tp0/P444/ntttuy/PPP5+jjz66LT8C/g/bOwAAAABAJ3fooYfmgx/8YM4999x897vfbfXeP/7jP+ajH/1oS8gdOXJknnrqqVx88cWtYuykSZNy2mmntbz+2c9+lnXr1uWqq67KiBEjkiSHHXZYbrjhhixbtix9+vTJ7rvvnrq6utTX1+eII45Iknzxi19sWWPnnXfOFVdckf322y+rVq1Knz592uoj4A086QsAAAAABbjwwgtz/fXX5+mnn251/Omnn864ceNaHRs3blx+/etft9qWYd99933Tmr17924JvkkyaNCg1NbWtoq3gwYNarV9w4IFC/KpT30qw4YNS9++fTNhwoQkyZIlS7bsD+QdE30BAAAAoADjx4/P5MmTc9ZZZ23W9dttt92bjnXv3r3V64qKirc8tmHDhiTJ6tWrM3ny5FRVVeX73/9+Hnvssdx6661J/vTlcLQP2zsAAAAAQCFmzpyZD37wgxk1alTLsd122y0PPPBAq/MeeOCBjBw5Mt26dduq9//Vr36V//mf/8nMmTMzdOjQJMn8+fO36j348zzpCwAAAACF2HPPPXPkkUfmiiuuaDl22mmnZe7cuZk+fXqeeeaZXH/99fnOd76T008/favff9iwYamsrMy3v/3t/Pa3v80dd9yR6dOnb/X7sGmiLwAAAAAU5Pzzz2/ZbiFJ9t577/zHf/xHbrrppuyxxx4555xzcv7557f6EretZcCAAZk1a1Zuvvnm7L777pk5c2YuueSSrX4fNq2iubm5uaOHeK9auXJlqqur09jYmKqqqo4eBwAAAIA2sHbt2jz33HMZPnx4evbs2dHj0IVt6n/x3bRKe/oCAGyB2m/c3dEjdCnPz/xkR48AAADvebZ3AAAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAgC6ioaEhFRUVWbFixSbPq62tzeWXX95OU7G1ib4AAAAA0MlcffXV6du3b15//fWWY6tWrUr37t0zceLEVuduDL3PPvtsxo4dm6VLl6a6ujpJMmvWrPTr12+rzHT00UenoqIiFRUV6d69ewYNGpSPfexj+dd//dds2LBhq9yjs3r++edTUVGRRYsWtcv9tm2XuwAAAABAJ7Pn9Xu26/2ePOrJd3xuXV1dVq1alfnz52f//fdPkvzsZz9LTU1NHnnkkaxduzY9e/ZMktTX12fYsGEZMWJEkqSmpmbrD/+/DjzwwFx33XVZv359li1bljlz5uRv/uZvcsstt+SOO+7Ittu2TY587bXXUllZ2SZrd0ae9AUAAACATmbUqFEZPHhwGhoaWo41NDTk4IMPzvDhw/Pwww+3Ol5XV9fy+8btHRoaGnLMMceksbGx5Qnd8847r+W6NWvW5Itf/GL69u2bYcOG5dprr/2zc/Xo0SM1NTV53/vel7333jt/+7d/m9tvvz2zZ8/OrFmzWs5bsWJFvvzlL2fAgAGpqqrKpEmT8vjjj7da684778x+++2Xnj17Zscdd8yhhx7a8l5tbW2mT5+eqVOnpqqqKscee2yS5P77789HPvKR9OrVK0OHDs3JJ5+c1atXt7ru7//+7zN16tT06dMn73//+3PHHXfkv//7v3PwwQenT58+GT16dObPn99qlney7gUXXPC2n9fw4cOTJB/60IdSUVHxpqextzbRFwAAAAA6obq6utTX17e8rq+vz8SJEzNhwoSW46+++moeeeSRluj7RmPHjs3ll1+eqqqqLF26NEuXLs3pp5/e8v6ll16afffdNwsXLswJJ5yQ448/PosXL37Xc06aNCl77bVXfvSjH7Uc+8xnPpPly5dn9uzZWbBgQfbee+989KMfzR//+Mckyd13351DDz00Bx10UBYuXJi5c+fmL//yL1ute8kll2SvvfbKwoULc/bZZ+fZZ5/NgQcemClTpuSJJ57Iv//7v+f+++/PiSee2Oq6yy67LOPGjcvChQvzyU9+Ml/4whcyderU/PVf/3V+/vOfZ8SIEZk6dWqam5uT5B2vu6nP69FHH02S3HfffVm6dGmrz6ItiL4AAAAA0AnV1dXlgQceyOuvv55XXnklCxcuzIQJEzJ+/PiWJ4AfeuihNDU1vWX0raysTHV1dSoqKlJTU5Oampr06dOn5f2DDjooJ5xwQnbZZZeceeaZ2XHHHVtF5nfjAx/4QJ5//vkkf3pq9tFHH83NN9+cfffdN7vuumsuueSS9OvXL7fcckuS5B/+4R/y2c9+Nt/61rey2267Za+99spZZ53Vas1JkybltNNOy4gRIzJixIjMmDEjRx55ZE455ZTsuuuuGTt2bK644op873vfy9q1a1v9Xccdd1x23XXXnHPOOVm5cmX222+/fOYzn8nIkSNz5pln5umnn86yZcuS5F2t+3af14ABA5IkO+ywQ2pqatK/f//N+hzfKXv6AgAAAEAnNHHixKxevTqPPfZYXn755YwcOTIDBgzIhAkTcswxx2Tt2rVpaGjIzjvvnGHDhr3r9UePHt3y+8YwvHz58s2atbm5ORUVFUmSxx9/PKtWrcoOO+zQ6pxXX301zz77bJJk0aJF+cpXvrLJNffdd99Wrx9//PE88cQT+f73v9/qvhs2bMhzzz2X3Xbb7U1/16BBg5Ike+6555uOLV++PDU1NZu17pZ+XltK9AUAAACATmiXXXbJTjvtlPr6+rz88suZMGFCkmTIkCEZOnRoHnzwwdTX12fSpEmbtX737t1bva6oqMiGDRs2a62nn366ZV/bVatWvWk/4o369euXJOnVq9efXXO77bZr9XrVqlU57rjjcvLJJ7/p3DdG7zf+XRtD9Fsd2/i3bs66G9fZ3M9rS4m+AAAAANBJ1dXVpaGhIS+//HLOOOOMluPjx4/P7Nmz8+ijj+b4449/2+srKyuzfv36Np3xP//zP/Pkk0/m1FNPTZLsvffeeemll7Ltttumtrb2La8ZPXp05s6dm2OOOeYd32fvvffOU089lV122WVrjL1V162srEySNv+sN7KnLwAAAAB0UnV1dbn//vuzaNGilid9k2TChAm55ppr8tprr73lfr4b1dbWZtWqVZk7d27+8Ic/ZM2aNVs0T1NTU1566aX8/ve/z89//vNccMEFOfjgg/NXf/VXmTp1apLkgAMOyJgxY3LIIYfkJz/5SZ5//vk8+OCD+eY3v5n58+cnSc4999z84Ac/yLnnnpunn346Tz75ZC688MJN3vvMM8/Mgw8+mBNPPDGLFi3Kr3/969x+++1v+sK1d2trrDtw4MD06tUrc+bMybJly9LY2LhFM/05oi8AAAAAdFJ1dXV59dVXs8suu7TsRZv8Kfq+8sorGTVqVAYPHvy2148dOzZf/epXc8QRR2TAgAG56KKLtmieOXPmZPDgwamtrc2BBx6Y+vr6XHHFFbn99tvTrVu3JH/a9uCee+7J+PHjc8wxx2TkyJH57Gc/m//6r/9q+RsmTpyYm2++OXfccUc++MEPZtKkSXn00Uc3ee/Ro0dn3rx5eeaZZ/KRj3wkH/rQh3LOOedkyJAhW/Q3bY11t91221xxxRW55pprMmTIkBx88MFbNNOfU9Hc3NzcpnfoxFauXJnq6uo0Njamqqqqo8cBAN6Dar9xd0eP0KU8P/OTHT0CAFCgtWvX5rnnnsvw4cPTs2fPjh6HLmxT/4vvplV60hcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAECS5ubmjh6BLm5r/Q+KvgAAAAB0ad27d0+SrFmzpoMnoavb+D+48X9yc227NYYBAAAAgM6qW7du6devX5YvX54k6d27dyoqKjp4KrqS5ubmrFmzJsuXL0+/fv3SrVu3LVpP9AUAAACgy6upqUmSlvALHaFfv34t/4tbQvQFAAAAoMurqKjI4MGDM3DgwKxbt66jx6EL6t69+xY/4buR6AsAAAAA/6tbt25bLbxBR/FFbgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAUpNNG36uuuiqjR49OVVVVqqqqMmbMmMyePbvl/bVr12batGnZYYcd0qdPn0yZMiXLli3rwIkBAAAAANpep42+O+20U2bOnJkFCxZk/vz5mTRpUg4++OD88pe/TJKceuqpufPOO3PzzTdn3rx5efHFF/PpT3+6g6cGAAAAAGhbFc3Nzc0dPcTW0r9//1x88cU57LDDMmDAgNx444057LDDkiS/+tWvsttuu+Whhx7K/vvv/47WW7lyZaqrq9PY2Jiqqqq2HB0A6KRqv3F3R4/QpTw/85MdPQIAAHSId9MqO+2Tvm+0fv363HTTTVm9enXGjBmTBQsWZN26dTnggANazvnABz6QYcOG5aGHHurASQEAAAAA2ta2HT3AlnjyySczZsyYrF27Nn369Mmtt96a3XffPYsWLUplZWX69evX6vxBgwblpZdeetv1mpqa0tTU1PJ65cqVbTY7AAAAAEBb6NRP+o4aNSqLFi3KI488kuOPPz5HHXVUnnrqqc1eb8aMGamurm75GTp06FacFgAAAACg7XXq6FtZWZlddtkl++yzT2bMmJG99tor//RP/5Sampq89tprWbFiRavzly1blpqamrdd76yzzkpjY2PLzwsvvNDWfwIAAAAAwFbVqaPv/7Vhw4Y0NTVln332Sffu3TN37tyW9xYvXpwlS5ZkzJgxb3t9jx49UlVV1eoHAAAAAKAz6bR7+p511ln5xCc+kWHDhuWVV17JjTfemIaGhvz4xz9OdXV1vvSlL+VrX/ta+vfvn6qqqpx00kkZM2ZM9t9//44eHQAAAACgzXTa6Lt8+fJMnTo1S5cuTXV1dUaPHp0f//jH+djHPpYkueyyy7LNNttkypQpaWpqyuTJk3PllVd28NQAAAAAAG2rorm5ubmjh3ivWrlyZaqrq9PY2GirBwDgLdV+4+6OHqFLeX7mJzt6BAAA6BDvplUWtacvAAAAAEBXJ/oCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAUZNuOHgAAAN6x86o7eoKu57zGjp4AAIB3yZO+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAUpNNG3xkzZmS//fZL3759M3DgwBxyyCFZvHhxq3MmTpyYioqKVj9f/epXO2hiAAAAAIC212mj77x58zJt2rQ8/PDDuffee7Nu3bp8/OMfz+rVq1ud95WvfCVLly5t+bnooos6aGIAAAAAgLa3bUcPsLnmzJnT6vWsWbMycODALFiwIOPHj2853rt379TU1LT3eAAAAAAAHaLTPun7fzU2NiZJ+vfv3+r497///ey4447ZY489ctZZZ2XNmjUdMR4AAAAAQLvotE/6vtGGDRtyyimnZNy4cdljjz1ajn/+85/P+9///gwZMiRPPPFEzjzzzCxevDg/+tGP3nKdpqamNDU1tbxeuXJlm88OAAAAALA1FRF9p02bll/84he5//77Wx0/9thjW37fc889M3jw4Hz0ox/Ns88+mxEjRrxpnRkzZuRb3/pWm88LAAAAANBWOv32Dp9LR9IAACAASURBVCeeeGLuuuuu1NfXZ6eddtrkuR/+8IeTJL/5zW/e8v2zzjorjY2NLT8vvPDCVp8XAAAAAKAtddonfZubm3PSSSfl1ltvTUNDQ4YPH/5nr1m0aFGSZPDgwW/5fo8ePdKjR4+tOicAAAAAQHvqtNF32rRpufHGG3P77benb9++eemll5Ik1dXV6dWrV5599tnceOONOeigg7LDDjvkiSeeyKmnnprx48dn9OjRHTw9AAAAAEDb6LTR96qrrkqSTJw4sdXx6667LkcffXQqKytz33335fLLL8/q1aszdOjQTJkyJX/3d3/XAdMCAAAAALSPTht9m5ubN/n+0KFDM2/evHaaBgAAAADgvaHTf5EbAAAAAAD/n+gLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCbNvRAwAAAO9de16/Z0eP0KU8edSTHT0CAFAAT/oCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAK0mmj74wZM7Lffvulb9++GThwYA455JAsXry41Tlr167NtGnTssMOO6RPnz6ZMmVKli1b1kETAwAAAAC0vU4bfefNm5dp06bl4Ycfzr333pt169bl4x//eFavXt1yzqmnnpo777wzN998c+bNm5cXX3wxn/70pztwagAAAACAtrVtRw+wuebMmdPq9axZszJw4MAsWLAg48ePT2NjY7773e/mxhtvzKRJk5Ik1113XXbbbbc8/PDD2X///TtibAAAAACANtVpn/T9vxobG5Mk/fv3T5IsWLAg69atywEHHNByzgc+8IEMGzYsDz30UIfMCAAAAADQ1jrtk75vtGHDhpxyyikZN25c9thjjyTJSy+9lMrKyvTr16/VuYMGDcpLL730lus0NTWlqamp5fXKlSvbbmgAAAAAgDZQxJO+06ZNyy9+8YvcdNNNW7TOjBkzUl1d3fIzdOjQrTQhAAAAAED76PTR98QTT8xdd92V+vr67LTTTi3Ha2pq8tprr2XFihWtzl+2bFlqamrecq2zzjorjY2NLT8vvPBCm84OAAAAALC1dcj2Dq+//nquueaaNDQ0ZP369Rk3blymTZuWnj17vuM1mpubc9JJJ+XWW29NQ0NDhg8f3ur9ffbZJ927d8/cuXMzZcqUJMnixYuzZMmSjBkz5i3X7NGjR3r06LH5fxgAAAAAQAfrkOh78skn55lnnsmnP/3prFu3Lt/73vcyf/78/OAHP3jHa0ybNi033nhjbr/99vTt27dln97q6ur06tUr1dXV+dKXvpSvfe1r6d+/f6qqqnLSSSdlzJgx2X///dvqTwMAAAAA6FDtEn1vvfXWHHrooS2vf/KTn2Tx4sXp1q1bkmTy5MnvOsReddVVSZKJEye2On7dddfl6KOPTpJcdtll2WabbTJlypQ0NTVl8uTJufLKKzf/DwEAAAAAeI+raG5ubm7rm3zqU59Kt27dcuWVV2bIkCE5/PDDU11dnSlTpmTdunX553/+57z66qu5995723qUd2XlypWprq5OY2NjqqqqOnocAOA9qPYbd3f0CF3K8z0/39EjdDl7Dh/W0SN0KU8e9WRHjwAAvEe9m1bZLl/kduedd+Zzn/tcJk6cmG9/+9u59tprU1VVlW9+85s5++yzM3To0Nx4443tMQoAAAAAQNHabU/fI444IpMnT87Xv/71TJ48OVdffXUuvfTS9ro9AAAAAECX0C5P+m7Ur1+/XHvttbn44oszderUnHHGGVm7dm17jgAAAAAAULR2ib5LlizJ4Ycfnj333DNHHnlkdt111yxYsCC9e/fOXnvtldmzZ7fHGAAAAAAAxWuX6Dt16tRss802ufjiizNw4MAcd9xxqayszLe+9a3cdtttmTFjRg4//PD2GAUAAAAAoGjtsqfv/Pnz8/jjj2fEiBGZPHlyhg8f3vLebrvtlp/+9Ke59tpr22MUAAAAAICitUv03WeffXLOOefkqKOOyn333Zc999zzTecce+yx7TEKAAAAAEDR2mV7h+9973tpamrKqaeemt///ve55ppr2uO2AAAAAABdTrs86fv+978/t9xyS3vcCgAAAACgS2uXJ30BAAAAAGgfoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAqybXvebPXq1Zk5c2bmzp2b5cuXZ8OGDa3e/+1vf9ue4wAAAAAAFKddo++Xv/zlzJs3L1/4whcyePDgVFRUtOftAQAAAACK167Rd/bs2bn77rszbty49rwtAAAAAECX0a57+m6//fbp379/e94SAAAAAKBLadfoO3369JxzzjlZs2ZNe94WAAAAAKDLaNftHS699NI8++yzGTRoUGpra9O9e/dW7//85z9vz3EAAAAAAIrTrtH3kEMOac/bAQAAAAB0Oe0afc8999z2vB0AAAAAQJfTrnv6AgAAAADQttr8Sd/+/fvnmWeeyY477pjtt98+FRUVb3vuH//4x7YeBwAAAACgaG0efS+77LL07ds3SXL55Ze39e0AAAAAALq0No++Rx111Fv+DgAAAADA1mdPXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoyLbtebPVq1dn5syZmTt3bpYvX54NGza0ev+3v/1te44DAAAAAFCcdo2+X/7ylzNv3rx84QtfyODBg1NRUdGetwcAAAAAKF67Rt/Zs2fn7rvvzrhx49rztgAAAAAAXUa77um7/fbbp3///u15SwAAAACALqVdo+/06dNzzjnnZM2aNe15WwAAAACALqNdt3e49NJL8//Yu/dgq+r7/v+vzcUDglw1XOrhpvESFaUiDl5GQjCCjsbEaqQ2KqZitYQiVRM0GkFSa6MRiUTNtISYGo1KY3S+DVao4o3oKEY01SpIgjSgQSoHUMHA+f2Rb84vfFETI2cd/ZzHY2bP7P3Za5313o6y5jxZrr1s2bL06tUrAwYMSPv27bd5f/HixVWOAwAAAABQnEqj74knnljl4QAAAAAAWp1Ko+/Xvva1Kg8HAAAAANDqVBp9f+fJJ5/Mc889lyTZb7/9MmTIkJYYAwAAAACgOJVG31dffTWnnnpqHnjggXTr1i1J8vrrr+eTn/xkbrvttuy2225VjgMAAAAAUJw2VR7sS1/6UtavX5+f//znWbt2bdauXZtnn302DQ0NmThxYpWjAAAAAAAUqdIrfefNm5f58+dn3333bVr7xCc+kVmzZuXTn/50laMAAAAAABSp0it9t27dmvbt22+33r59+2zdurXKUQAAAAAAilRp9B05cmT+7u/+Lr/61a+a1v7nf/4n559/fj71qU9VOQoAAAAAQJEqjb7XX399GhoaMmDAgOyxxx7ZY489MnDgwDQ0NORb3/pWlaMAAAAAABSp0nv61tfXZ/HixZk/f36ef/75JMm+++6bUaNGVTkGAAAAAECxKo2+SVKr1XL00Ufn6KOPrvrQAAAAAADFa/boO3PmzIwfPz4dOnTIzJkz33PbiRMnNvc4AAAAAABFa/boe+211+a0005Lhw4dcu21177rdrVaTfQFAAAAAPiAmj36Ll++/B2fAwAAAACw47Wp8mDTpk3LG2+8sd36m2++mWnTplU5CgAAAABAkSqNvlOnTs2GDRu2W3/jjTcyderUKkcBAAAAAChSpdG3sbExtVptu/Wnn346PXr0qHIUAAAAAIAiNfs9fZOke/fuqdVqqdVq2WuvvbYJv1u2bMmGDRvyN3/zN1WMAgAAAABQtEqi74wZM9LY2JizzjorU6dOTdeuXZve22mnnTJgwIAMHz68ilEAAAAAAIpWSfQ944wzkiQDBw7MYYcdlvbt21dxWAAAAACAVqeS6Ps7Rx11VNPzt956K5s3b97m/S5dulQ5DgAAAABAcSr9Irc33ngjEyZMyMc+9rF06tQp3bt33+YBAAAAAMAHU2n0vfDCC/Of//mfueGGG1JXV5d//ud/ztSpU9O3b9/cfPPNVY4CAAAAAFCkSm/vcM899+Tmm2/OiBEjMm7cuBx55JHZc889079//9xyyy057bTTqhwHAAAAAKA4lV7pu3bt2gwaNCjJb+/fu3bt2iTJEUcckQcffLDKUQAAAAAAilTplb6DBg3K8uXL069fv+yzzz65/fbbM2zYsNxzzz3p1q1blaPwLgZ85f+09Aitzi/+8biWHgEAAACAglR6pe+4cePy9NNPJ0m+8pWvZNasWenQoUPOP//8XHjhhVWOAgAAAABQpEqv9D3//PObno8aNSrPP/98nnzyyey5554ZPHhwlaMAAAAAABSp0uj7/+rfv3/69+/fkiMAAAAAABSl0ts7TJw4MTNnztxu/frrr8+kSZOqHAUAAAAAoEiVRt+5c+fm8MMP3279sMMOy5133lnlKAAAAAAARao0+r722mvp2rXrdutdunTJmjVrqhwFAAAAAKBIlUbfPffcM/Pmzdtu/Sc/+UkGDRpU5SgAAAAAAEWq9IvcJk+enAkTJuTXv/51Ro4cmSRZsGBBrrnmmsyYMaPKUQAAAAAAilRp9D3rrLOyadOmfP3rX88VV1yRJBkwYEBuuOGGnH766VWOAgAAAABQpEqjb5Kce+65Offcc/PrX/86HTt2TOfOnaseAQAAAACgWJVH39/ZbbfdWurQAAAAAADFavbo++d//udZsGBBunfvniFDhqRWq73rtosXL27ucQAAAAAAitbs0fczn/lM6urqkiQnnnhicx8OAAAAAKBVa/bo271797Rp0yZJMm7cuOy+++5NrwEAAAAA2LGavb5Onjw5DQ0NSZKBAwdmzZo1zX1IAAAAAIBWq9mv9O3bt2/mzp2bY489No2NjVm5cmXeeuutd9y2X79+zT0OAAAAAEDRmj36fvWrX82XvvSlTJgwIbVaLYcccsh22zQ2NqZWq2XLli3NPQ4AAAAAQNGaPfqOHz8+Y8eOzS9/+csMHjw48+fPT8+ePZv7sAAAAAAArVKzR98k2WWXXbL//vvnu9/9bg4//PDU1dVVcVgAAAAAgFankuj7O2eccUaVhwMAAAAAaHWaPfr26NEjL7zwQnbdddd07949tVrtXbddu3Ztc48DAAAAAFC0Zo++1157bXbZZZem5+8VfQEAAAAA+GCaPfr+/i0dzjzzzOY+HAAAAABAq9amyoMtXrw4zzzzTNPrH//4xznxxBNz8cUXZ/PmzVWOAgAAAABQpEqj7znnnJMXXnghSfLSSy/l85//fHbeeefccccdueiii6ocBQAAAACgSJVG3xdeeCEHHXRQkuSOO+7IUUcdlR/84AeZM2dO5s6dW+UoAAAAAABFqjT6NjY2ZuvWrUmS+fPn59hjj02S1NfXZ82aNVWOAgAAAABQpEqj79ChQzN9+vR8//vfz8KFC3PcccclSZYvX55evXpVOQoAAAAAQJEqjb4zZszI4sWLM2HChFxyySXZc889kyR33nlnDjvssCpHAQAAAAAoUrsqDzZ48OA888wz261/4xvfSNu2bascBQAAAACgSJVe6fvyyy9n5cqVTa8ff/zxTJo0KTfffHPat29f5SgAAAAAAEWqNPr+5V/+Ze6///4kyerVq3P00Ufn8ccfzyWXXJJp06ZVOQoAAAAAQJEqjb7PPvtshg0bliS5/fbbs//+++fRRx/NLbfckjlz5lQ5CgAAAABAkSqNvm+//Xbq6uqSJPPnz88JJ5yQJNlnn32yatWqKkcBAAAAAChSpdF3v/32y4033piHHnoo9913X0aPHp0k+dWvfpWePXtWOQoAAAAAQJEqjb5XXXVVbrrppowYMSJjx47NgQcemCS5++67m277AAAAAADAn65dlQcbMWJE1qxZk4aGhnTv3r1pffz48dl5552rHAUAAAAAoEiVRt8kadu27TbBN0kGDBhQ9RgAAAAAAEWqPPreeeeduf3227NixYps3rx5m/cWL15c9TgAAAAAAEWp9J6+M2fOzLhx49KrV6889dRTGTZsWHr27JmXXnopY8aMqXIUAAAAAIAiVRp9v/3tb+c73/lOvvWtb2WnnXbKRRddlPvuuy8TJ07MunXrqhwFAAAAAKBIlUbfFStW5LDDDkuSdOzYMevXr0+SfOELX8itt95a5SgAAAAAAEWqNPr27t07a9euTZL069cvP/3pT5Mky5cvT2NjY5WjAAAAAAAUqdLoO3LkyNx9991JknHjxuX888/P0Ucfnc9//vP57Gc/W+UoAAAAAABFalflwb7zne9k69atSZK//du/Tc+ePfPoo4/mhBNOyDnnnFPlKAAAAAAARao0+rZp0yZt2vz/FxefeuqpOfXUU6scAQAAAACgaM0efZcsWfJHbzt48OBmnAQAAAAAoHzNHn0POuig1Gq1P/hFbbVaLVu2bGnucQAAAAAAitbs0Xf58uXNfQgAAAAAAP6vZo++/fv3b+5DAAAAAADwf7X5w5vsOFdeeWVmz5693frs2bNz1VVXVTkKAAAAAECRKo2+N910U/bZZ5/t1vfbb7/ceOONVY4CAAAAAFCkSqPv6tWr06dPn+3Wd9ttt6xatarKUQAAAAAAilRp9K2vr88jjzyy3fojjzySvn37VjkKAAAAAECRmv2L3H7f2WefnUmTJuXtt9/OyJEjkyQLFizIRRddlL//+7+vchSglTrgewe09AitzjNnPNPSIwAAAECrUmn0vfDCC/Paa6/lvPPOy+bNm5MkHTp0yJe//OVMmTKlylEAAAAAAIpUafSt1Wq56qqrcumll+a5555Lx44d8/GPfzx1dXVVjgEAAAAAUKxK7+n7O507d84hhxySfv365Sc/+Umee+65lhgDAAAAAKA4lUbfU045Jddff32S5M0338zQoUNzyimnZPDgwZk7d26VowAAAAAAFKnS6Pvggw/myCOPTJL86Ec/SmNjY15//fXMnDkz06dPr3IUAAAAAIAiVRp9161blx49eiRJ5s2bl5NOOik777xzjjvuuLz44otVjgIAAAAAUKRKo299fX0WLVqUjRs3Zt68efn0pz+dJPnf//3fdOjQocpRAAAAAACK1K7Kg02aNCmnnXZaOnfunP79+2fEiBFJfnvbhwMOOKDKUQAAAAAAilTplb7nnXdeFi1alNmzZ+fhhx9Omza/PfygQYPe9z19H3zwwRx//PHp27dvarVa7rrrrm3eP/PMM1Or1bZ5jB49eod9FgAAAACAD6NKr/RNkqFDh2bo0KHbrB133HHv++ds3LgxBx54YM4666x87nOfe8dtRo8ene9+97tNr+vq6t73cQAAAAAAPkqaPfpOnjw5V1xxRTp16pTJkye/57bf/OY3/+ifO2bMmIwZM+Y9t6mrq0vv3r3/6J8JAAAAAPBR1+zR96mnnsrbb7/d9Pzd1Gq1HX7sBx54IB/72MfSvXv3jBw5MtOnT0/Pnj13+HEAAAAAAD4smj363n///e/4vLmNHj06n/vc5zJw4MAsW7YsF198ccaMGZNFixalbdu277jPpk2bsmnTpqbXDQ0NVY0LAAAAALBDVH5P36qceuqpTc8POOCADB48OHvssUceeOCBfOpTn3rHfa688spMnTq1qhEBAAAAAHa4SqLvWWed9UdtN3v27GabYdCgQdl1112zdOnSd42+U6ZM2ea+ww0NDamvr2+2mQAAAAAAdrRKou+cOXPSv3//DBkyJI2NjVUccjsrV67Ma6+9lj59+rzrNnV1damrq6twKgAAAACAHauS6Hvuuefm1ltvzfLlyzNu3Lj81V/9VXr06PGBfuaGDRuydOnSptfLly/Pz372s/To0SM9evTI1KlTc9JJJ6V3795ZtmxZLrroouy555455phjPujHAQAAAAD40GpTxUFmzZqVVatW5aKLLso999yT+vr6nHLKKbn33nv/5Ct/n3jiiQwZMiRDhgxJkkyePDlDhgzJZZddlrZt22bJkiU54YQTstdee+WLX/xiDj744Dz00EOu5AUAAAAAilbZF7nV1dVl7NixGTt2bH75y19mzpw5Oe+88/Kb3/wmP//5z9O5c+f39fNGjBjxnsH43nvv/aAjAwAAAAB85FRype92B23TJrVaLY2NjdmyZUtLjAAAAAAAUKTKou+mTZty66235uijj85ee+2VZ555Jtdff31WrFjxvq/yBQAAAADgnVVye4fzzjsvt912W+rr63PWWWfl1ltvza677lrFoQEAAAAAWpVKou+NN96Yfv36ZdCgQVm4cGEWLlz4jtv927/9WxXjAAAAAAAUq5Loe/rpp6dWq1VxKAAAAACAVq2S6DtnzpwqDgMAAAAA0OpV9kVuAAAAAAA0v0qu9AXew+VdW3qC1mVgv5aeAAAAAKBZudIXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABTkIxt9H3zwwRx//PHp27dvarVa7rrrrm3eb2xszGWXXZY+ffqkBi64kwAAIABJREFUY8eOGTVqVF588cUWmhYAAAAAoBof2ei7cePGHHjggZk1a9Y7vv9P//RPmTlzZm688cY89thj6dSpU4455pi89dZbFU8KAAAAAFCddi09wJ9qzJgxGTNmzDu+19jYmBkzZuSrX/1qPvOZzyRJbr755vTq1St33XVXTj311CpHBQAAAACozEf2St/3snz58qxevTqjRo1qWuvatWsOPfTQLFq06F3327RpUxoaGrZ5AAAAAAB8lBQZfVevXp0k6dWr1zbrvXr1anrvnVx55ZXp2rVr06O+vr5Z5wQAAAAA2NGKjL5/qilTpmTdunVNj5dffrmlRwIAAAAAeF+KjL69e/dOkrzyyivbrL/yyitN772Turq6dOnSZZsHAAAAAMBHSZHRd+DAgendu3cWLFjQtNbQ0JDHHnssw4cPb8HJAAAAAACaV7uWHuBPtWHDhixdurTp9fLly/Ozn/0sPXr0SL9+/TJp0qRMnz49H//4xzNw4MBceuml6du3b0488cQWnBoAAAAAoHl9ZKPvE088kU9+8pNNrydPnpwkOeOMMzJnzpxcdNFF2bhxY8aPH5/XX389RxxxRObNm5cOHTq01MgAAAAAAM3uIxt9R4wYkcbGxnd9v1arZdq0aZk2bVqFUwEAAAAAtKwi7+kLAAAAANBaib4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABWnX0gMAAAAAQAkO+N4BLT1Cq/PMGc+09AgfSq70BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgxUbfyy+/PLVabZvHPvvs09JjAQAAAAA0q3YtPUBz2m+//TJ//vym1+3aFf1xAQAAAADKjr7t2rVL7969W3oMAAAAAIDKFHt7hyR58cUX07dv3wwaNCinnXZaVqxY8Z7bb9q0KQ0NDds8AAAAAAA+SoqNvoceemjmzJmTefPm5YYbbsjy5ctz5JFHZv369e+6z5VXXpmuXbs2Perr6yucGAAAAADggys2+o4ZMyYnn3xyBg8enGOOOSb//u//ntdffz233377u+4zZcqUrFu3runx8ssvVzgxAAAAAMAHV/Q9fX9ft27dstdee2Xp0qXvuk1dXV3q6uoqnAoAAAAAYMcq9krf/9eGDRuybNmy9OnTp6VHAQAAAABoNsVG3wsuuCALFy7ML37xizz66KP57Gc/m7Zt22bs2LEtPRoAAAAAQLMp9vYOK1euzNixY/Paa69lt912yxFHHJGf/vSn2W233Vp6NAAAAACAZlNs9L3ttttaegQAAAAAgMoVe3sHAAAAAIDWSPQFAAAAAChIsbd3AAAAAGj1Lu/a0hO0LgP7tfQEkMSVvgAAAAAARRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABWnX0gMAAAAArcOAr/yflh6h1flFh5aeAGgJrvQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAACiI6AsAAAAAUBDRFwAAAACgIKIvAAAAAEBBRF8AAAAAgIKIvgAAAAAABRF9AQAAAAAKIvoCAAAAABRE9AUAAAAAKIjoCwAAAABQENEXAAAAAKAgoi8AAAAAQEFEXwAAAACAgoi+AAAAAAAFEX0BAAAAAAoi+gIAAAAAFET0BQAAAAAoiOgLAAAAAFAQ0RcAAAAAoCCiLwAAAABAQURfAAAAAICCiL4AAAAAAAURfQEAAAAACiL6AgAAAAAURPQFAAAAAChI8dF31qxZGTBgQDp06JBDDz00jz/+eEuPBAAAAADQbIqOvj/84Q8zefLkfO1rX8vixYtz4IEH5phjjsmrr77a0qMBAAAAADSLoqPvN7/5zZx99tkZN25cPvGJT+TGG2/MzjvvnNmzZ7f0aAAAAAAAzaJdSw/QXDZv3pwnn3wyU6ZMaVpr06ZNRo0alUWLFr3jPps2bcqmTZuaXq9bty5J0tDQ0LzDfohs3fRGS4/Q6jTUGlt6hFZly5tbWnqEVqc1/RlK6+TcWS3nzeo5d1bLeZPSOW9Wz7mzWs6b1WtN587ffdbGxj/833Wx0XfNmjXZsmVLevXqtc16r1698vzzz7/jPldeeWWmTp263Xp9fX2zzAhJ0rWlB2h1nmvpAVqdruf6txzYcfyJ0hKcO6vkvAnsaP5UqZrzZtVa47lz/fr16dr1vT93sdH3TzFlypRMnjy56fXWrVuzdu3a9OzZM7VarQUngw+XhoaG1NfX5+WXX06XLl1aehwA+FBz3gSA98e5E95ZY2Nj1q9fn759+/7BbYuNvrvuumvatm2bV155ZZv1V155Jb17937Hferq6lJXV7fNWrdu3ZptRvio69KlixMwAPyRnDcB4P1x7oTt/aErfH+n2C9y22mnnXLwwQdnwYIFTWtbt27NggULMnz48BacDAAAAACg+RR7pW+STJ48OWeccUaGDh2aYcOGZcaMGdm4cWPGjRvX0qMBAAAAADSLtpdffvnlLT1Ec9l///3TrVu3fP3rX8/VV1+dJLnllluy9957t/Bk8NHXtm3bjBgxIu3aFf13RwCwQzhvAsD749wJH0ytsbGxsaWHAAAAAABgxyj2nr4AAAAAAK2R6AsAAAAAUBDRFwAAAACgIKIvUIkzzzwzJ554YkuPAQAfSiNGjMikSZNaegwAAAoh+kIr9qf8gumXUgAAAIAPN9EXAAB2kM2bN7f0CADwkeLcCc1D9IVW6swzz8zChQtz3XXXpVarpVar5Re/+EUWLlyYYcOGpa6uLn369MlXvvKV/OY3v3nPfbZs2ZIvfvGLGThwYDp27Ji999471113XQt/QgBofiNGjMiECRMyadKk7LrrrjnmmGPy7LPPZsyYMencuXN69eqVL3zhC1mzZk3TPhs3bszpp5+ezp07p0+fPrnmmmta8BMAwI61fv36nHbaaenUqVP69OmTa6+9dpv/Y3TAgAG54oorcvrpp6dLly4ZP358kuThhx/OkUcemY4dO6a+vj4TJ07Mxo0bm37upk2bcsEFF+TP/uzP0qlTpxx66KF54IEHmt6fM2dOunXrlnvvvTf77rtvOnfunNGjR2fVqlWVfn74sBB9oZW67rrrMnz48Jx99tlZtWpVVq1alfbt2+fYY4/NIYcckqeffjo33HBD/uVf/iXTp09/133q6+uzdevW7L777rnjjjvyX//1X7nsssty8cUX5/bbb2/hTwkAze973/tedtpppzzyyCP5x3/8x4wcOTJDhgzJE088kXnz5uWVV17JKaec0rT9hRdemIULF+bHP/5x/uM//iMPPPBAFi9e3IKfAAB2nMmTJ+eRRx7J3Xffnfvuuy8PPfTQdue5q6++OgceeGCeeuqpXHrppVm2bFlGjx6dk046KUuWLMkPf/jDPPzww5kwYULTPhMmTMiiRYty2223ZcmSJTn55JMzevTovPjii03bvPHGG7n66qvz/e9/Pw8++GBWrFiRCy64oLLPDh8mtcbGxsaWHgJoGSNGjMhBBx2UGTNmJEkuueSSzJ07N88991xqtVqS5Nvf/na+/OUvZ926dWnTps12+7ybCRMmZPXq1bnzzjuT/PYq4ddffz133XVX834oAKjQiBEj0tDQ0PTL7PTp0/PQQw/l3nvvbdpm5cqVqa+vz3//93+nb9++6dmzZ/71X/81J598cpJk7dq12X333TN+/Pg/eH4FgA+z9evXp2fPnvnBD36Qv/iLv0iSrFu3Ln379s3ZZ5+dGTNmZMCAARkyZEh+9KMfNe3313/912nbtm1uuummprWHH344Rx11VDZu3JhXX301gwYNyooVK9K3b9+mbUaNGpVhw4blH/7hHzJnzpyMGzcuS5cuzR577JHkt7/PTps2LatXr67onwB8eLRr6QGAD4/nnnsuw4cPbwq+SXL44Ydnw4YNWblyZfr16/eu+86aNSuzZ8/OihUr8uabb2bz5s056KCDqhgbAFrUwQcf3PT86aefzv3335/OnTtvt92yZcuazpGHHnpo03qPHj2y9957VzIrADSnl156KW+//XaGDRvWtNa1a9ftznNDhw7d5vXTTz+dJUuW5JZbbmlaa2xszNatW7N8+fK89NJL2bJlS/baa69t9tu0aVN69uzZ9HrnnXduCr5J0qdPn7z66qs75LPBR43oC3xgt912Wy644IJcc801GT58eHbZZZd84xvfyGOPPdbSowFAs+vUqVPT8w0bNuT444/PVVddtd12ffr0ydKlS6scDQA+lH7/3Jn89vx5zjnnZOLEidtt269fvyxZsiRt27bNk08+mbZt227z/u//RWv79u23ea9Wq8X/4E5rJfpCK7bTTjtly5YtTa/33XffzJ07N42NjU1X+z7yyCPZZZddsvvuu7/jPr/b5rDDDst55533/7V353E15f8fwF8t9972RBtKF0lZQighDeLay3hgGkZoohAGZfyGb8bYyTC+hhmDyjYzjdDXkqXFEkIqWwupyZIlsqRBy/v3R4/OdHRbJ+u8n4/HfTw653z2cz6f+PS55yOcS09Pfws1YIwxxt4vdnZ22LVrF+RyOdTVy/9Tu3nz5pBIJIiLixO+QZObm4u0tDQ4Ozu/7eIyxhhjdapZs2aQSCQ4d+6c8HvuyZMnSEtLQ48ePSqMZ2dnh6tXr8LS0lLp9Q4dOqCoqAj379+Hk5PTGyk7Yx8b3siNsX8xuVyOuLg4ZGZmIicnB5MmTcLNmzfh6+uLlJQU7N27FwEBAZgxYwZUVVWVxikuLkaLFi1w/vx5HDp0CGlpaZg3bx7OnTv3jmvHGGOMvX2TJ0/Go0eP4O7ujnPnziE9PR2HDh3CuHHjUFRUBB0dHXh6esLPzw9RUVG4fPkyxo4dK/yeZYwxxj5kurq68PDwgJ+fH6Kjo3HlyhV4enpCVVVV9BrB182ePRunTp3ClClTkJiYiGvXrmHv3r3CRm5WVlYYNWoUxowZg7CwMGRkZODs2bNYsmQJ9u/f/7aqx9gHhf91ydi/2KxZs6CmpoZWrVrByMgIBQUFOHDgAM6ePYt27drB29sbnp6emDt3boVxsrKyMHHiRHz66acYOXIkHBwc8PDhQ9GqX8YYY+zfolGjRoiNjUVRURH69u2Ltm3bYvr06ahXr54wsbtixQo4OTlh8ODBcHFxQffu3UXvBWaMMcY+ZKtWrYKjoyMGDRoEFxcXdOvWDTY2NtDQ0Kgwjq2tLY4dO4a0tDQ4OTmhQ4cO+M9//iPatG3Lli0YM2YMZs6ciZYtW8LNzU20opgxJqZC/HITxhhjjDHGGGOMMfYGPH/+HI0bN0ZgYCA8PT3fdXEY+9fgd/oyxhhjjDHGGGOMsTqRkJCAlJQU2Nvb48mTJ1iwYAEAwNXV9R2XjLF/F570ZYwxxhhjjDHGGGN1ZuXKlUhNTYVUKkXHjh1x4sQJGBoavutiMfavwq93YIwxxhhjjDHGGGOMsY8Ib+TGGGOMMcYYY4wxxhhjHxGe9GWMMcYYY4wxxhhjjLGPCE/6MsYYY4wxxhhjjDHG2EeEJ33/pTIzM6GiooLExMR3XZR/BblcjtWrV9d5uioqKtizZ0+dp8tKcD9hb1pQUBDq1av3roshqIsxJTY2Fm3btoVEIoGbm1sdlYwxxhhjjDHGWE3UaNJ37NixUFFRgYqKCiQSCUxMTNCnTx9s3rwZxcXFNcr4Xf1Hd+zYsf/4P6ETJ06EmpoaQkNDaxX/k08+Edqx7Mfb2/sflet9k5SUBHd3d5ibm0NTUxM2NjZYs2ZNuXAxMTGws7ODTCaDpaUlgoKCyoVZt24d5HI5NDQ04ODggLNnz9aoLKWTd6UfqVQKS0tLLFy4EDXdy/BtTbQ+ePAAPj4+aNKkCWQyGUxNTaFQKBAbGyuEyc7ORv/+/d94WV4XFBQEW1tbaGhowNjYGJMnT1Ya7vr169DV1a1VX/+Q+8mbmuT/kNS2DV7vq6WfM2fOiMKFhobC2toaGhoaaNu2LQ4cOFDjvJTlo6Kigl9//bXGabG/zZgxA+3bt0dGRobS8Rwo6d/Tp09/uwV7z/yTNpg6dSo6duwImUyG9u3bl7v+NvsRY4wxxhhj7P2kXtMI/fr1w5YtW1BUVIR79+4hIiIC06ZNwx9//IHw8HCoq9c4yQ9Kfn4+fv31V/j7+2Pz5s0YPnx4rdLx8vLCggULROe0tLTqoojvjfj4eBgbG2Pbtm0wNzfHqVOnMGHCBKipqWHKlCkAgIyMDAwcOBDe3t7Yvn07IiMj8eWXX6Jhw4ZQKBQAgN9++w0zZszAhg0b4ODggNWrV0OhUCA1NRXGxsY1KtPRo0fRunVrvHz5EidPnhTy8vT0rPP6/1PDhg3Dq1evEBwcjGbNmuHevXuIjIzEw4cPhTCmpqZvvVyrVq1CYGAgVqxYAQcHBzx//hyZmZnlwhUUFMDd3R1OTk44depUrfL6N/ST2nj16hWkUum7LsYbVdpXSzVo0ED4+dSpU3B3d8eSJUswaNAg7NixA25ubrhw4QLatGlTo3y2bNmCfv36ic69TytvP0Tp6enw9vaGmZnZOyvDv6GPjB8/HnFxcbh48WKFYd5WP2KMMcYYY4y9h6gGPDw8yNXVtdz5yMhIAkAbN24UzgUGBlKbNm1IS0uLzMzMyMfHh549e0ZERNHR0QRA9AkICCAiopCQEOrYsSPp6OiQiYkJubu7071794R0Hz16RJ9//jkZGhqShoYGWVpa0ubNm4XrWVlZNHz4cNLX1ycDAwMaMmQIZWRkEBFRQEBAuXyjo6Nr0gQUFBREXbp0ocePH5OWlhZlZWXVKD4RkbOzM02bNq3C6xkZGQSAdu7cSY6OjiSTyah169YUExMjChcTE0OdO3cmqVRKpqamNHv2bCooKBCuFxUV0bJly6h58+YklUrJ3NycFi5cKMpj165d9Mknn5CmpibZ2trSqVOnhPiZmZk0aNAgqlevHmlpaVGrVq1o//79Na5vWZMmTaKePXsKx/7+/tS6dWtRmJEjR5JCoRCO7e3tafLkyaJ6NWrUiJYsWVLtfEvrm5CQIDrfu3dvmjRpknB89uxZcnFxoQYNGpCenh716NGD4uPjhesWFhai58fCwkK4Fh4eTp06dSKZTEYNGjQgNzc3UbxFixbRuHHjSEdHh8zNzemnn36qsLy5ubkEoNw9fx0A2r17NxEpf74B0JYtW4iopN0WL15McrmcNDQ0yNbWlkJDQ6tsu7IePXpEmpqadPTo0SrD+vv70+jRo2nLli2kr69fo3yIPpx+ooyFhQV9//33wnHp+Ojm5kaamppkaWlJe/fuFcW5fPkyDRw4kHR1dUlHR4e6d+9O169fJ6K/x96FCxdSw4YNSS6XE1Hl413ZeIsWLSJjY2PS19enb7/9lgoKCmjWrFlkYGBAjRs3Fo2hNUl3xYoVZGpqSvXr16dJkybRq1evhHv3+nNYXRX11bJGjBhBAwcOFJ1zcHCgiRMnVjsfInH/Uab02d29ezdZWlqSTCajvn37lhv3f/zxR2rWrBlJJBKysrKikJAQ0fXc3FyaMGECGRsbC8/p//73P1EeERERZG1tTdra2qRQKOjOnTuVlv3SpUvUr18/0tbWJmNjYxo9ejQ9ePBAuO7s7Ey+vr7k5+dHBgYGZGJiIvyeLZWWlkZOTk4kk8nIxsaGDh8+XGWbvHjxgnx9fcnIyIhkMhl169aNzp49S0R/3ztl48/rXu/f1Rkjb968SZ999hkZGBiQlpYWdezYkc6cOUNEJeNfu3btaOPGjSSXy0lFRUVoe09PTzI0NCRdXV3q2bMnJSYmCmmWxtu0aROZm5uTtrY2+fj4UGFhIS1btoxMTEzIyMhIGBNKVTfdkJAQsrCwID09PRo5ciQ9ffqUiEr60OttVbaPVVdpPq97m/2IMcYYY4wx9n6qk3f69urVC+3atUNYWJhwTlVVFT/88AOuXLmC4OBgREVFwd/fHwDQtWtXrF69Gnp6esjOzkZ2djZmzZoFoGR14HfffYekpCTs2bMHmZmZGDt2rJDuvHnzcPXqVRw8eBDJyclYv349DA0NhbgKhQK6uro4ceIEYmNjoaOjg379+uHVq1eYNWsWRowYgX79+gn5du3aFUDJ1yzL5lORTZs2YfTo0dDX10f//v0r/OpqXfDz88PMmTORkJAAR0dHDB48WFjlefv2bQwYMACdO3dGUlIS1q9fj02bNmHhwoVC/Dlz5mDp0qVCm+3YsQMmJiaiPL755hvMmjULiYmJsLKygru7OwoLCwEAkydPxsuXL3H8+HFcunQJy5Ytg46OjhBXLpdj/vz5NarTkydPUL9+feH49OnTcHFxEYVRKBQ4ffo0gJLVWvHx8aIwqqqqcHFxEcLU1vnz5xEfHw8HBwfh3LNnz+Dh4YGTJ0/izJkzaNGiBQYMGIBnz54BAM6dOwegZHVgdna2cLx//34MHToUAwYMQEJCAiIjI2Fvby/KLzAwEJ06dUJCQgImTZoEHx8fpKamKi2bjo4OdHR0sGfPHrx8+bJa9Zk1a5bwXGdnZ2PlypXQ0tJCp06dAABLlixBSEgINmzYgCtXruCrr77C6NGjcezYMSGNqu7pkSNHUFxcjNu3b8PGxgZmZmYYMWIEbt68KQoXFRWF0NBQrFu3rlpl/yfedT+prm+//RYjRozAxYsXMWDAAIwaNQqPHj0SytmjRw/IZDJERUUhPj4e48ePF+URGRmJ1NRUHDlyBPuRn/shAAAVUElEQVT27atyvCsVFRWFO3fu4Pjx41i1ahUCAgIwaNAgGBgYIC4uDt7e3pg4cSJu3boFoOpxtFR0dDTS09MRHR2N4OBgBAUFCeNhWFgYzMzMsGDBAuF5LKWiolKtcXPIkCEwNjZG9+7dER4eLrpW1bhRl/Lz87Fo0SKEhIQgNjYWjx8/xmeffSZc3717N6ZNm4aZM2fi8uXLmDhxIsaNG4fo6GgAQHFxMfr374/Y2Fhs27YNV69exdKlS6GmpibKY+XKldi6dSuOHz+OrKws4XeiMo8fP0avXr3QoUMHnD9/HhEREbh37x5GjBghChccHAxtbW3ExcVh+fLlWLBgAY4cOSKU69NPP4VUKkVcXBw2bNiA2bNnV9ke/v7+2LVrF4KDg3HhwgVYWlpCoVDg0aNHMDc3R3Z2NvT09LB69WpkZ2dj5MiR1W7rysbIvLw8ODs74/bt2wgPD0dSUhL8/f1Fr5a6fv06du3ahbCwMOE93MOHD8f9+/dx8OBBxMfHw87ODr179xb6HlCyMvngwYOIiIjAzp07sWnTJgwcOBC3bt3CsWPHsGzZMsydOxdxcXFCnOqmu2fPHuzbtw/79u3DsWPHsHTpUgDAmjVr4OjoCC8vL6GPmJubA6jd79aKvC/9iDHGGGOMMfYO1GSGuKKVvkQlqzNtbGwqjBsaGkoNGjQQjqu7+u/cuXMEQFglPHjwYBo3bpzSsFu3bqWWLVtScXGxcO7ly5ekqalJhw4dqrQOX3zxBX399deVliUtLY0kEomwmmr37t3UtGlTUX7V4ezsTBKJhLS1tUWfbdu2EdHfK3SWLl0qxCkoKCAzMzNatmwZERH93//9X7m6rlu3jnR0dKioqIiePn1KMplMtPq6rNI8fvnlF+HclStXCAAlJycTEVHbtm1p/vz5FdajV69etHbt2mrXOzY2ltTV1YV7QUTUokULWrx4sSjc/v37CQDl5+fT7du3CUC5lZV+fn5kb29f7bxL66upqUna2tokkUgIAE2YMKHSeEVFRaSrqyusyiNSvjrQ0dGRRo0aVWE6FhYWNHr0aOG4uLiYjI2Naf369RXG+eOPP8jAwIA0NDSoa9euNGfOHEpKShKFUVYWIqLTp0+ThoYG/fbbb0RUsjpPS0urXDt6enqSu7u7cFzVPV2yZAlJJBJq2bIlRURE0OnTp6l3797UsmVLevnyJRER5eTkkLm5OR07doyIqt/XX/eh9BNllK30nTt3rnCcl5dHAOjgwYNERDRnzhxq2rSpsFL2dR4eHmRiYiK0MVH1xzsLCwsqKioSwrRs2ZKcnJyE48LCQtLW1qadO3fWON3CwkIhzPDhw2nkyJEVtkHZ/MPCwpTWk4jowYMHFBgYSGfOnKGzZ8/S7NmzSUVFRbQyWiKR0I4dO0Tx1q1bR8bGxhWmqwwA0tDQKPeM/fnnn0RU8uwCEFaTEhElJycTAIqLiyMioq5du5KXl5co3eHDh9OAAQOIiOjQoUOkqqpKqampSstQmkfpqu7SupiYmFRY7u+++4769u0rOnfz5k0CIOTj7OxM3bt3F4Xp3LkzzZ49WyiXuro63b59W7h+8ODBSlf65uXlkUQioe3btwvnXr16RY0aNaLly5cL5/T19Stc4VtK2UrfysbIn376iXR1denhw4dK0wsICCCJREL3798Xzp04cYL09PToxYsXorDNmzcXVhEHBASQlpaWsAKXiEihUJBcLi/Xb0q/XVLbdP38/MjBwaHCNihVk9+tFa30fZv9iDHGGGOMMfZ+qrMX8BIRVFRUhOOjR49iyZIlSElJwdOnT1FYWIgXL14gPz+/0ndyxsfHY/78+UhKSkJubq6wiicrKwutWrWCj48Phg0bhgsXLqBv375wc3MTVusmJSUJG0eV9eLFC6Snp1da/pCQkCrruHnzZigUCmFl8YABA+Dp6YmoqCj07t27yvhljRo1Ct98843o3OurCx0dHYWf1dXV0alTJyQnJwMAkpOT4ejoKGrzbt26IS8vD7du3cLdu3fx8uXLKstla2sr/NywYUMAwP3792FtbY2pU6fCx8cHhw8fhouLC4YNGyYKHxkZWe36Xr58Ga6urggICEDfvn2rHa+u/fbbb7CxsUFBQQEuX74MX19fGBgYCKuv7t27h7lz5yImJgb3799HUVER8vPzkZWVVWm6iYmJ8PLyqjRM2bZTUVGBqakp7t+/X2H4YcOGYeDAgThx4gTOnDmDgwcPYvny5fjll18qXZWelZUFNzc3YWU7ULICLj8/H3369BGFffXqFTp06CAcV3VPi4uLUVBQgB9++EG4jzt37oSpqSmio6OhUCjg5eWFzz//HD169Kg0rer4EPpJdZVNQ1tbG3p6esL9T0xMhJOTEyQSSYXx27ZtK3pHaXXHu9atW0NV9e8vdZiYmIje16mmpoYGDRoIZalJumVXqzZs2BCXLl2qvBEApKSkVHrd0NAQM2bMEI47d+6MO3fuYMWKFRgyZEiV6dfU999/X261Y6NGjYSf1dXV0blzZ+HY2toa9erVQ3JyMuzt7ZGcnIwJEyaI4nfr1k3YtDIxMRFmZmawsrKqsAxaWlpo3ry5cNywYcNKx4akpCRER0eLvnlRKj09Xcir7DP3errJyckwNzcX1bVsX1ImPT0dBQUF6Natm3BOIpEI7fBPVTZGJiYmokOHDqJvirzOwsICRkZGwnFSUhLy8vJE77EFgL/++kv0LMvlctHzbmJiAjU1tXL9pmwfqU26Vd3XUjX53VqRt92PGGOMMcYYY++fOpv0TU5ORtOmTQGU7Bo9aNAg+Pj4YNGiRahfvz5OnjwJT09PvHr1qsJJ3+fPn0OhUEChUGD79u0wMjJCVlYWFAqF8LXi/v37488//8SBAwdw5MgR9O7dG5MnT8bKlSuRl5eHjh07Yvv27eXSLvsfwdooKipCcHAw7t69K9qsrqioCJs3b67xpK++vj4sLS3/UZkqo6mpWa1wZSeZSifGSifav/zySygUCuzfvx+HDx/GkiVLEBgYCF9f3xqV5erVq+jduzcmTJiAuXPniq6Zmpri3r17onP37t2Dnp4eNDU1oaamBjU1NaVharOJmbm5udDuNjY2SE9Px7x58zB//nxoaGjAw8MDDx8+xJo1a2BhYQGZTAZHR0fR19qVqU57vz6hp6KiIvpqsjIaGhro06cP+vTpg3nz5uHLL79EQEBAhZO+z58/x5AhQ+Do6CjaAC0vLw9AyWsoGjduLIojk8mqLHup0gnPVq1aCeeMjIxgaGgoTIxHRUUhPDwcK1euBFDyB6Hi4mKoq6vj559/xvjx46ud34fQT6qrsvtfnXJoa2uLjqs73inLt7Ky/JN0a9om1eXg4CC8lgCoeNyozZhgamr6zp8xZW1JRBWGz8vLw+DBg7Fs2bJy10r7aEXpvql7VBfeRB9p2LAhYmJiyoUtu1lfbfpIbdN9l+3/JvsRY4wxxhhj7P1TJ+/0jYqKwqVLlzBs2DAAJat1i4uLERgYiC5dusDKygp37twRxZFKpSgqKhKdS0lJwcOHD7F06VI4OTnB2tpa6aoYIyMjeHh4YNu2bVi9ejV+/vlnAICdnR2uXbsGY2NjWFpaij76+voV5lsdBw4cwLNnz5CQkIDExEThs3PnToSFheHx48c1TrMqZ86cEX4uLCxEfHw8bGxsAJRMWJ4+fVo0MRAbGwtdXV2YmZmhRYsW0NTU/McrhszNzeHt7Y2wsDDMnDkTGzdurFH8K1euoGfPnvDw8MCiRYvKXXd0dCxXxiNHjggrzqRSKTp27CgKU1xcjMjIyCpXpVWHmpoaCgsLhUnd2NhYTJ06FQMGDEDr1q0hk8mQk5MjiiORSMo9Q7a2tnWyOqsqrVq1wvPnz5VeIyKMHj0axcXF2Lp1q2h1a6tWrSCTyZCVlVWub5S+R7I6Slf4lX0X8aNHj5CTkwMLCwsAJe+JLNtHFixYAF1dXSQmJmLo0KG1qXal3od+8k/Z2trixIkTKCgoqHac6ox3tVFX6dZ2rFUmMTFRNJlZ1bhRlwoLC3H+/HnhODU1FY8fPxY9Y7GxsaI4sbGxwh9GbG1tcevWLaSlpdVZmezs7HDlyhXI5fJy9+j1ic+K2NjY4ObNm6L3LZftS8o0b94cUqlUVN+CggKcO3dO9IegN8HW1haJiYmid+ZWxc7OTvhD7evtVPqNndqoq3Trso9Ux7vsR4wxxhhjjLG3r8aTvi9fvsTdu3dx+/ZtXLhwAYsXL4arqysGDRqEMWPGAAAsLS1RUFCAtWvX4saNG9i6dSs2bNggSkculyMvLw+RkZHIyclBfn4+mjRpAqlUKsQLDw/Hd999J4r3n//8B3v37sX169dx5coV7Nu3T/jP96hRo2BoaAhXV1ecOHECGRkZiImJwdSpU4VNiuRyOS5evIjU1FTk5OQIkyxjxozBnDlzKqx36cYu7dq1Q5s2bYTPiBEjUK9ePaWr4iqTn5+Pu3fvij65ubmiMOvWrcPu3buRkpKCyZMnIzc3V1glOWnSJNy8eRO+vr5ISUnB3r17ERAQgBkzZkBVVRUaGhqYPXs2/P39ERISgvT0dJw5cwabNm2qdhmnT5+OQ4cOISMjAxcuXEB0dLTQ1gDQu3dv/Pe//60w/uXLl9GzZ0/07dsXM2bMEOr54MEDIYy3tzdu3LgBf39/pKSk4Mcff8Tvv/+Or776SggzY8YMbNy4EcHBwUhOToaPjw+eP3+OcePGVbsupR4+fIi7d+/i1q1bOHjwINasWYOePXtCT08PANCiRQts3boVycnJiIuLw6hRo8qtMJPL5YiMjBTds4CAAOzcuRMBAQFITk4WNr6rrYcPH6JXr17Ytm0bLl68iIyMDISGhmL58uVwdXVVGmf+/Pk4evQofvrpJ+Tl5Qnt/ddff0FXVxezZs3CV199heDgYKSnp+PChQtYu3YtgoODhTSquqdWVlZwdXXFtGnTcOrUKVy+fBkeHh6wtrZGz549AZRMJpXtI40bN4aqqiratGkDAwODGrXDh9BP6sKUKVPw9OlTfPbZZzh//jyuXbuGrVu3VrjRH1C98a426ipduVyO48eP4/bt26I/nFhbW2P37t0VxgsODsbOnTuRkpKClJQULF68GJs3bxZ9w2DatGmIiIhAYGAgUlJSMH/+fJw/fx5TpkypcX0fP35c7hkr+4cViUQCX19fxMXFIT4+HmPHjkWXLl2EjRr9/PwQFBSE9evX49q1a1i1ahXCwsKEjdicnZ3Ro0cPDBs2DEeOHEFGRoawaVhtTZ48GY8ePYK7uzvOnTuH9PR0HDp0COPGjav2JKKLiwusrKzg4eGBpKQknDhxotyrVF6nra0NHx8f+Pn5ISIiAlevXoWXlxfy8/Ph6elZ6/pUh7u7O0xNTeHm5obY2FjcuHEDu3btqnTTMRcXFzg6OsLNzQ2HDx9GZmYmTp06hW+++UY0kV9TdZWuXC5HXFwcMjMzkZOTI6wCrmocBkpe2ZOYmCiM8aV/ZCv9A+bb7keMMcYYY4yx91BNXgDs4eFBAAgAqaurk5GREbm4uNDmzZtFG54QEa1atYoaNmxImpqapFAoKCQkhABQbm6uEMbb25saNGhAACggIICIiHbs2EFyuZxkMhk5OjpSeHg4AaCEhAQiKtnAxsbGhjQ1Nal+/frk6upKN27cENLMzs6mMWPGkKGhIclkMmrWrBl5eXnRkydPiIjo/v371KdPH9LR0SEAFB0dTUQlG6p4eHgorffdu3dJXV2dfv/9d6XXfXx8qEOHDkREFB0dTQAoIyOjwnZ0dnYW2rHsR6FQENHfm0ft2LGD7O3tSSqVUqtWrSgqKkqUTkxMDHXu3JmkUimZmprS7NmzqaCgQLheVFRECxcuJAsLC5JIJNSkSRNh07TSPErblYgoNzdX1CZTpkyh5s2bk0wmIyMjI/riiy8oJydHCG9hYSHcN2UCAgKU1tPCwkIULjo6mtq3b09SqZSaNWumdAOgtWvXUpMmTUgqlZK9vb1oYyWikmfT2dm5wrKU1rf0o6amRmZmZuTl5SXa+OfChQvUqVMn0tDQoBYtWlBoaGi5DanCw8PJ0tKS1NXVRXXZtWuXUA9DQ0P69NNPRW31+qZW7dq1q7D9Xrx4QV9//TXZ2dmRvr4+aWlpUcuWLWnu3LmUn58vhEOZTZcqeq5K27O4uJhWr15NLVu2JIlEQkZGRqRQKIQN10rLWdk9JSJ68uQJjR8/nurVq0f169enoUOHUlZWVoXhlW3k9jH1E2WUbeT2+uZYr292lZSURH379iUtLS3S1dUlJycnSk9PJ6KKN6CsarxTFk/Z5lGvl7c26U6bNk3UB0+fPk22trYkk8mo7K+ass+kMkFBQWRjY0NaWlqkp6dH9vb2FBoaWi7c77//TlZWViSVSql169a0f/9+0fWAgIByY83rlD1fAIQNu0qf3V27dlGzZs1IJpORi4uLsNFbqR9//JGaNWtGEomErKysKCQkRHT94cOHNG7cOGrQoAFpaGhQmzZtaN++faI8ytq9e7eozZRJS0ujoUOHUr169UhTU5Osra1p+vTpwgZ8yu6zq6ur6Pdcamoqde/enaRSKVlZWVFERESlG7kREf3111/k6+srPBvdunWjs2fPisLUdiO3qsbIzMxMGjZsGOnp6ZGWlhZ16tRJ2FCvog3Nnj59Sr6+vtSoUSOSSCRkbm5Oo0aNEsYsZfGq029qk+73338veiZTU1OpS5cupKmpKRoPqzMOVzQ+lqZRV/2IMcYYY4wx9uFSIarkxYGsxrZs2YLFixfj6tWrlW7KVJnMzEw0bdoUCQkJaN++fR2X8OPk7OyMnj17Yv78+e+6KKwauJ+wN83DwwMqKioICgqqdRpBQUGYPn36G3l9D2OMMcYYY4wx9ibV2UZurMSBAwewePHiWk9ksZp78uQJ0tPTsX///nddFFZN3E/Ym0REiImJwcmTJ991URhjjDHGGGOMsXeCJ33rWGho6Lsuwr+Ovr7+P3qHKXv7uJ+wN0lFRQV//vnnuy4GY4wxxhhjjDH2zvDrHRhjjDHGGGOMMcYYY+wjovquC8AYY4wxxhhjjDHGGGOs7vCkL2OMMcYYY4wxxhhjjH1EeNKXMcYYY4wxxhhjjDHGPiI86csYY4wxxhhjjDHGGGMfEZ70ZYwxxhhjjDHGGGOMsY8IT/oyxhhjjDHGGGOMMcbYR4QnfRljjDHGGGOMMcYYY+wjwpO+jDHGGGOMMcYYY4wx9hHhSV/GGGOMMcYYY4wxxhj7iPw/oTK7rsyoTNMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1400x1000 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}