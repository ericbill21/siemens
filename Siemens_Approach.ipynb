{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siemens_Approach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericbill21/siemens/blob/cleanup/Siemens_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W70udFHYSHNI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb8e5c9b-274c-48ab-ccaa-5954483b2ad1"
      },
      "source": [
        "#@title Imports and coinfig\n",
        "%tensorflow_version 2.x\n",
        "from IPython.display import clear_output\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "import sys\n",
        "import gc\n",
        "import logging\n",
        "import time\n",
        "#tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "#time prediciton\n",
        "prev_time = 0\n",
        "\n",
        "plt.style.use('seaborn')\n",
        "plt.figure(figsize=(4,4))\n",
        "\n",
        "tf.random.set_seed(31415)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E98cwmoUT7w1"
      },
      "source": [
        "#@title Global constants\n",
        "\n",
        "#Dictionaries\n",
        "colors = {0 : 'green', 1 : 'red', 'green' : 0, 'red' : 1}\n",
        "sources = {'A' : 'https://drive.google.com/file/d/1hAzAKZNpmSclSI7HnV_cRjpMS4Kh5r1q/view?usp=sharing', 'B' : 'https://drive.google.com/file/d/12VlecL-5iYs-BFpnTOba1x65jWofBX1P/view?usp=sharing', 'C' : 'https://drive.google.com/file/d/1-Z0RuJIi1cZcqrrmV6TqT0O1PwI2OiBY/view?usp=sharing'}\n",
        "SOURCE_SIZE = {'A': 1000,'B' : 5000, 'C' : 50000}\n",
        "\n",
        "CURRENT_SET = 'B'\n",
        "\n",
        "#Examlpe subsets of each dataset\n",
        "subsetA = [47, 847, 993, 55, 102, 572, 430, 115, 842, 72, 770, 107, 78, 834, 593, 43, 234, 709, 210, 378]\n",
        "subsetB = [606, 2663, 1809, 2145, 4539, 3333, 3562, 2262, 512, 2046, 1541, 909, 286, 4815, 3663, 1742, 2822, 2756, 2937, 3080, 3845, 3949, 2506, 3984, 2803, 2067]\n",
        "subsetC = [32088, 33534, 39634, 40177, 25142, 752, 41771, 11793, 16415, 3811, 2096, 35902, 42221, 19594, 25109, 40476, 25162, 41150, 34610, 28329, 46339, 43149, 44441, 25720, 38747, 49497, 12708, 23920, 2280, 17946]\n",
        "\n",
        "VAL_INDICES = subsetB\n",
        "\n",
        "#Penalty applied to false green classifications in custom loss function\n",
        "PENALTY = 0.3"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISkimS6oUTP9",
        "cellView": "code"
      },
      "source": [
        "#@title Functions\n",
        "\n",
        "def getDataSet():\n",
        "  path = 'https://drive.google.com/uc?export=download&id='+sources[CURRENT_SET].split('/')[-2]\n",
        "  return pd.read_excel(path)\n",
        "\n",
        "\n",
        "#Plots the given dataSet in the rigth colors\n",
        "def makePlot(dataSet = None, correct_pred_points = [], incorrect_pred_points = []):\n",
        "\n",
        "  # if optional parameter dataSet is not set\n",
        "  if dataSet == None:\n",
        "    dataSet = getDataSet() \n",
        "\n",
        "  # Cheching for the right type\n",
        "  if not isinstance(dataSet, pd.DataFrame):\n",
        "    raise TypeError(f'dataSet is of type: {type(dataSet)}, but should be {pd.DataFrame}')\n",
        "\n",
        "\n",
        "  # Cheching for the right shape \n",
        "  if len(np.array(correct_pred_points).shape) != 2 and np.array(correct_pred_points).shape != (0,):\n",
        "    raise TypeError(f'The shape of the parameter correct_pred_points is: {np.array(correct_pred_points).shape}, but it should be 2 dimensional')\n",
        "  \n",
        "  if len(np.array(incorrect_pred_points).shape) != 2 and np.array(incorrect_pred_points).shape != (0,):\n",
        "    raise TypeError(f'The shape of the parameter incorrect_pred_points is: {np.array(incorrect_pred_points).shape}, but it should be 2 dimensional')\n",
        "  \n",
        "  # Creating a subplot\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  # Scattering all points\n",
        "  for i in range(2):\n",
        "    x_1 = np.array(dataSet['x_i1'].loc[dataSet['l_i'] == i])\n",
        "    x_2 = np.array(dataSet['x_i2'].loc[dataSet['l_i'] == i])\n",
        "    ax.scatter(x_1, x_2, c = colors[i])\n",
        "\n",
        "\n",
        "  # Adding markers to the specified points\n",
        "  ax.scatter(correct_pred_points[:, 0],correct_pred_points[:, 1],marker = \"x\", c = 'black', label='correct')\n",
        "  ax.scatter(incorrect_pred_points[:, 0], incorrect_pred_points[:, 1], marker = \"*\", c = 'black', label='incorrect')\n",
        "\n",
        "\n",
        "  # Setting parameters for ploting\n",
        "  ax.legend()\n",
        "  plt.legend()\n",
        "  plt.xlabel('x_i1')\n",
        "  plt.ylabel('x_i2')\n",
        "  plt.title(f'DataSet {CURRENT_SET}')\n",
        "  plt.axis('scaled')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Prepares a subset of the dataSet for validation\n",
        "def seperateValidationSet(dataSet, validationIndices):\n",
        "\n",
        "  # Cheching for the right type\n",
        "  if not isinstance(dataSet, pd.DataFrame):\n",
        "    raise TypeError(f'dataSet is of type: {type(dataSet)}, but should be {pd.DataFrame}')\n",
        "\n",
        "  # Cheching for the right shape \n",
        "  if len(np.array(validationIndices).shape) != 1:\n",
        "    raise TypeError(f'The shape of the parameter validationIndices is: {np.array(validationIndices).shape}, but it should be 1 dimensional')\n",
        "  \n",
        "\n",
        "  sampleSet_features = []\n",
        "  sampleSet_labels = []\n",
        "\n",
        "  for i in validationIndices:\n",
        "    sampleSet_features.append([dataSet['x_i1'].loc[i], dataSet['x_i2'].loc[i]])\n",
        "    sampleSet_labels.append([dataSet['l_i'].loc[i]])\n",
        "  \n",
        "  #Saving the testing points\n",
        "  prediction_point = tf.constant(sampleSet_features, tf.float32)\n",
        "  prediciton_label = tf.constant(sampleSet_labels, tf.float32)\n",
        "\n",
        "  #Removing the testing point\n",
        "  dataSet.drop(index=validationIndices, inplace=True)\n",
        "  dataSet.reset_index(inplace=True)\n",
        "\n",
        "  return (prediction_point, prediciton_label)\n",
        "\n",
        "\n",
        "\n",
        "# Print iterations progress\n",
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
        "\n",
        "    # Preparing strings\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "\n",
        "    # Writing strings to console\n",
        "    sys.stdout.write(f'\\r{prefix} |{bar}| {percent}% ETA: {round(timeCalc()*(total-iteration), 2)} minutes {suffix}')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    # Erease progress bar on complete\n",
        "    if iteration == total:\n",
        "      global prev_time\n",
        "      prev_time = 0\n",
        "      sys.stdout.write('\\r')\n",
        "      sys.stdout.flush()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def makeCertaintiyMap(model, accuracy = 100, specific_color = None):\n",
        "  accuracy_map = np.zeros((accuracy, accuracy))\n",
        "\n",
        "  for i in range(accuracy):\n",
        "    tensor = tf.constant([[j/accuracy, i/accuracy] for j in range(accuracy)], tf.float32)\n",
        "    result = model.predict(tensor)\n",
        "\n",
        "    if specific_color != None:\n",
        "      accuracy_map[i] = result[:, specific_color]\n",
        "    else:\n",
        "      result = result.max(axis=1) #Getting each max value\n",
        "      if max(result) != min(result):\n",
        "        normalized = (result-min(result))/(max(result)-min(result))\n",
        "        accuracy_map[i] = normalized\n",
        "      else: \n",
        "        accuracy_map[i] = result\n",
        "      \n",
        "    \n",
        "    printProgressBar(i, accuracy-1)\n",
        "\n",
        "\n",
        "  plt.imshow(accuracy_map, origin='lower', cmap='tab20b', vmin=0, vmax=1)\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "  return accuracy_map\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plotAllPenaltyCombinations(model, accuracy = 100):\n",
        "  print('Chosen Subset:')\n",
        "  makePlot(marker=prediction_points.numpy())\n",
        "\n",
        "  result_x = np.zeros(accuracy+1)\n",
        "  result_y = np.zeros(accuracy+1)\n",
        "\n",
        "  printProgressBar(0, accuracy,prefix='Progress', suffix='ETA: ')\n",
        "\n",
        "  #Iterating over every penalty\n",
        "  for i in range(accuracy+1):\n",
        "    keras.backend.clear_session()\n",
        "    prevTime = time.time()\n",
        "\n",
        "    penalty = i/accuracy #Selecting a value between 0 and 1 with steps of 1/accuracy\n",
        "\n",
        "    model.compile(optimizer='adam',loss=construct_custom_penalty_loss(penalty),metrics=['accuracy'])\n",
        "    model.fit(training_points, training_labels, batch_size=32, epochs=10, shuffle=True, verbose=0)\n",
        "    \n",
        "    #Saving results\n",
        "    result_x[i] = penalty\n",
        "    result_y[i] = model.evaluate(prediction_points, prediction_labels, verbose=0)[0]\n",
        "\n",
        "    #Printing progress\n",
        "    printProgressBar(i+1, accuracy+1,prefix='Progress')\n",
        "\n",
        "  #Presenting the results\n",
        "  print('\\nThe loss:')\n",
        "  plt.plot(result_x, result_y)\n",
        "\n",
        "  return result_y\n",
        "\n",
        "\n",
        "def timeCalc():\n",
        "  global prev_time\n",
        "  if prev_time == 0:\n",
        "    prev_time = time.time()\n",
        "    return 0\n",
        "  \n",
        "  res = (time.time() - prev_time) / 60\n",
        "  prev_time = time.time()\n",
        "  return res\n",
        "\n",
        "\n",
        "def plotHistory(history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def showPredicitons(model, prediction_points, prediction_labels):\n",
        "  prediction = model.predict(prediction_points)\n",
        "\n",
        "  points = prediction_points.numpy()\n",
        "  labels = prediction_labels.numpy()[:, 0].astype(int)\n",
        "\n",
        "  correct_indices = np.where((labels == np.argmax(prediction, axis=1)) == True)\n",
        "  wrong_indices = np.where((labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "  number_of_points = np.bincount(np.argmax(prediction, axis=1))\n",
        "\n",
        "  print(f'Predictions for green: {number_of_points[0]} / {len(labels)}')\n",
        "  print(f'Predictions for red: {number_of_points[1]} / {len(labels)}')\n",
        "  print(f'The algorithm predicted {np.bincount(labels == np.argmax(prediction, axis=1))[0]} times wrong')\n",
        "  makePlot(correct_pred_points=points[correct_indices], incorrect_pred_points=points[wrong_indices])\n",
        "\n",
        "  return prediction"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCsy_7qMzuBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35252db4-509c-4262-a185-d739bfe6a4cf"
      },
      "source": [
        "#Preparing data\n",
        "dataSet = getDataSet()\n",
        "dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "prediction_points, prediction_labels = seperateValidationSet(dataSet=dataSet, validationIndices=VAL_INDICES)\n",
        "\n",
        "#Artificially balancing the dataSet\n",
        "number_of_green_points = list(dataSet['l_i']).count(colors['green'])\n",
        "number_of_red_points = list(dataSet['l_i']).count(colors['red'])\n",
        "\n",
        "if number_of_red_points / SOURCE_SIZE[CURRENT_SET] <= 0.5:\n",
        "  amount = int((0.5 - number_of_red_points / SOURCE_SIZE[CURRENT_SET]) * SOURCE_SIZE[CURRENT_SET])\n",
        "  red_points = dataSet.loc[dataSet['l_i'] == 1] #Getting all red points\n",
        "  choosen_points = red_points.sample(amount, replace=True) #Selecting a random subset of red points\n",
        "  dataSet = dataSet.append(choosen_points, ignore_index=True) #appending the subset\n",
        "\n",
        "if number_of_green_points / SOURCE_SIZE[CURRENT_SET] <= 0.5:\n",
        "  amount = int((0.5 - number_of_green_points / SOURCE_SIZE[CURRENT_SET]) * SOURCE_SIZE[CURRENT_SET])\n",
        "  green_points = dataSet.loc[dataSet['l_i'] == 0] #Getting all green points\n",
        "  choosen_points = green_points.sample(amount, replace=True) #Selecting a random subset of green points\n",
        "  dataSet = dataSet.append(choosen_points, ignore_index=True) #appending green subset\n",
        "\n",
        "if 'index' in dataSet.columns:\n",
        "  dataSet.pop('index') #removing old indices\n",
        "  print(f'Artificially exended by {dataSet[\"x_i1\"].size - SOURCE_SIZE[CURRENT_SET] + len(VAL_INDICES)} points')\n",
        "  print(f'Relation is now: {dataSet.loc[dataSet[\"l_i\"] == 0].shape[0]} green  : {dataSet.loc[dataSet[\"l_i\"] == 1].shape[0]} red ')\n",
        "\n",
        "#Creating tensors\n",
        "training_labels = tf.constant(dataSet.pop('l_i'), tf.float32)\n",
        "training_points = tf.constant(dataSet, tf.float32)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Artificially exended by 140 points\n",
            "Relation is now: 2500 green  : 2614 red \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N24D-gWpnFmD"
      },
      "source": [
        "def construct_custom_penalty_loss(penalty=PENALTY):\n",
        "\n",
        "  def custom_penalty_loss(y_true,y_pred):\n",
        "    length = tf.shape(y_true)[0]\n",
        "\n",
        "    #Creating a vector with all values set to the penalty: [0.3, 0.3, ... 0.3]\n",
        "    error = tf.multiply(tf.constant(penalty, tf.float32), tf.ones(length)) \n",
        "\n",
        "    #Setting every entry to 0 if the corresponding entry in y_true is 1\n",
        "    error = tf.where(tf.equal(y_true[:, 0], tf.zeros(length)), error, tf.zeros(length))\n",
        "\n",
        "    #Setting every entry to 0 if the algorithm predicted 0\n",
        "    error = tf.where(tf.greater(y_pred[:, 0], y_pred[:, 1]), tf.zeros(length), error)\n",
        "\n",
        "    #Transforms the vector from [0, 0, 0.3, ... 0,3] to [[0, -0], [0, -0], [0.3, -0.3], ... [0.3, -0.3]]\n",
        "    error = tf.stack([error, tf.multiply(tf.constant(-1, tf.float32), error)], 1)\n",
        "\n",
        "    #Adding the artificial loss\n",
        "    y_pred = y_pred + error\n",
        "\n",
        "    #Eliminating values > 1 or < 0\n",
        "    y_pred0 = tf.where(tf.greater(y_pred[:, 0], tf.ones(length)), tf.ones(length), y_pred[:, 0])\n",
        "    y_pred1 = tf.where(tf.greater(y_pred[:, 1], tf.zeros(length)), y_pred[:, 1], tf.zeros(length))\n",
        "    y_pred = tf.stack([y_pred0, y_pred1], axis=1)\n",
        "\n",
        "\n",
        "    loss = keras.losses.sparse_categorical_crossentropy(y_pred=y_pred, y_true=y_true)\n",
        "    return loss\n",
        "  \n",
        "  return custom_penalty_loss"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrxlkLjeccKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "becf8af9-4437-406e-99f3-89c0b75ca2d1"
      },
      "source": [
        "model = keras.Sequential([\n",
        "           keras.layers.Flatten(input_shape=(2,)),      #input layer: 2 neurons\n",
        "           keras.layers.Dense(100,activation='relu'), \n",
        "           keras.layers.Dense(70,activation='relu'), \n",
        "           keras.layers.Dense(50,activation='relu'),       \n",
        "           keras.layers.Dense(10,activation='relu'),\n",
        "           keras.layers.Dense(2,activation='softmax')   #output layer: 2 neurons              \n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss=construct_custom_penalty_loss(PENALTY) ,metrics=['accuracy'])\n",
        "\n",
        "validation_set = tf.concat([prediction_points, prediction_labels], axis=1)\n",
        "\n",
        "history = model.fit(training_points, training_labels, batch_size=32, epochs=500, shuffle=True, )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5492 - accuracy: 0.7098\n",
            "Epoch 2/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.8388\n",
            "Epoch 3/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2234 - accuracy: 0.8445\n",
            "Epoch 4/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2194 - accuracy: 0.8473\n",
            "Epoch 5/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2150 - accuracy: 0.8497\n",
            "Epoch 6/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.8438\n",
            "Epoch 7/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2278 - accuracy: 0.8394\n",
            "Epoch 8/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2199 - accuracy: 0.8486\n",
            "Epoch 9/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2244 - accuracy: 0.8369\n",
            "Epoch 10/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.8552\n",
            "Epoch 11/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.8287\n",
            "Epoch 12/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2237 - accuracy: 0.8332\n",
            "Epoch 13/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2260 - accuracy: 0.8317\n",
            "Epoch 14/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2204 - accuracy: 0.8444\n",
            "Epoch 15/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2185 - accuracy: 0.8439\n",
            "Epoch 16/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.8316\n",
            "Epoch 17/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2166 - accuracy: 0.8508\n",
            "Epoch 18/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2237 - accuracy: 0.8453\n",
            "Epoch 19/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2259 - accuracy: 0.8359\n",
            "Epoch 20/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2180 - accuracy: 0.8500\n",
            "Epoch 21/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2181 - accuracy: 0.8430\n",
            "Epoch 22/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2191 - accuracy: 0.8528\n",
            "Epoch 23/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2140 - accuracy: 0.8481\n",
            "Epoch 24/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2162 - accuracy: 0.8446\n",
            "Epoch 25/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2172 - accuracy: 0.8372\n",
            "Epoch 26/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2220 - accuracy: 0.8400\n",
            "Epoch 27/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2125 - accuracy: 0.8450\n",
            "Epoch 28/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2208 - accuracy: 0.8454\n",
            "Epoch 29/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2176 - accuracy: 0.8407\n",
            "Epoch 30/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.8548\n",
            "Epoch 31/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2171 - accuracy: 0.8487\n",
            "Epoch 32/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2183 - accuracy: 0.8434\n",
            "Epoch 33/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2101 - accuracy: 0.8546\n",
            "Epoch 34/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2155 - accuracy: 0.8420\n",
            "Epoch 35/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2138 - accuracy: 0.8508\n",
            "Epoch 36/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2163 - accuracy: 0.8437\n",
            "Epoch 37/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2259 - accuracy: 0.8402\n",
            "Epoch 38/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.8510\n",
            "Epoch 39/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2204 - accuracy: 0.8417\n",
            "Epoch 40/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2047 - accuracy: 0.8504\n",
            "Epoch 41/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2139 - accuracy: 0.8390\n",
            "Epoch 42/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2190 - accuracy: 0.8397\n",
            "Epoch 43/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.8541\n",
            "Epoch 44/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.8553\n",
            "Epoch 45/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.2082 - accuracy: 0.8504\n",
            "Epoch 46/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.8500\n",
            "Epoch 47/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1982 - accuracy: 0.8623\n",
            "Epoch 48/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.8635\n",
            "Epoch 49/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1907 - accuracy: 0.8718\n",
            "Epoch 50/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1834 - accuracy: 0.8769\n",
            "Epoch 51/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1819 - accuracy: 0.8787\n",
            "Epoch 52/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1810 - accuracy: 0.8746\n",
            "Epoch 53/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1632 - accuracy: 0.8848\n",
            "Epoch 54/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1546 - accuracy: 0.8937\n",
            "Epoch 55/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1526 - accuracy: 0.9033\n",
            "Epoch 56/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9006\n",
            "Epoch 57/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1326 - accuracy: 0.9168\n",
            "Epoch 58/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9278\n",
            "Epoch 59/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9330\n",
            "Epoch 60/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1163 - accuracy: 0.9338\n",
            "Epoch 61/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1107 - accuracy: 0.9228\n",
            "Epoch 62/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1023 - accuracy: 0.9450\n",
            "Epoch 63/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9303\n",
            "Epoch 64/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0854 - accuracy: 0.9517\n",
            "Epoch 65/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.9457\n",
            "Epoch 66/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9292\n",
            "Epoch 67/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9292\n",
            "Epoch 68/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0838 - accuracy: 0.9440\n",
            "Epoch 69/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0706 - accuracy: 0.9677\n",
            "Epoch 70/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0799 - accuracy: 0.9478\n",
            "Epoch 71/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9564\n",
            "Epoch 72/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9456\n",
            "Epoch 73/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9589\n",
            "Epoch 74/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0659 - accuracy: 0.9603\n",
            "Epoch 75/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9621\n",
            "Epoch 76/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9625\n",
            "Epoch 77/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9644\n",
            "Epoch 78/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.9703\n",
            "Epoch 79/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0601 - accuracy: 0.9682\n",
            "Epoch 80/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0707 - accuracy: 0.9584\n",
            "Epoch 81/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0696 - accuracy: 0.9483\n",
            "Epoch 82/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0578 - accuracy: 0.9657\n",
            "Epoch 83/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0542 - accuracy: 0.9681\n",
            "Epoch 84/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9672\n",
            "Epoch 85/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0718 - accuracy: 0.9539\n",
            "Epoch 86/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0521 - accuracy: 0.9701\n",
            "Epoch 87/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9640\n",
            "Epoch 88/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9701\n",
            "Epoch 89/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9453\n",
            "Epoch 90/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9581\n",
            "Epoch 91/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9590\n",
            "Epoch 92/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0554 - accuracy: 0.9666\n",
            "Epoch 93/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9651\n",
            "Epoch 94/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9717\n",
            "Epoch 95/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0481 - accuracy: 0.9698\n",
            "Epoch 96/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0663 - accuracy: 0.9568\n",
            "Epoch 97/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0541 - accuracy: 0.9655\n",
            "Epoch 98/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9792\n",
            "Epoch 99/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0570 - accuracy: 0.9630\n",
            "Epoch 100/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9697\n",
            "Epoch 101/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9801\n",
            "Epoch 102/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9721\n",
            "Epoch 103/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9566\n",
            "Epoch 104/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9734\n",
            "Epoch 105/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0432 - accuracy: 0.9720\n",
            "Epoch 106/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0522 - accuracy: 0.9661\n",
            "Epoch 107/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0481 - accuracy: 0.9725\n",
            "Epoch 108/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0563 - accuracy: 0.9640\n",
            "Epoch 109/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9659\n",
            "Epoch 110/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9630\n",
            "Epoch 111/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9755\n",
            "Epoch 112/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9660\n",
            "Epoch 113/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9618\n",
            "Epoch 114/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0489 - accuracy: 0.9708\n",
            "Epoch 115/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9611\n",
            "Epoch 116/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0537 - accuracy: 0.9661\n",
            "Epoch 117/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9652\n",
            "Epoch 118/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0451 - accuracy: 0.9755\n",
            "Epoch 119/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0399 - accuracy: 0.9787\n",
            "Epoch 120/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9768\n",
            "Epoch 121/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9615\n",
            "Epoch 122/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0402 - accuracy: 0.9743\n",
            "Epoch 123/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9765\n",
            "Epoch 124/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9638\n",
            "Epoch 125/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0452 - accuracy: 0.9684\n",
            "Epoch 126/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9810\n",
            "Epoch 127/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9748\n",
            "Epoch 128/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0466 - accuracy: 0.9713\n",
            "Epoch 129/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0371 - accuracy: 0.9805\n",
            "Epoch 130/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9656\n",
            "Epoch 131/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9625\n",
            "Epoch 132/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9751\n",
            "Epoch 133/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9805\n",
            "Epoch 134/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9671\n",
            "Epoch 135/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9780\n",
            "Epoch 136/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9728\n",
            "Epoch 137/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0668 - accuracy: 0.9532\n",
            "Epoch 138/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9752\n",
            "Epoch 139/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9713\n",
            "Epoch 140/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9738\n",
            "Epoch 141/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9790\n",
            "Epoch 142/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9613\n",
            "Epoch 143/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9760\n",
            "Epoch 144/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0441 - accuracy: 0.9668\n",
            "Epoch 145/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9599\n",
            "Epoch 146/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9700\n",
            "Epoch 147/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9749\n",
            "Epoch 148/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9736\n",
            "Epoch 149/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9761\n",
            "Epoch 150/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0663 - accuracy: 0.9546\n",
            "Epoch 151/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0367 - accuracy: 0.9766\n",
            "Epoch 152/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9731\n",
            "Epoch 153/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9701\n",
            "Epoch 154/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9786\n",
            "Epoch 155/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9784\n",
            "Epoch 156/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.9769\n",
            "Epoch 157/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0477 - accuracy: 0.9710\n",
            "Epoch 158/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0460 - accuracy: 0.9718\n",
            "Epoch 159/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9779\n",
            "Epoch 160/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9745\n",
            "Epoch 161/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0720 - accuracy: 0.9474\n",
            "Epoch 162/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9702\n",
            "Epoch 163/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9836\n",
            "Epoch 164/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9687\n",
            "Epoch 165/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9705\n",
            "Epoch 166/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9797\n",
            "Epoch 167/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0385 - accuracy: 0.9770\n",
            "Epoch 168/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9673\n",
            "Epoch 169/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9747\n",
            "Epoch 170/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9758\n",
            "Epoch 171/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9815\n",
            "Epoch 172/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0516 - accuracy: 0.9648\n",
            "Epoch 173/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9709\n",
            "Epoch 174/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0347 - accuracy: 0.9759\n",
            "Epoch 175/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9738\n",
            "Epoch 176/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9641\n",
            "Epoch 177/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9733\n",
            "Epoch 178/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9722\n",
            "Epoch 179/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9692\n",
            "Epoch 180/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9793\n",
            "Epoch 181/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9825\n",
            "Epoch 182/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9753\n",
            "Epoch 183/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9736\n",
            "Epoch 184/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 185/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9608\n",
            "Epoch 186/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9701\n",
            "Epoch 187/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9757\n",
            "Epoch 188/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0401 - accuracy: 0.9756\n",
            "Epoch 189/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9774\n",
            "Epoch 190/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0392 - accuracy: 0.9738\n",
            "Epoch 191/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0478 - accuracy: 0.9648\n",
            "Epoch 192/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0467 - accuracy: 0.9720\n",
            "Epoch 193/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0370 - accuracy: 0.9782\n",
            "Epoch 194/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9647\n",
            "Epoch 195/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9706\n",
            "Epoch 196/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9759\n",
            "Epoch 197/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9666\n",
            "Epoch 198/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.9753\n",
            "Epoch 199/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9761\n",
            "Epoch 200/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9765\n",
            "Epoch 201/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9723\n",
            "Epoch 202/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9772\n",
            "Epoch 203/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0537 - accuracy: 0.9657\n",
            "Epoch 204/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0466 - accuracy: 0.9729\n",
            "Epoch 205/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9836\n",
            "Epoch 206/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0446 - accuracy: 0.9678\n",
            "Epoch 207/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9781\n",
            "Epoch 208/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0451 - accuracy: 0.9732\n",
            "Epoch 209/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9831\n",
            "Epoch 210/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9810\n",
            "Epoch 211/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0643 - accuracy: 0.9562\n",
            "Epoch 212/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9738\n",
            "Epoch 213/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9740\n",
            "Epoch 214/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9802\n",
            "Epoch 215/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9790\n",
            "Epoch 216/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9700\n",
            "Epoch 217/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9758\n",
            "Epoch 218/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9762\n",
            "Epoch 219/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9777\n",
            "Epoch 220/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.9796\n",
            "Epoch 221/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9816\n",
            "Epoch 222/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9772\n",
            "Epoch 223/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9821\n",
            "Epoch 224/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9769\n",
            "Epoch 225/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9655\n",
            "Epoch 226/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9632\n",
            "Epoch 227/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0555 - accuracy: 0.9665\n",
            "Epoch 228/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9819\n",
            "Epoch 229/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9681\n",
            "Epoch 230/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9790\n",
            "Epoch 231/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9801\n",
            "Epoch 232/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9739\n",
            "Epoch 233/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0387 - accuracy: 0.9771\n",
            "Epoch 234/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9711\n",
            "Epoch 235/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9733\n",
            "Epoch 236/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9757\n",
            "Epoch 237/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9768\n",
            "Epoch 238/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9792\n",
            "Epoch 239/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9800\n",
            "Epoch 240/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9806\n",
            "Epoch 241/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9822\n",
            "Epoch 242/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0418 - accuracy: 0.9694\n",
            "Epoch 243/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9698\n",
            "Epoch 244/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9737\n",
            "Epoch 245/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9763\n",
            "Epoch 246/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9727\n",
            "Epoch 247/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9661\n",
            "Epoch 248/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9682\n",
            "Epoch 249/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0387 - accuracy: 0.9762\n",
            "Epoch 250/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9752\n",
            "Epoch 251/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9710\n",
            "Epoch 252/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9784\n",
            "Epoch 253/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0582 - accuracy: 0.9625\n",
            "Epoch 254/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9711\n",
            "Epoch 255/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9706\n",
            "Epoch 256/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9827\n",
            "Epoch 257/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9731\n",
            "Epoch 258/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9856\n",
            "Epoch 259/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9754\n",
            "Epoch 260/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0443 - accuracy: 0.9708\n",
            "Epoch 261/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9799\n",
            "Epoch 262/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9821\n",
            "Epoch 263/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9553\n",
            "Epoch 264/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9817\n",
            "Epoch 265/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9668\n",
            "Epoch 266/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9793\n",
            "Epoch 267/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9745\n",
            "Epoch 268/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9830\n",
            "Epoch 269/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9812\n",
            "Epoch 270/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0355 - accuracy: 0.9762\n",
            "Epoch 271/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0376 - accuracy: 0.9768\n",
            "Epoch 272/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9677\n",
            "Epoch 273/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9704\n",
            "Epoch 274/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9830\n",
            "Epoch 275/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0372 - accuracy: 0.9732\n",
            "Epoch 276/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9732\n",
            "Epoch 277/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9770\n",
            "Epoch 278/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9848\n",
            "Epoch 279/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9789\n",
            "Epoch 280/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.9870\n",
            "Epoch 281/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9812\n",
            "Epoch 282/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9725\n",
            "Epoch 283/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9664\n",
            "Epoch 284/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9695\n",
            "Epoch 285/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9825\n",
            "Epoch 286/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9789\n",
            "Epoch 287/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9798\n",
            "Epoch 288/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9756\n",
            "Epoch 289/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9685\n",
            "Epoch 290/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9724\n",
            "Epoch 291/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9746\n",
            "Epoch 292/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0430 - accuracy: 0.9698\n",
            "Epoch 293/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9760\n",
            "Epoch 294/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9834\n",
            "Epoch 295/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9823\n",
            "Epoch 296/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0238 - accuracy: 0.9838\n",
            "Epoch 297/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9755\n",
            "Epoch 298/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9787\n",
            "Epoch 299/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9815\n",
            "Epoch 300/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9803\n",
            "Epoch 301/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9704\n",
            "Epoch 302/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9786\n",
            "Epoch 303/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9846\n",
            "Epoch 304/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9821\n",
            "Epoch 305/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9673\n",
            "Epoch 306/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9804\n",
            "Epoch 307/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0347 - accuracy: 0.9785\n",
            "Epoch 308/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0355 - accuracy: 0.9750\n",
            "Epoch 309/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9684\n",
            "Epoch 310/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9773\n",
            "Epoch 311/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9767\n",
            "Epoch 312/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9838\n",
            "Epoch 313/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9732\n",
            "Epoch 314/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9728\n",
            "Epoch 315/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9799\n",
            "Epoch 316/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9828\n",
            "Epoch 317/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9807\n",
            "Epoch 318/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.9813\n",
            "Epoch 319/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9720\n",
            "Epoch 320/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9757\n",
            "Epoch 321/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9748\n",
            "Epoch 322/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0452 - accuracy: 0.9672\n",
            "Epoch 323/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9841\n",
            "Epoch 324/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9768\n",
            "Epoch 325/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9821\n",
            "Epoch 326/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0370 - accuracy: 0.9780\n",
            "Epoch 327/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9808\n",
            "Epoch 328/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9785\n",
            "Epoch 329/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9829\n",
            "Epoch 330/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0347 - accuracy: 0.9803\n",
            "Epoch 331/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9832\n",
            "Epoch 332/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9812\n",
            "Epoch 333/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9833\n",
            "Epoch 334/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9813\n",
            "Epoch 335/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9815\n",
            "Epoch 336/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9829\n",
            "Epoch 337/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9820\n",
            "Epoch 338/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9791\n",
            "Epoch 339/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9766\n",
            "Epoch 340/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0370 - accuracy: 0.9772\n",
            "Epoch 341/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9844\n",
            "Epoch 342/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9821\n",
            "Epoch 343/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9793\n",
            "Epoch 344/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9743\n",
            "Epoch 345/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0371 - accuracy: 0.9705\n",
            "Epoch 346/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0331 - accuracy: 0.9794\n",
            "Epoch 347/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9797\n",
            "Epoch 348/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0469 - accuracy: 0.9675\n",
            "Epoch 349/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0303 - accuracy: 0.9784\n",
            "Epoch 350/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9760\n",
            "Epoch 351/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9834\n",
            "Epoch 352/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9759\n",
            "Epoch 353/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9788\n",
            "Epoch 354/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9816\n",
            "Epoch 355/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9721\n",
            "Epoch 356/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9827\n",
            "Epoch 357/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9748\n",
            "Epoch 358/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9777\n",
            "Epoch 359/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9826\n",
            "Epoch 360/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9811\n",
            "Epoch 361/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0258 - accuracy: 0.9831\n",
            "Epoch 362/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9743\n",
            "Epoch 363/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9792\n",
            "Epoch 364/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9618\n",
            "Epoch 365/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9837\n",
            "Epoch 366/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9834\n",
            "Epoch 367/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9839\n",
            "Epoch 368/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9784\n",
            "Epoch 369/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9840\n",
            "Epoch 370/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9759\n",
            "Epoch 371/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9748\n",
            "Epoch 372/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9799\n",
            "Epoch 373/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9754\n",
            "Epoch 374/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9793\n",
            "Epoch 375/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9719\n",
            "Epoch 376/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9818\n",
            "Epoch 377/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9799\n",
            "Epoch 378/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9629\n",
            "Epoch 379/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0489 - accuracy: 0.9678\n",
            "Epoch 380/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9880\n",
            "Epoch 381/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9800\n",
            "Epoch 382/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9847\n",
            "Epoch 383/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9851\n",
            "Epoch 384/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9699\n",
            "Epoch 385/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9869\n",
            "Epoch 386/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0359 - accuracy: 0.9753\n",
            "Epoch 387/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9785\n",
            "Epoch 388/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9849\n",
            "Epoch 389/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0350 - accuracy: 0.9756\n",
            "Epoch 390/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9803\n",
            "Epoch 391/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9832\n",
            "Epoch 392/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9832\n",
            "Epoch 393/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9819\n",
            "Epoch 394/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9757\n",
            "Epoch 395/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9741\n",
            "Epoch 396/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9767\n",
            "Epoch 397/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0359 - accuracy: 0.9735\n",
            "Epoch 398/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9707\n",
            "Epoch 399/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9813\n",
            "Epoch 400/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9764\n",
            "Epoch 401/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9827\n",
            "Epoch 402/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9819\n",
            "Epoch 403/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9772\n",
            "Epoch 404/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9818\n",
            "Epoch 405/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0406 - accuracy: 0.9774\n",
            "Epoch 406/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9874\n",
            "Epoch 407/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9842\n",
            "Epoch 408/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9759\n",
            "Epoch 409/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9786\n",
            "Epoch 410/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9772\n",
            "Epoch 411/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9742\n",
            "Epoch 412/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9809\n",
            "Epoch 413/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0441 - accuracy: 0.9697\n",
            "Epoch 414/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9868\n",
            "Epoch 415/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9866\n",
            "Epoch 416/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0497 - accuracy: 0.9719\n",
            "Epoch 417/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9773\n",
            "Epoch 418/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9838\n",
            "Epoch 419/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9883\n",
            "Epoch 420/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9834\n",
            "Epoch 421/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0350 - accuracy: 0.9729\n",
            "Epoch 422/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9759\n",
            "Epoch 423/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9789\n",
            "Epoch 424/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9788\n",
            "Epoch 425/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9787\n",
            "Epoch 426/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9850\n",
            "Epoch 427/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9699\n",
            "Epoch 428/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9847\n",
            "Epoch 429/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9820\n",
            "Epoch 430/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0370 - accuracy: 0.9730\n",
            "Epoch 431/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9849\n",
            "Epoch 432/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9863\n",
            "Epoch 433/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9763\n",
            "Epoch 434/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9773\n",
            "Epoch 435/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9793\n",
            "Epoch 436/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9854\n",
            "Epoch 437/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9789\n",
            "Epoch 438/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9761\n",
            "Epoch 439/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9777\n",
            "Epoch 440/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9823\n",
            "Epoch 441/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9837\n",
            "Epoch 442/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9726\n",
            "Epoch 443/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9805\n",
            "Epoch 444/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9745\n",
            "Epoch 445/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9813\n",
            "Epoch 446/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9796\n",
            "Epoch 447/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9849\n",
            "Epoch 448/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9812\n",
            "Epoch 449/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9844\n",
            "Epoch 450/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9756\n",
            "Epoch 451/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9804\n",
            "Epoch 452/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9790\n",
            "Epoch 453/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9764\n",
            "Epoch 454/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0445 - accuracy: 0.9694\n",
            "Epoch 455/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9796\n",
            "Epoch 456/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9735\n",
            "Epoch 457/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9791\n",
            "Epoch 458/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9738\n",
            "Epoch 459/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9764\n",
            "Epoch 460/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9783\n",
            "Epoch 461/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9769\n",
            "Epoch 462/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9841\n",
            "Epoch 463/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9854\n",
            "Epoch 464/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9872\n",
            "Epoch 465/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9794\n",
            "Epoch 466/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9855\n",
            "Epoch 467/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9821\n",
            "Epoch 468/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9842\n",
            "Epoch 469/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9813\n",
            "Epoch 470/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9823\n",
            "Epoch 471/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9811\n",
            "Epoch 472/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9798\n",
            "Epoch 473/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9784\n",
            "Epoch 474/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9760\n",
            "Epoch 475/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0303 - accuracy: 0.9778\n",
            "Epoch 476/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 0.9807\n",
            "Epoch 477/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9807\n",
            "Epoch 478/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9799\n",
            "Epoch 479/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9849\n",
            "Epoch 480/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9805\n",
            "Epoch 481/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.9881\n",
            "Epoch 482/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9807\n",
            "Epoch 483/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9759\n",
            "Epoch 484/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9726\n",
            "Epoch 485/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9843\n",
            "Epoch 486/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9875\n",
            "Epoch 487/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9792\n",
            "Epoch 488/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9793\n",
            "Epoch 489/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9742\n",
            "Epoch 490/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9759\n",
            "Epoch 491/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9734\n",
            "Epoch 492/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0492 - accuracy: 0.9671\n",
            "Epoch 493/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9794\n",
            "Epoch 494/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9828\n",
            "Epoch 495/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9822\n",
            "Epoch 496/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9787\n",
            "Epoch 497/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9833\n",
            "Epoch 498/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9851\n",
            "Epoch 499/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9773\n",
            "Epoch 500/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j7CzWG7OiIr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "105c27f6-e8cb-4866-9eaf-d4ba2a3ed734"
      },
      "source": [
        "x = showPredicitons(model, prediction_points, prediction_labels)\n",
        "y = makeCertaintiyMap(model, specific_color=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions for green: 12 / 26\n",
            "Predictions for red: 14 / 26\n",
            "The algorithm predicted 4 times wrong\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}