{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siemens_Approach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericbill21/siemens/blob/BobsLaboratory/Siemens_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W70udFHYSHNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf576f8c-11fb-4b80-e1b6-902ebe1dc31d"
      },
      "source": [
        "#@title Imports and config\n",
        "\n",
        "# Tensorflow and Keras\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython.display import clear_output\n",
        "from psutil import virtual_memory\n",
        "\n",
        "# Arithmetic Operations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "# Data visualization\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "plt.style.use('default')\n",
        "\n",
        "# Progress calculation\n",
        "import sys\n",
        "import logging\n",
        "import time\n",
        "from datetime import date\n",
        "\n",
        "# Time prediciton\n",
        "PREV_TIME = 0\n",
        "PB_START_TIME = 0\n",
        "\n",
        "# Mounting Google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E98cwmoUT7w1"
      },
      "source": [
        "#@title Global constants\n",
        "\n",
        "# Dictionaries\n",
        "COLORS = {0 : 'green', 1 : 'red', 'green' : 0, 'red' : 1}\n",
        "SOURCES = {'A' : 'https://drive.google.com/file/d/1hAzAKZNpmSclSI7HnV_cRjpMS4Kh5r1q/view?usp=sharing', 'B' : 'https://drive.google.com/file/d/12VlecL-5iYs-BFpnTOba1x65jWofBX1P/view?usp=sharing', 'C' : 'https://drive.google.com/file/d/1-Z0RuJIi1cZcqrrmV6TqT0O1PwI2OiBY/view?usp=sharing'}\n",
        "SOURCE_SIZE = {'A': 1000,'B' : 5000, 'C' : 50000}\n",
        "\n",
        "CURRENT_SET = 'A'\n",
        "\n",
        "# Balancing dataset to threshold\n",
        "THRESHOLD = 0.4\n",
        "\n",
        "# Random number seed\n",
        "random.seed(time.time())\n",
        "\n",
        "# Examlpe subsets of each dataset\n",
        "#subsetA = [47, 847, 993, 55, 102, 572, 430, 115, 842, 72, 770, 107, 78, 834, 593, 43, 234, 709, 210, 378]\n",
        "#subsetB = [606, 2663, 1809, 2145, 4539, 3333, 3562, 2262, 512, 2046, 1541, 909, 286, 4815, 3663, 1742, 2822, 2756, 2937, 3080, 3845, 3949, 2506, 3984, 2803, 2067]\n",
        "#subsetC = [32088, 33534, 39634, 40177, 25142, 752, 41771, 11793, 16415, 3811, 2096, 35902, 42221, 19594, 25109, 40476, 25162, 41150, 34610, 28329, 46339, 43149, 44441, 25720, 38747, 49497, 12708, 23920, 2280, 17946]\n",
        "\n",
        "subsetA = random.sample(range(1000), 150)\n",
        "subsetB = random.sample(range(5000), 800)\n",
        "subsetC = random.sample(range(50000), 8000)\n",
        "\n",
        "VAL_INDICES = locals()['subset' + CURRENT_SET]\n",
        "\n",
        "# Penalty applied to false green classifications in custom loss function\n",
        "PENALTY = 0.2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISkimS6oUTP9",
        "cellView": "code"
      },
      "source": [
        "#@title Functions\n",
        "def getDataSet():\n",
        "  \"\"\"Returns the dataset currently selected by CURRENT_SET.\"\"\"\n",
        "  path = 'https://drive.google.com/uc?export=download&id='+SOURCES[CURRENT_SET].split('/')[-2]\n",
        "  return pd.read_excel(path)\n",
        "  \n",
        "\n",
        "\n",
        "def makePlot(dataSet = getDataSet(), showCorrectPoints=False, correct_pred_points = [],\n",
        "             incorrect_pred_points = []):\n",
        "  \"\"\"\"Plots green and red points and markers as scatter graph.\n",
        "  \n",
        "  Args:\n",
        "    dataSet: Optional; Expects pandas.DataFrame object with columns 'x_i1',\n",
        "      'x_i2', 'l_i1'. Dataset to be plotted. Defaults to dataset selected by\n",
        "      CURRENT_SET.\n",
        "    showCorrectPoints: Optional; Expects boolean stating whether correctly \n",
        "      classified points should be marked as black 'x' or not.\n",
        "    correct_pred_points: Optional; Expects 2-dimensional list of shape (x,2)\n",
        "      containing correctly predicted points. Marked as black 'x' on scatter\n",
        "      graph.\n",
        "    incorrect_pred_points: Optional; Expects 2-dimensional list of shape (x,2)\n",
        "      containing incorrectly predicted points. Marked as black '*' on scatter\n",
        "      graph.\n",
        "  \n",
        "  Raises:\n",
        "    TypeError: If dataSet is not an instance of pd.DataFrame or the other\n",
        "      parameters do not have the required shape.\n",
        "  \"\"\"\n",
        "  # Checking for the right type\n",
        "  if not isinstance(dataSet, pd.DataFrame):\n",
        "    raise TypeError(f'dataSet is of type: {type(dataSet)}, but should be {pd.DataFrame}')\n",
        "\n",
        "  # Checking for the right shape \n",
        "  if len(np.array(correct_pred_points).shape) != 2 and np.array(correct_pred_points).shape != (0,):\n",
        "    raise TypeError(f'The shape of the parameter correct_pred_points is: \\\n",
        "      {np.array(correct_pred_points).shape}, but it should be 2 dimensional')\n",
        "  \n",
        "  if len(np.array(incorrect_pred_points).shape) != 2 and np.array(incorrect_pred_points).shape != (0,):\n",
        "    raise TypeError(f'The shape of the parameter incorrect_pred_points is: \\\n",
        "      {np.array(incorrect_pred_points).shape}, but it should be 2 dimensional')\n",
        "  \n",
        "  # Creating a subplot\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  # Scattering all points\n",
        "  for i in range(2):\n",
        "    x_1 = np.array(dataSet['x_i1'].loc[dataSet['l_i'] == i])\n",
        "    x_2 = np.array(dataSet['x_i2'].loc[dataSet['l_i'] == i])\n",
        "    ax.scatter(x_1, x_2, c = COLORS[i])\n",
        "\n",
        "  # Adding markers to the specified points\n",
        "  if showCorrectPoints == True:\n",
        "    ax.scatter(correct_pred_points[:, 0], correct_pred_points[:, 1],\n",
        "              marker = \"x\", c = 'black', label='correct')\n",
        "  ax.scatter(incorrect_pred_points[:, 0], incorrect_pred_points[:, 1],\n",
        "            marker = \"*\", c = 'black', label='incorrect')\n",
        "\n",
        "  # Setting parameters for ploting\n",
        "  plt.legend()\n",
        "  plt.xlabel('x_i1')\n",
        "  plt.ylabel('x_i2')\n",
        "  plt.title(f'DataSet {CURRENT_SET}')\n",
        "  plt.axis('scaled')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def seperateValidationSet(dataSet, validationIndices):\n",
        "  \"\"\"Formats a subset of points from a dataset as validation points.\n",
        "\n",
        "  Validation points are extracted and deleted from dataSet to be used for\n",
        "  validation later on.\n",
        "\n",
        "  Args:\n",
        "    dataSet: Expects pandas.DataFrame object with columns 'x_i1', 'x_i2', 'l_i1'.\n",
        "      dataSet which the validation points are extracted from.\n",
        "    validationIndices: Expects 1-dimensional list of integers. The elements\n",
        "      corresponding to these indices are extracted from dataSet.\n",
        "  Returns: 2-tuple of the form (valSet_points, valSet_labels), where valSet_points\n",
        "    is a tensor of shape (x,2) and valSet_labels is a tensor of shape (x,1).\n",
        "  \"\"\"\n",
        "  # Checking for the right type\n",
        "  if not isinstance(dataSet, pd.DataFrame):\n",
        "    raise TypeError(f'dataSet is of type: {type(dataSet)}, but should be \\\n",
        "      {pd.DataFrame}')\n",
        "\n",
        "  # Checking for the right shape \n",
        "  if len(np.array(validationIndices).shape) != 1:\n",
        "    raise TypeError(f'The shape of the parameter validationIndices is: \\\n",
        "      {np.array(validationIndices).shape}, but it should be 1 dimensional')\n",
        "  \n",
        "  valSet_points = []\n",
        "  valSet_labels = []\n",
        "\n",
        "  for i in validationIndices:\n",
        "    valSet_points.append([dataSet['x_i1'].loc[i], dataSet['x_i2'].loc[i]])\n",
        "    valSet_labels.append([dataSet['l_i'].loc[i]])\n",
        "  \n",
        "  # Saving the validation points\n",
        "  valSet_points = tf.constant(valSet_points, tf.float32)\n",
        "  valSet_labels = tf.constant(valSet_labels, tf.float32)\n",
        "\n",
        "  # Removing the validation point\n",
        "  dataSet.drop(index=validationIndices, inplace=True)\n",
        "  dataSet.reset_index(inplace=True)\n",
        "\n",
        "  return (valSet_points, valSet_labels)\n",
        "\n",
        "\n",
        "\n",
        "def printProgressBar(iteration, total, prefix = '', suffix = '', decimals = 1,\n",
        "                     length = 100, fill = 'â–ˆ'):\n",
        "  \"\"\"Prints a progress bar.\n",
        "\n",
        "  Args:\n",
        "    iteration: Expects integer. Current progress step as. (iteration/total progress).\n",
        "    total: Expects integer. Total progress steps until completion.\n",
        "    prefix: Optional; Expects String. Printed infront of the progress bar.\n",
        "    suffix: Optional; Expects String. Printed behind ETA.\n",
        "    decimals: Optional; Expects integer. Number of decimal places of percentage\n",
        "      progress.\n",
        "    length: Optional; Expects integer. Length of the progress bar in characters.\n",
        "    fill: Optional; Expects char. Filler of the progress bar.\n",
        "  \"\"\"\n",
        "  # Preparing strings\n",
        "  percentage_progress = (100*(iteration/float(total)))\n",
        "  percent = (\"{0:.\" + str(decimals) + \"f}\").format(percentage_progress)\n",
        "  filledLength = int(length * iteration // total)\n",
        "  bar = fill * filledLength + '-' * (length - filledLength)\n",
        "\n",
        "  # Writing strings to console\n",
        "  # sys.stdout.write(f'\\r{prefix} |{bar}| {percent}% ETA: {round(timeCalc()*(total-iteration), 2)} minutes {suffix}')\n",
        "  # sys.stdout.flush()\n",
        "\n",
        "  # Bob's alternative time calculation\n",
        "  if iteration == 0:\n",
        "    global PB_START_TIME\n",
        "    PB_START_TIME = time.time()\n",
        "    time_so_far = 0\n",
        "    time_remaining = 0\n",
        "  else:\n",
        "    time_so_far = time.time() - PB_START_TIME\n",
        "    time_remaining = time_so_far/percentage_progress * (100-percentage_progress)\n",
        "\n",
        "  sys.stdout.write(f'\\r{prefix} |{bar}| {percent}% | ETA: {round((time_remaining/60), 2)} minutes | {suffix}')\n",
        "  sys.stdout.flush()\n",
        "\n",
        "  # Erease progress bar on complete\n",
        "  if iteration == total:\n",
        "    global PREV_TIME\n",
        "    PREV_TIME = 0\n",
        "    sys.stdout.write('\\r')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "\n",
        "def makeCertaintyMap(model, accuracy = 100, specific_color = None):\n",
        "  \"\"\"Visualizes the prediction certainty of the model for a grid of data points.\n",
        "\n",
        "  All data points have x and y values between 0 and 1. \n",
        "\n",
        "  Args:\n",
        "    model: Expects a keras model. The model who's certainty is to be\n",
        "      visualized.\n",
        "    accuracy: Optional; Expects integer. Data points are spaced 1/accuracy apart\n",
        "      along the x and y axis. The grid of data points plotted has the dimension\n",
        "      accuracy*accuracy.\n",
        "    specific_color: Optional; Expects 0 or 1. If 0, plots the model's certainty\n",
        "      that a data point is green for all points in the grid. If 1, analogously \n",
        "      for red. \n",
        "\n",
        "  Raises:\n",
        "    TypeError: If specific_color is not 'None', '0' or '1', or if accuracy is not\n",
        "      an int.\n",
        "  \"\"\"\n",
        "  # Exceptions\n",
        "  if specific_color != None:\n",
        "    if specific_color != 0 and specific_color != 1:\n",
        "      raise TypeError(f'Invalid value for specific_color. Value is {specific_color}, \\\n",
        "        but should be \"None\", \"0\" or \"1\".')\n",
        "\n",
        "  if not isinstance(accuracy, int):\n",
        "    raise TypeError(f'Invalid type for accuracy. Type is {type(accuracy)}, but \\\n",
        "      should be int.')\n",
        "\n",
        "  accuracy_map = np.zeros((accuracy, accuracy))\n",
        "\n",
        "  for i in range(accuracy):\n",
        "    tensor = tf.constant([[j/accuracy, i/accuracy] for j in range(accuracy)], tf.float32)\n",
        "    result = model.predict(tensor)\n",
        "\n",
        "    if specific_color != None:\n",
        "      # Saving the prediction for the specified color\n",
        "      accuracy_map[i] = result[:, specific_color]\n",
        "    \n",
        "    else:\n",
        "      result = result.max(axis=1) #Getting each max value\n",
        "\n",
        "      #Normalize the values which are between 0.5 <-> 1 to 0 <-> 1\n",
        "      normalized = (result-0.5)/0.5\n",
        "      accuracy_map[i] = normalized\n",
        "  \n",
        "    # Print current progress\n",
        "    printProgressBar(i, accuracy-1)\n",
        "\n",
        "  if specific_color != None:\n",
        "    plt.title(f'Certaintiy for {COLORS[specific_color]}')\n",
        "  else:\n",
        "    plt.title(f'General Certainty')\n",
        "\n",
        "  plt.imshow(accuracy_map, origin='lower', cmap='tab20b', vmin=0, vmax=1)\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "  return accuracy_map\n",
        "\n",
        "\n",
        "\n",
        "def timeCalc():\n",
        "  \"\"\"Calculates time between previous call and current call.\n",
        "\n",
        "  Returns:\n",
        "    Time difference in minutes as float.\n",
        "  \"\"\"\n",
        "  global PREV_TIME\n",
        "  if PREV_TIME == 0:\n",
        "    PREV_TIME = time.time()\n",
        "    return 0\n",
        "  \n",
        "  res = (time.time() - PREV_TIME) / 60\n",
        "  PREV_TIME = time.time()\n",
        "  return res\n",
        "\n",
        "\n",
        "\n",
        "def plotLoss(history):\n",
        "  \"\"\"Plots training loss and validation loss with respect to training epochs.\n",
        "\n",
        "  Args:\n",
        "    history: Expects keras History. history of keras model.\n",
        "  \"\"\"\n",
        "  if 'val_loss' in history.history:\n",
        "    plt.plot(history.history['val_loss'])\n",
        "\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def showPredicitons(model, history, valSet_points,\n",
        "                    valSet_labels, showCorrectPoints=False):\n",
        "  \"\"\"Visualizes the predictions for the validation points.\n",
        "\n",
        "  Args:\n",
        "    model: Expects keras model. Model which performs the predictions.\n",
        "    history: Expects keras History. history of keras model.\n",
        "    valSet_points: Expects tensor of shape (x,2). Data points used for validation.\n",
        "    valSet_labels: Expects tensor of shape (x,1). Ground truth labels of the \n",
        "      validation points.\n",
        "    showCorrectPoints: Optional; Expects boolean stating whether correctly \n",
        "      classified points should be marked as black 'x' or not.\n",
        "\n",
        "  Returns:\n",
        "    2-dimensional numpy array of shape (x,2) with the predictions for the\n",
        "    validation points.\n",
        "  \"\"\"\n",
        "  # Predict the validation points\n",
        "  prediction = model.predict(valSet_points)\n",
        "\n",
        "  points = valSet_points.numpy()\n",
        "  labels = valSet_labels.numpy()[:, 0].astype(int)\n",
        "\n",
        "  # Identifying correctly and incorrectly classified points\n",
        "  correct_indices = np.where((labels == np.argmax(prediction, axis=1)) == True)\n",
        "  incorrect_indices = np.where((labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "  number_of_points = np.bincount(np.argmax(prediction, axis=1))\n",
        "\n",
        "  total_misclassifications = np.bincount(labels == np.argmax(prediction, axis=1))[0]\n",
        "  red_misclassifications = len(np.where(labels[incorrect_indices] == 1)[0])\n",
        "  green_misclassifications = len(np.where(labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "  #Average misclassification certainty\n",
        "  misclass_certainties = []\n",
        "  for i in incorrect_indices[0]:\n",
        "    misclass_certainties.append(np.max(prediction[i]))\n",
        "  avg_misclass_certainty = sum(misclass_certainties)/total_misclassifications\n",
        "  \n",
        "  print('Validation accuracy: {:.2f}%'.format((history.history['val_accuracy'])[-1]*100))\n",
        "  print(f'Predictions for green: {number_of_points[0]} / {len(labels)}')\n",
        "  print(f'Predictions for red: {number_of_points[1]} / {len(labels)}')\n",
        "  print(f'Points misclassified: {total_misclassifications}')\n",
        "  print(f'Red points misclassified: {red_misclassifications}')\n",
        "  print(f'Green points misclassified: {green_misclassifications}')\n",
        "  print('Average misclassification certainty: {:.2f}'.format(avg_misclass_certainty))\n",
        "\n",
        "  makePlot(showCorrectPoints=showCorrectPoints, correct_pred_points=points[correct_indices],\n",
        "           incorrect_pred_points=points[incorrect_indices])\n",
        "\n",
        "  # Make bar graph showing red and green misclassifications\n",
        "  bars = ('Red', 'Green')\n",
        "  height = [red_misclassifications, green_misclassifications]\n",
        "  x_pos = np.arange(len(bars))\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.bar(x_pos, height, width=0.35, color=['red', 'green'])\n",
        "\n",
        "  ax.set_ylabel('Misclassifications')\n",
        "  ax.set_title('Misclassifications by color')\n",
        "  ax.set_xticks(x_pos)\n",
        "  ax.set_xticklabels(bars)\n",
        "\n",
        "  rects = ax.patches # Array of bars\n",
        "\n",
        "  labels = [red_misclassifications, green_misclassifications]\n",
        "\n",
        "  for rect, label in zip(rects, labels): # Add labels above bars\n",
        "      height = rect.get_height()\n",
        "      ax.text(rect.get_x() + rect.get_width() / 2, height, label,\n",
        "              ha='center', va='bottom')\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "  return prediction\n",
        "\n",
        "  \n",
        "\n",
        "def balanceDataset(dataSet, threshold, verbose=1):\n",
        "  \"\"\"Artificially balances dataSet by duplicating red or green points.\n",
        "\n",
        "  Args: \n",
        "    dataSet: Expects pandas.DataFrame object with columns 'x_i1', 'x_i2', 'l_i1'.\n",
        "      The dataset to be balanced.\n",
        "    threshold: Expects float between 0 and 0.5. The function duplicates red or \n",
        "      green points until the fraction of points of the less frequent color is\n",
        "      at least equal to the threshold.\n",
        "\n",
        "  Returns:\n",
        "    balanced dataset of shape (x,2)\n",
        "  \"\"\"\n",
        "  total_number_of_points = dataSet.shape[0]\n",
        "  number_of_green_points = dataSet.loc[dataSet[\"l_i\"] == 0].shape[0]\n",
        "  number_of_red_points = dataSet.loc[dataSet[\"l_i\"] == 1].shape[0]\n",
        "\n",
        "  amount = 0\n",
        "\n",
        "  if number_of_red_points / total_number_of_points < threshold:\n",
        "    amount = int( (threshold * total_number_of_points - number_of_red_points) // (1 - threshold) )\n",
        "    red_points = dataSet.loc[dataSet['l_i'] == 1] #Getting all red points\n",
        "    chosen_points = red_points.sample(amount, replace=True) #Selecting a random subset of red points\n",
        "    dataSet = dataSet.append(chosen_points, ignore_index=True) #appending the subset\n",
        "\n",
        "  if number_of_green_points / total_number_of_points < threshold:\n",
        "    amount = int( (threshold * total_number_of_points - number_of_green_points) // (1 - threshold) )\n",
        "    green_points = dataSet.loc[dataSet['l_i'] == 0] #Getting all green points\n",
        "    chosen_points = green_points.sample(amount, replace=True) #Selecting a random subset of green points\n",
        "    dataSet = dataSet.append(chosen_points, ignore_index=True) #appending green subset\n",
        "\n",
        "  if 'index' in dataSet.columns:\n",
        "    dataSet.pop('index') #removing old indices\n",
        "\n",
        "  total_number_of_points = dataSet.shape[0]\n",
        "  number_of_green_points = dataSet.loc[dataSet[\"l_i\"] == 0].shape[0]\n",
        "  number_of_red_points = dataSet.loc[dataSet[\"l_i\"] == 1].shape[0]\n",
        "\n",
        "  if verbose > 0:\n",
        "    print(f'Artificially exended by {amount} points')\n",
        "    print(f'Relation is now: {round(number_of_green_points / total_number_of_points, 2)}',\n",
        "            f'green : {round(number_of_red_points / total_number_of_points, 2)} red ')\n",
        "  \n",
        "  return dataSet\n",
        "\n",
        "\n",
        "\n",
        "def calculatePenaltyEffect(model, x, y, validation_data, interval=(0,1), accuracy=10, \n",
        "                      batch_size=32, epochs=200, verbose=0):\n",
        "  \"\"\"Calculates red, green, and total misclassifications in relation to penalty.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model for which the penalty effect is measured.\n",
        "    x: tensor of shape (x,2) and type tf.float32\n",
        "      Training points.\n",
        "    y: tensor of shape (x,1) and type float32\n",
        "      Training labels.\n",
        "    validation_data: 2-tuple\n",
        "      (valSet_points, valSet_labels) where valSet_points is a tensor of shape\n",
        "      (x,2) and type tf.float32 and valSet_labels tensor of shape (x,1) and type\n",
        "      tf.float32. Validation points and labels.\n",
        "    interval: 2-tuple, optional\n",
        "      (x,y) which defines the penalty interval plotted. x is the lowest penalty,\n",
        "      y the highest.\n",
        "    accuracy: int, optional\n",
        "      Penalty interval is evenly split into 'accuracy' many points.\n",
        "    verbose: boolean, optional\n",
        "      Whether to print progress bar and plot results or not. \n",
        "    All others: optional\n",
        "      See tf.keras.Model.\n",
        "\n",
        "  Returns:\n",
        "    3-tuple of int lists (total_misclass_percentage, red_misclass_percentage, \n",
        "    green_misclass_percentage).\n",
        "  \"\"\"\n",
        "  total_misclass_percentages = []\n",
        "  red_misclass_percentages = []\n",
        "  green_misclass_percentages = []\n",
        "  penalties = np.zeros(accuracy + 1)\n",
        "  increments = (interval[1]-interval[0])/accuracy\n",
        "\n",
        "  points = validation_data[0].numpy()\n",
        "  labels = validation_data[1].numpy()[:, 0].astype(int)\n",
        "\n",
        "  number_of_points = len(labels)\n",
        "  red_points = len(np.where(labels==1)[0])\n",
        "  green_points = len(np.where(labels==0)[0])\n",
        "\n",
        "  if verbose > 0:\n",
        "    printProgressBar(0, accuracy+1)\n",
        "\n",
        "  # MAIN LOOP\n",
        "  for i in range(accuracy+1):\n",
        "    penalty = interval[0] + (interval[1]-interval[0])*(i/accuracy)\n",
        "    model.set_weights(initialWeights)\n",
        "\n",
        "    model.compile(optimizer='adam', loss=construct_custom_penalty_loss(penalty),\n",
        "                  metrics=['accuracy']) # Compile model with penalty\n",
        "\n",
        "    history = model.fit(x, y, batch_size, epochs, verbose=0, validation_data=validation_data)\n",
        "\n",
        "    prediction = model.predict(validation_data[0])\n",
        "\n",
        "    correct_indices = np.where((labels == np.argmax(prediction, axis=1)) == True)\n",
        "    incorrect_indices = np.where((labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "    total_misclassifications = np.bincount(labels == np.argmax(prediction, axis=1))[0]\n",
        "    red_misclassifications = len(np.where(labels[incorrect_indices] == 1)[0])\n",
        "    green_misclassifications = len(np.where(labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "    total_misclass_percentages.append((total_misclassifications/number_of_points)*100)\n",
        "    red_misclass_percentages.append((red_misclassifications/red_points)*100)\n",
        "    green_misclass_percentages.append((green_misclassifications/green_points)*100)\n",
        "\n",
        "    penalties[i] = penalty\n",
        "    \n",
        "    if verbose > 0:\n",
        "      printProgressBar(i+1, iterations+1)\n",
        "\n",
        "  # PLOTTING RESULTS\n",
        "  if verbose > 0:\n",
        "    plt.figure(figsize=(20,15))\n",
        "    plt.plot(penalties, total_misclass_percentages, 'b', penalties, \n",
        "              red_misclass_percentages, 'r', penalties, green_misclass_percentages,\n",
        "              'g')\n",
        "    plt.title(f'Dataset {CURRENT_SET}: Misclassification by penalty')\n",
        "    plt.ylabel('% misclassified')\n",
        "    plt.xlabel('Penalty')\n",
        "    plt.xticks(np.arange(interval[0], interval[1]+increments, increments))\n",
        "    plt.legend(['total', 'red', 'green'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "  return (total_misclass_percentages, red_misclass_percentages,\n",
        "         green_misclass_percentages)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGMBPET_gqbP",
        "cellView": "code"
      },
      "source": [
        "#@title Average Penalty Effect\n",
        "def averagePenaltyEffect(model, n, valSet_size, path='', interval=(0,1), accuracy=10, \n",
        "                      batch_size=32, epochs=200, verbose=1):\n",
        "  \"\"\"Plots average penalty effect over n iterations.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model for which the penalty effect is measured.\n",
        "    n: int\n",
        "      Number of iterations the penalty effect is measured and averaged over.\n",
        "    valSet_size: int\n",
        "      Size of the validation set.\n",
        "    path: str, optional\n",
        "      Path to which the excel sheet will be saved. e.g. '/content/drive/MyDrive/'\n",
        "    verbose: boolean, optional\n",
        "      Whether to print progress bar or not.\n",
        "    All others:\n",
        "      See calculatePenaltyEffect.\n",
        "\n",
        "  Returns:\n",
        "    3-tuple of np arrays (total_misclass_percentages_avg,\n",
        "    red_misclass_percentages_avg, green_misclass_percentages_avg).\n",
        "  \"\"\"\n",
        "  #Start time\n",
        "  start_time = time.time()\n",
        "\n",
        "  penalties = np.arange(interval[0], interval[1]+(interval[1]-interval[0])/accuracy,\n",
        "                        (interval[1]-interval[0])/accuracy)\n",
        "\n",
        "  # INITIALIZATION OF DATA COLLECTION OBJECTS\n",
        "  # For averaging\n",
        "  total_misclass_percentages_collected = []\n",
        "  red_misclass_percentages_collected = []\n",
        "  green_misclass_percentages_collected = []\n",
        "  # For saving in excel\n",
        "  validation_points_collected = np.zeros((valSet_size, 3*n))\n",
        "  misclassification_matrix = np.zeros((len(penalties), 3*n))\n",
        "  # Column names\n",
        "  val_columns = []\n",
        "  coll_columns = []\n",
        "\n",
        "  # Initialize progress bar\n",
        "  if verbose > 0:\n",
        "    printProgressBar(0, n)\n",
        "\n",
        "  # MAIN LOOP\n",
        "  for i in range(n):\n",
        "    # PREPARING DATA\n",
        "    dataSet = getDataSet()\n",
        "    dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "    # Choose random validation set\n",
        "    random.seed(time.time())\n",
        "    val_indices = random.sample(range(SOURCE_SIZE[CURRENT_SET]), valSet_size)\n",
        "\n",
        "    valSet_points, valSet_labels = seperateValidationSet(dataSet=dataSet, validationIndices=val_indices)\n",
        "    dataSet = balanceDataset(dataSet, threshold=THRESHOLD, verbose=0)\n",
        "\n",
        "    training_labels = tf.constant(dataSet.pop('l_i'), tf.float32)\n",
        "    training_points = tf.constant(dataSet, tf.float32)\n",
        "\n",
        "    # Collecting misclassification percentages\n",
        "    allPercentages = calculatePenaltyEffect(model, training_points, training_labels,\n",
        "                                            (valSet_points, valSet_labels),\n",
        "                                            interval=interval, accuracy=accuracy,\n",
        "                                            batch_size=batch_size, epochs=epochs, \n",
        "                                            verbose=0)\n",
        "\n",
        "    total_misclass_percentages_collected.append(allPercentages[0])\n",
        "    red_misclass_percentages_collected.append(allPercentages[1])\n",
        "    green_misclass_percentages_collected.append(allPercentages[2])\n",
        "\n",
        "    # Creating seperate columns for validation set\n",
        "    val_columns.append(f'x_i1:{i}')\n",
        "    val_columns.append(f'x_i2:{i}')\n",
        "    val_columns.append(f'l_i:{i}')\n",
        "\n",
        "    valSet_points = valSet_points.numpy()\n",
        "    valSet_labels = valSet_labels.numpy()\n",
        "\n",
        "    for j in range(valSet_size):\n",
        "      validation_points_collected[j,3*i + 0] = valSet_points[j, 0]\n",
        "      validation_points_collected[j,3*i + 1] = valSet_points[j, 1] \n",
        "      validation_points_collected[j,3*i + 2] = valSet_labels[j, 0] \n",
        "\n",
        "    # Creating seperarte columns for current misclassification\n",
        "    coll_columns.append(f'total:{i}')\n",
        "    coll_columns.append(f'red:{i}')\n",
        "    coll_columns.append(f'green:{i}')\n",
        "\n",
        "    misclassification_matrix[:, 3*i + 0] = allPercentages[0]\n",
        "    misclassification_matrix[:, 3*i + 1] = allPercentages[1]\n",
        "    misclassification_matrix[:, 3*i + 2] = allPercentages[2]\n",
        "\n",
        "    if verbose > 0:\n",
        "      printProgressBar(i+1, n)\n",
        "\n",
        "  \n",
        "  # Averaging\n",
        "  total_misclass_percentages_avg = np.average(total_misclass_percentages_collected, axis=0)\n",
        "  red_misclass_percentages_avg = np.average(red_misclass_percentages_collected, axis=0)\n",
        "  green_misclass_percentages_avg = np.average(green_misclass_percentages_collected, axis=0)\n",
        "\n",
        "  result = (total_misclass_percentages_avg, red_misclass_percentages_avg,\n",
        "         green_misclass_percentages_avg)\n",
        "\n",
        "  # PLOTTING RESULTS\n",
        "  plotPenaltyEffect(model, data=result, interval=interval, accuracy=accuracy, n=n, \n",
        "                    valSet_size=valSet_size, batch_size=batch_size, epochs=epochs,\n",
        "                    path=path)\n",
        "\n",
        "  # Print time taken for calculation\n",
        "  end_time = time.time()\n",
        "  total_time = (end_time-start_time)/60\n",
        "  print(f'Time taken: {round(total_time, 2)} minutes.')\n",
        "\n",
        "  # Save results to excel\n",
        "  writer = pd.ExcelWriter(f'{path}PenaltyEffect_{CURRENT_SET}_{model.name}.xlsx')\n",
        "  # Save average misclassification percentages to excel\n",
        "  pd.DataFrame([total_misclass_percentages_avg, red_misclass_percentages_avg, \n",
        "                green_misclass_percentages_avg], ['total','red','green'], \n",
        "               columns=penalties).to_excel(writer, sheet_name=f'Average')\n",
        "  # Save misclassification percentages collected to excel\n",
        "  pd.DataFrame(misclassification_matrix, penalties,\n",
        "               columns=coll_columns).to_excel(writer, sheet_name=f'Collected')\n",
        "  # Save all validation set to one '.xlsx' file\n",
        "  pd.DataFrame(validation_points_collected,\n",
        "               columns=val_columns).to_excel(writer, sheet_name=f'Validation Sets')\n",
        "\n",
        "  writer.save()\n",
        "\n",
        "  return result"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KscN7_iScqQK"
      },
      "source": [
        "#@title Plot Average Penalty Effect\n",
        "def plotPenaltyEffect(model, data, interval, accuracy, n, valSet_size, batch_size, epochs,\n",
        "                      dataset=CURRENT_SET, ylim=[0,10], maj_yt_incr=1,\n",
        "                      min_yt_incr=0.1, figsize=(14,10), showParameters=True,\n",
        "                      resolution=300, path=''):\n",
        "  \"\"\"Plots average penalty effect given by 'data' and saves png of plot to the\n",
        "    directory.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model for which the penalty effect is measured.\n",
        "    data: 3-tuple of np arrays, or str\n",
        "      (total_misclass_percentages_avg, red_misclass_percentages_avg,\n",
        "      green_misclass_percentages_avg) or the name of an Excel sheet present in\n",
        "      the directory as a String (e.g. 'data.xlsx').\n",
        "    interval: 2-tuple\n",
        "      (x,y) which defines the penalty interval plotted. x is the lowest penalty,\n",
        "      y the highest.\n",
        "    accuracy: int\n",
        "      Penalty interval is evenly split into 'accuracy' many points.\n",
        "    n, valSet_size, batch_size, epochs:\n",
        "      Parameters used for training and calculaing the average penalty effect.\n",
        "      Shown in configurations text in plot.\n",
        "    dataset: char, optional\n",
        "      Dataset which the penalty effect was measured on. 'A', 'B' or 'C'.\n",
        "    ylim: 1D list of floats or ints, optional\n",
        "      [x,y] which defines the range of % misclassification shown on the y-axis.\n",
        "    maj_yt_incr: float, optional\n",
        "      The increments in which major y-ticks are plotted on the y-axis.\n",
        "    min_yt_incr: float, optional\n",
        "      The increments in which minor y-ticks are plotted on the y-axis.\n",
        "    figsize: 2-tuple of floats, optional\n",
        "      (x,y) where x is the width of the plot and y is the height of the plot.\n",
        "    showParameters: boolean, optional\n",
        "      Whether to include a configuratiuon text in the plot or not. \n",
        "    resolution: int, optional\n",
        "      Resolution of the plot png in dpi.\n",
        "    path: str, optional\n",
        "      Path to which the plots will be saved. e.g. '/content/drive/MyDrive/'\n",
        "\n",
        "  Raises:\n",
        "    TypeError: if data is not of type String or 3-tuple of np arrays.\n",
        "  \"\"\"\n",
        "  # Penalties to be plotted on the x-axis\n",
        "  penalties = np.arange(interval[0], interval[1]+(interval[1]-interval[0])/accuracy,\n",
        "                          (interval[1]-interval[0])/accuracy)\n",
        "\n",
        "  # DATA PREPARATION\n",
        "  if (isinstance(data, tuple) and isinstance(data[0], np.ndarray) and \n",
        "      isinstance(data[1], np.ndarray) and isinstance(data[2], np.ndarray) and\n",
        "      len(data)==3):\n",
        "    total_misclass_percentages_avg = data[0]\n",
        "    red_misclass_percentages_avg = data[1]\n",
        "    green_misclass_percentages_avg = data [2]\n",
        "\n",
        "  elif isinstance(data, str):\n",
        "    xls = pd.ExcelFile(data)\n",
        "    avg_data = pd.read_excel(xls, 'Average')\n",
        "\n",
        "    total = pd.DataFrame(avg_data.loc[0])\n",
        "    total = total.drop('Unnamed: 0')\n",
        "    total_misclass_percentages_avg = total[0]\n",
        "\n",
        "    red = pd.DataFrame(avg_data.loc[1])\n",
        "    red = red.drop('Unnamed: 0')\n",
        "    red_misclass_percentages_avg = red[1]\n",
        "\n",
        "    green = pd.DataFrame(avg_data.loc[2])\n",
        "    green = green.drop('Unnamed: 0')\n",
        "    green_misclass_percentages_avg = green[2]\n",
        "\n",
        "  else:\n",
        "    raise TypeError(f'Invalid type of data. data should be of type String or '\n",
        "                    + f'a 3-tuple of np arrays, but data is of type {type(data)}.')\n",
        "\n",
        "  # Define yticks\n",
        "  major_yticks = np.arange(0, ylim[1]+maj_yt_incr, maj_yt_incr)\n",
        "  minor_yticks = np.arange(0, ylim[1]+min_yt_incr, min_yt_incr)\n",
        "\n",
        "  # Create subplot\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "  ax.plot(penalties, total_misclass_percentages_avg, 'b', penalties, \n",
        "            red_misclass_percentages_avg, 'r', penalties,\n",
        "            green_misclass_percentages_avg, 'g')\n",
        "\n",
        "  ax.set_title(f'Dataset {dataset}: Average misclassification by penalty',\n",
        "               fontsize='x-large')\n",
        "  ax.set_ylabel('% misclassified', fontsize='large')\n",
        "  ax.set_xlabel('Penalty', fontsize='large')\n",
        "\n",
        "  # Ranges of x and y-axis\n",
        "  ax.set_xlim(list(interval))\n",
        "  ax.set_ylim(ylim)\n",
        "\n",
        "  # Set ticks\n",
        "  ax.set_xticks(penalties)\n",
        "  ax.set_yticks(major_yticks)\n",
        "  ax.set_yticks(minor_yticks, minor=True)\n",
        "\n",
        "  # Color and grid\n",
        "  ax.set_facecolor('white')\n",
        "  ax.grid(which='minor', alpha=0.2, color='black')\n",
        "  ax.grid(which='major', alpha=0.5, color='black')\n",
        "\n",
        "  # Show configuration information on plot\n",
        "  if showParameters==True:\n",
        "    config_info = (f'{model.name}\\nn: {n}\\nVal. set size: {valSet_size}\\n' + \n",
        "                   f'Batch size: {batch_size}\\nEpochs: {epochs}')\n",
        "    ax.text(interval[1]+(interval[1]/(8*figsize[0])), ylim[1]-(ylim[1]/figsize[1]),\n",
        "            config_info)\n",
        "\n",
        "  plt.legend(['total', 'red', 'green'], loc='upper left', fontsize='medium')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  # Get current date\n",
        "  today = date.today()\n",
        "\n",
        "  fig.savefig(f'{path}{today.strftime(\"%d-%m-%Y\")}_Dataset_{dataset}_Penalty_Plt_{model.name}.png',\n",
        "              dpi=resolution)\n",
        "  fig.savefig(f'{path}{today.strftime(\"%d-%m-%Y\")}_Dataset_{dataset}_Penalty_Plt_{model.name}.pdf')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Plp8chnd34"
      },
      "source": [
        "def epochsBatchSize(model, initialWeights, valSet_size, batchRange, batchIncrements,\n",
        "                 epochRange, epochIncrements, path='', verbose=1):\n",
        "  \"\"\"Calculates total, red, and green % misclassification in relation to batch\n",
        "    size and epoch number for a random validation set on CURRENT_SET.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      Model which classifies the validation set.\n",
        "    initialWeights: array-like\n",
        "      Initial weights of model.\n",
        "    valSet_size: int\n",
        "      Size of the randomly chosen validation set.\n",
        "    batchRange: 2-tuple of ints\n",
        "      The range of batch sizes used. (x,y) where x is the smallest and y is the\n",
        "      largest batch size used. \n",
        "    batchIncrements: int\n",
        "      Increment in which the batch size is increased.\n",
        "    epochRange: 2-tuple of ints\n",
        "      The range of epochs used. (x,y) where x is the smallest and y is the\n",
        "      largest epoch number used.\n",
        "    epochIncrements: int\n",
        "      Increment in which the epoch number is increased.\n",
        "    path: str, optional\n",
        "      Path to which the plots will be saved. e.g. '/content/drive/MyDrive/'\n",
        "    verbose: boolean, optional\n",
        "      Whether to print a progress bar or not.\n",
        "\n",
        "  Returns:\n",
        "    5-tuple of lists (epochs, batch_sizes, total_misclass_percentage,\n",
        "    red_misclass_percentage, green_misclass_percentage).\n",
        "  \"\"\"\n",
        "  # Start time\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Preparing data collection lists\n",
        "  epochs = []\n",
        "  batch_sizes = []\n",
        "  total_misclass_percentage = []\n",
        "  red_misclass_percentage = []\n",
        "  green_misclass_percentage = []\n",
        "\n",
        "  # Defining interation lists\n",
        "  batch_size_iter = np.arange(batchRange[0], batchRange[1]+1, batchIncrements)\n",
        "  epoch_iter = np.arange(epochRange[0], epochRange[1]+1, epochIncrements)\n",
        "\n",
        "  # Preparing data\n",
        "  dataSet = getDataSet()\n",
        "  dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "  # Choose random validation set\n",
        "  random.seed(time.time())\n",
        "  val_indices = random.sample(range(SOURCE_SIZE[CURRENT_SET]), valSet_size)\n",
        "\n",
        "  valSet_points, valSet_labels = seperateValidationSet(dataSet=dataSet,\n",
        "                                                       validationIndices=val_indices)\n",
        "  \n",
        "  dataSet = balanceDataset(dataSet, threshold=THRESHOLD, verbose=0)\n",
        "\n",
        "  training_labels = tf.constant(dataSet.pop('l_i'), tf.float32)\n",
        "  training_points = tf.constant(dataSet, tf.float32)\n",
        "\n",
        "  points = valSet_points.numpy()\n",
        "  labels = valSet_labels.numpy()[:, 0].astype(int)\n",
        "\n",
        "  number_of_points = len(labels)\n",
        "  red_points = len(np.where(labels==1)[0])\n",
        "  green_points = len(np.where(labels==0)[0])\n",
        "\n",
        "  # Initialize progress bar\n",
        "  if verbose > 0:\n",
        "    num_training_points = training_labels.shape[0] - valSet_size\n",
        "    progress = 0\n",
        "    full = 0\n",
        "    # Calculate full progress\n",
        "    for ep in epoch_iter:\n",
        "      for ba in batch_size_iter:\n",
        "        full += ep*math.ceil(num_training_points/ba)\n",
        "    # Print bar\n",
        "    printProgressBar(progress, full, suffix=f'{progress}/{full} steps')\n",
        "\n",
        "  # Epoch loop\n",
        "  for ep in epoch_iter:\n",
        "    # Batch size loop\n",
        "    for ba in batch_size_iter:\n",
        "      epochs.append(ep)\n",
        "      batch_sizes.append(ba)\n",
        "\n",
        "      # Prepare model for classification\n",
        "      model.set_weights(initialWeights)\n",
        "\n",
        "      model.compile(optimizer='adam', loss=construct_custom_penalty_loss(PENALTY),\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "      history = model.fit(training_points, training_labels, ba, ep, verbose=0,\n",
        "                          validation_data=(valSet_points,valSet_labels))\n",
        "\n",
        "      # Classification and saving results\n",
        "      prediction = model.predict(valSet_points)\n",
        "\n",
        "      correct_indices = np.where((labels == np.argmax(prediction, axis=1)) == True)\n",
        "      incorrect_indices = np.where((labels == np.argmax(prediction, axis=1)) == False)\n",
        "\n",
        "      total_misclassifications = np.bincount(labels == np.argmax(prediction, axis=1))[0]\n",
        "      red_misclassifications = len(np.where(labels[incorrect_indices] == 1)[0])\n",
        "      green_misclassifications = len(np.where(labels[incorrect_indices] == 0)[0])\n",
        "\n",
        "      total_misclass_percentage.append((total_misclassifications/number_of_points)*100)\n",
        "      red_misclass_percentage.append((red_misclassifications/red_points)*100)\n",
        "      green_misclass_percentage.append((green_misclassifications/green_points)*100)\n",
        "\n",
        "      # Update progress bar\n",
        "      if verbose > 0:\n",
        "        progress += ep*math.ceil(num_training_points/ba)\n",
        "        printProgressBar(progress, full, suffix=f'{progress}/{full} steps')\n",
        "\n",
        "  result = (epochs, batch_sizes, total_misclass_percentage, red_misclass_percentage,\n",
        "            green_misclass_percentage)\n",
        "\n",
        "  # Print time taken for calculation\n",
        "  end_time = time.time()\n",
        "  total_time = (end_time-start_time)/60\n",
        "  print(f'Time taken: {round(total_time, 2)} minutes.')\n",
        "\n",
        "  # Plot results\n",
        "  plotEpochsBatchSize(model, result, path=path)\n",
        "\n",
        "  # Save results to excel\n",
        "  df = pd.DataFrame.from_dict({'epoch':epochs,'batch_size':batch_sizes,\n",
        "                               'total':total_misclass_percentage,\n",
        "                               'red':red_misclass_percentage,\n",
        "                               'green':green_misclass_percentage})\n",
        "  df.to_excel(f'{path}EpochsBatchSize_{CURRENT_SET}_{model.name}.xlsx',\n",
        "              header=True, index=False)\n",
        "  \n",
        "  return result\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV8gqh2NRIug",
        "cellView": "code"
      },
      "source": [
        "#@title Plot epochs / batch size\n",
        "def plotEpochsBatchSize(model, data, dataset=CURRENT_SET,\n",
        "                        misclass_range=(0,15), figsize=(14,10), resolution=300,\n",
        "                        cmap='viridis', path=''):\n",
        "  \"\"\"Plots a 3D graph showing the relation between epoch number, batch size,\n",
        "    and percentage misclassification.\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "      The model which was used for training and classification.\n",
        "    data: 5-tuple lists, or str\n",
        "      (epochs, batch_sizes, total_misclass_percentage, red_misclass_percentage,\n",
        "      green_misclass_percentage) or the name of an Excel sheet present in\n",
        "      the directory as a String (e.g. 'data.xlsx').\n",
        "    dataset: char, optional\n",
        "      The dataset used. 'A', 'B' or 'C'.\n",
        "    misclass_range: 2-tuple, optional\n",
        "      The range of misclassification percentages plotted (limits of the z-axis).\n",
        "    figsize: 2-tuple, optional\n",
        "      (x,y) where x is the width of the plot and y is the height of the plot.\n",
        "    resolution: int, optional\n",
        "      Resolution of the plot png in dpi.\n",
        "    cmap: Colormap, optional\n",
        "      A colormap for the surface patches.\n",
        "    path: str, optional\n",
        "      Path to which the plots will be saved. e.g. '/content/drive/MyDrive/'\n",
        "  \"\"\"\n",
        "  # Converting data to array\n",
        "  data = list(data)\n",
        "  for i in range(5):\n",
        "    if isinstance(data[i], list):\n",
        "      data[i] = np.array(data[i])\n",
        "\n",
        "  # Checking for the right shapes\n",
        "  for i in range(4):\n",
        "    if data[i].shape != data[i+1].shape:\n",
        "      raise TypeError(f'The elements of the 5-tuple data must all have the same' +\n",
        "                f'shape! The {i+1}. element is shape {data[i].shape} and the {i+2}. element' +\n",
        "                f' is shape {data[i+1].shape}')\n",
        "      \n",
        "  if len(data[0].shape) != 1:\n",
        "    raise TypeError(f'The elements of the 5-tuple data must all be 1-dimensional')\n",
        "    \n",
        "  # Data preparation\n",
        "  epochs = data[0]\n",
        "  batch_sizes = data[1]\n",
        "\n",
        "  total_misclass = data[2]\n",
        "  red_misclass = data[3]\n",
        "  green_misclass = data[4]\n",
        "\n",
        "  # Plotting\n",
        "  fig = plt.figure(figsize=(figsize[0], figsize[1]*3))\n",
        "  # Total misclassification\n",
        "  ax_t = fig.add_subplot(3, 1, 1, projection='3d')\n",
        "  ax_t.plot_trisurf(epochs, batch_sizes, total_misclass, cmap=cmap)\n",
        "  ax_t.set_title(f'Dataset {dataset}: Total misclassification by epoch and batch size')\n",
        "  ax_t.set_xlabel('Epochs')\n",
        "  ax_t.set_ylabel('Batch size')\n",
        "  ax_t.set_zlabel('% misclassification')\n",
        "  ax_t.set_zlim3d(misclass_range[0], misclass_range[1])\n",
        "  # Red misclassification\n",
        "  ax_r = fig.add_subplot(3, 1, 2, projection='3d')\n",
        "  ax_r.plot_trisurf(epochs, batch_sizes, red_misclass, cmap=cmap)\n",
        "  ax_r.set_title(f'Dataset {dataset}: Red misclassification by epoch and batch size')\n",
        "  ax_r.set_xlabel('Epochs')\n",
        "  ax_r.set_ylabel('Batch size')\n",
        "  ax_r.set_zlabel('% misclassification')\n",
        "  ax_r.set_zlim3d(misclass_range[0], misclass_range[1])\n",
        "  # Green misclassification\n",
        "  ax_g = fig.add_subplot(3, 1, 3, projection='3d')\n",
        "  ax_g.plot_trisurf(epochs, batch_sizes, green_misclass, cmap=cmap)\n",
        "  ax_g.set_title(f'Dataset {dataset}: Green misclassification by epoch and batch size')\n",
        "  ax_g.set_xlabel('Epochs')\n",
        "  ax_g.set_ylabel('Batch size')\n",
        "  ax_g.set_zlabel('% misclassification')\n",
        "  ax_g.set_zlim3d(misclass_range[0], misclass_range[1])\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  # Saving\n",
        "  today = date.today()\n",
        "\n",
        "  fig.savefig(f'{path}{today.strftime(\"%d-%m-%Y\")}_Dataset_{dataset}_EpochsBatchSize_{model.name}.png',\n",
        "              dpi=resolution)\n",
        "  fig.savefig(f'{path}{today.strftime(\"%d-%m-%Y\")}_Dataset_{dataset}_EpochsBatchSize_{model.name}.pdf')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCsy_7qMzuBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "fcff603b-ba07-4230-d017-4c334c3e3f33"
      },
      "source": [
        "#@title Preparing data\n",
        "dataSet = getDataSet()\n",
        "dataSet.pop('Unnamed: 0') #Removing unnessary column\n",
        "\n",
        "valSet_points, valSet_labels = seperateValidationSet(dataSet=dataSet, validationIndices=VAL_INDICES)\n",
        "\n",
        "dataSet = balanceDataset(dataSet, threshold=THRESHOLD)\n",
        "\n",
        "#Creating tensors\n",
        "training_labels = tf.constant(dataSet.pop('l_i'), tf.float32)\n",
        "training_points = tf.constant(dataSet, tf.float32)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Artificially exended by 98 points\n",
            "Relation is now: 0.6 green : 0.4 red \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N24D-gWpnFmD",
        "cellView": "form"
      },
      "source": [
        "#@title Custom Loss Function\n",
        "\n",
        "def construct_custom_penalty_loss(penalty,\n",
        "                                  lossFunction=keras.losses.sparse_categorical_crossentropy):\n",
        "  \"\"\"Constructs a loss function which penalizes 'red as green' misclassifications. \n",
        "\n",
        "  Args:\n",
        "    penalty: Expects float between 0 and 1. Value added to the loss if a red\n",
        "      point is misclassified as green. \n",
        "    lossFunction: Optional; Expects a loss function. The loss function used after\n",
        "      adapting the loss values.\n",
        "\n",
        "  Returns:\n",
        "    custom_penalty_loss function with specified penalty and loss function. Can be\n",
        "    used like a regular loss function. \n",
        "  \"\"\"\n",
        "\n",
        "  def custom_penalty_loss(y_true, y_pred):\n",
        "    length = tf.shape(y_true)[0]\n",
        "\n",
        "    #Creating a vector with all values set to the penalty: [0.3, 0.3, ... 0.3]\n",
        "    error = tf.multiply(tf.constant(penalty, tf.float32), tf.ones(length)) \n",
        "\n",
        "    #Setting every entry to 0 if the corresponding entry in y_true is 1\n",
        "    error = tf.where(tf.equal(y_true[:, 0], tf.zeros(length)), error, tf.zeros(length))\n",
        "\n",
        "    #Setting every entry to 0 if the algorithm predicted 0\n",
        "    error = tf.where(tf.greater(y_pred[:, 0], y_pred[:, 1]), tf.zeros(length), error)\n",
        "\n",
        "    #Transforms the vector from [0, 0, 0.3, ... 0,3] to [[0, -0], [0, -0], [0.3, -0.3], ... [0.3, -0.3]]\n",
        "    error = tf.stack([error, tf.multiply(tf.constant(-1, tf.float32), error)], 1)\n",
        "\n",
        "    #Adding the artificial loss\n",
        "    y_pred = y_pred + error\n",
        "\n",
        "    #Eliminating values > 1 or < 0\n",
        "    y_pred0 = tf.where(tf.greater(y_pred[:, 0], tf.ones(length)), tf.ones(length), y_pred[:, 0])\n",
        "    y_pred1 = tf.where(tf.greater(y_pred[:, 1], tf.zeros(length)), y_pred[:, 1], tf.zeros(length))\n",
        "    y_pred = tf.stack([y_pred0, y_pred1], axis=1)\n",
        "\n",
        "\n",
        "    loss = lossFunction(y_pred=y_pred, y_true=y_true)\n",
        "    return loss\n",
        "  \n",
        "  return custom_penalty_loss"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrxlkLjeccKz"
      },
      "source": [
        "# Configure and compile model\n",
        "initalizer = keras.initializers.GlorotNormal()\n",
        "\n",
        "model_0 = keras.Sequential([\n",
        "          keras.layers.Flatten(input_shape=(2,)),      #input layer: 2 neurons\n",
        "          keras.layers.Dense(100,activation='relu', kernel_initializer=initalizer), \n",
        "          keras.layers.Dense(70,activation='relu', kernel_initializer=initalizer), \n",
        "          keras.layers.Dense(50,activation='relu', kernel_initializer=initalizer),       \n",
        "          keras.layers.Dense(10,activation='relu', kernel_initializer=initalizer),\n",
        "          keras.layers.Dense(2,activation='softmax', kernel_initializer=initalizer)   #output layer: 2 neurons              \n",
        "          ], name=\"model_0\")\n",
        "\n",
        "model_0.compile(optimizer='adam', loss=construct_custom_penalty_loss(PENALTY), metrics=['accuracy'])\n",
        "\n",
        "#Save initial weights\n",
        "initialWeights = model_0.get_weights()\n",
        "\n",
        "# Fit model\n",
        "history = model_0.fit(training_points, training_labels, batch_size=64, epochs=500,\n",
        "                    shuffle=True, validation_data=(valSet_points, valSet_labels))\n",
        "clear_output()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT5nK7VXTN5B"
      },
      "source": [
        "# Plot data\n",
        "plotLoss(history)\n",
        "x = showPredicitons(model_0, history, valSet_points, valSet_labels)\n",
        "y = makeCertaintyMap(model_0, 100, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFYpw1K2A2CF"
      },
      "source": [
        "#average_penalty_effect = averagePenaltyEffect(n=15, valSet_size=8000, accuracy=20,\n",
        "#                                              batch_size=768, epochs=1000) "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nzni4e78sTX",
        "cellView": "form"
      },
      "source": [
        "#@title GPU and RAM info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8FfzrseHYcr"
      },
      "source": [
        "result = epochsBatchSize(model_0, initialWeights, 150, (32,96), 16,\n",
        "                                  (200,400), 100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}